[
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/aws-cloudformation-installation/",
	"title": "CloudFormation",
	"tags": ["#aws", "#iam role", "#cloudFormation script"],
	"description": "",
	"content": " This installation method leverages a CloudFormation script found in step 1.4. After you make a new AWS integration in Metricly, the script populates a read-only IAM role in your AWS account and links it using the integration’s Account ID and External ID. Once created, it may take a few minutes for the status to be updated.\nCreate an AWS Integration in Metricly  Open Metricly and navigate to Integrations \u0026gt; AWS.\n Create a new AWS integration. Ensure that the below tabled properties are set according to your needs.     AWS Toggle Description     CostExplorer Captures billing data. This should only be enabled on 1 AWS account, the master billing data account.   CloudWatch Enable the CloudWatch toggle to monitor performance data. This can be done on multiple accounts.    3. For AWS Authentication, select IAM Role.\n4. Click the CloudFormation script link under Configure AWS Permissions. This opens a new tab in AWS.\n5. Check I acknowledge that AWS CloudFormation might create IAM resources.\n6. Click Create Role.\n7. It may take a few minutes to create the role. When ready, the status turns green. Add Role ARN to the New AWS Integration  In the AWS console, navigate to Services \u0026gt; IAM \u0026gt; Roles.\n Find the role created in the previous section using the search bar.\n Expand Outputs and copy the Role ARN.\n Do not copy the Stack ID. The Role ARN looks like: arn:aws:iam::\u0026lt;account-number\u0026gt;:role/\u0026lt;Metricly-Role-Name\u0026gt;  Return to the Metricly.\n Input the Role ARN into IAM Role ARN.\n Click Save.\n  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/getting-started/cost-tools/",
	"title": "Cost Tools",
	"tags": [],
	"description": "",
	"content": " more on this later "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/create-edit-policies/",
	"title": "Create or Edit a Policy",
	"tags": ["#alerts", "#notifications", "#events", "#policies"],
	"description": "",
	"content": "Create, edit, delete, enable, and disable policies with the Policy Editor. You can also use Policy Editor to enable and disable notifications.\n Open the Policy Editor. Navigate to Alerts \u0026gt; + Add New Policy. Begin crafting your policy at Step 1: Scope. You can also open an existing policy and click Edit Policy. Policies that correspond to inactive datasources cannot be edited.  The top of your policy has 3 important fields:\n Name: Make this human readable, something your team would understand months or years down the road. Enable Policy: Policies are automatically enabled upon creation. To complete an unfinished policy at a later time, uncheck this field and save. Category: Info, Warning, or Critical.     Category Color Description     Info Blue The Info category indicates that a policy has been violated, but the anomalous behavior is not critical.   Warning Yellow The Warning category indicates that a policy has been violated, and there will likely be a more critical event in the future.   Critical Red The Critical category indicates that a policy has been violated, and the cause of the event should be addressed quickly.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/",
	"title": "Dashboards",
	"tags": ["#getting started", "#directory page", "#dashboards", "#widgets"],
	"description": "",
	"content": " Visualize your data in Metricly with dashboards.You can use the default, pre-packaged integration dashboards or create and customize your own using widgets. Default dashboards are not editable.\nView a Dashboard  Click on Dashboards in the main menu.\nor Navigate to Dashboards \u0026gt; Manage Dashboards.  Edit a Dashboard Editing an existing dashboard can involve managing the layout of a dashboard, changing the dashboard’s settings, or manipulating the time frame setting/refresh interval.\nEdit Name  Navigate to Dashboards \u0026gt; Dashboard Name. Hover over the dashboard’s name and click to edit.  Edit Display Mode  Navigate to Dashboards \u0026gt; Dashboard Name. Click \r. A modal with all display options appears.  Toggle any setting active (green) to enable.  Shared: Makes dashboard public for each of the users under a tenant; users can edit and delete the dashboard if they wish without affecting the original dashboard. Fullscreen Mode:  Fullscreen: Fullscreen Mode makes your dashboard(s) take up the entire screen. Rotate Dashboards: If you have fullscreen mode enabled, it will only rotate through your favorite dashboards if this option is selected. Rotation Period (sec): If Rotate Dashboards is set to On, you can enable all of your dashboards to cycle through after a set number of seconds (the default is 60 seconds; the minimum is 20 seconds). Theater Mode: Hides the top navigation menu.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/getting-started/",
	"title": "Getting Started",
	"tags": ["#getting started", "#directory page"],
	"description": "",
	"content": " 1. Watch Our Product Demo There’s no faster way to get acquainted with the UI than by watching the demo video. This tour covers both the Cost and Monitoring products, including topics like: the EC2 recommendation report, the Utilization Boxplot report, and the Cost report.\n2. Register an Account You’re excited to right-size your environments and lower their costs. You’ve done all your research, and you’re ready to try Metricly’s 21-day free trial. Click Sign Up at the top-right of the page and, after filling out a quick form, you’ll begin to set up Metricly.\nWhitelist Metricly Emails Make sure you’re able to receive all of your emailed reports and notifications by whitelisting @metricly.com and @metriclyinc.com This prevents your reports from getting caught in spam filters.\n3. Set Up The AWS Integration Chances are, you’re going to want to start with AWS.\nWe recommend linking your AWS account using the CloudFormation Method found in our help documentation. It’s fast and gets you ready to pump in billing data. Just run the script, enable AWS Cost Explorer, and you’re ready to start monitoring.\nThis Integration Supports \r\rCost Reports for EC2, RDS, and S3\n\rResource Utilization\n\rEC2 Recommendation\n\rEC2 Reservation Recommendation\n\rAWS Services Cost\n\rASG Recommendation\n\rIdle Resource Discovery (ELB, EBS)\nRemember to enable cost explorer and detailed billing before moving beyond this stage.\n\r4. Install Agents (Linux, Windows) Check out our most popular agents! Click on the links to read their in-depth setup documentation. These agents pull in additional cost metrics and help you take action on report insights. Using these agents ensures the most accurate cost recommendations.\n Linux Agent\nQuickly deploy and collect metrics with a richer set of metadata, right out of the box. This agent also supports CloudWatch integration.\n Windows Agent\nMonitor windows performance counters and attributes with the Windows Agent. Pre-configured to send the most important performance metrics, windows events, and system attributes, it’s powerful from the start. You can also customize it to send additional data as needed.\n  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-standard-install/",
	"title": "Standard Install",
	"tags": ["#agents", "#linux"],
	"description": "",
	"content": " This integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\n1. Copy Install Command From Linux Integration Setup Page  From the top navigation menu, select Integrations. Select the Linux card. The name should be already populated, and Data Collection should be enabled. Highlight the one-line install command from the instructions and copy them. A unique API key for your account has already been generated and included in the command line.   If you’d prefer to specify the element name, copy the following instead:\nsudo N_APIKEY=your-apikey N_HOSTNAME=your-element-name bash -c \u0026quot;$(curl -Ls http://repos.app.netuitive.com/linux.sh)\u0026quot;  your-apikey is the API key generated from the integration and your-element-name can be any element name you wish (it must be unique from your other elements).\n2. Install Linux Agent  Paste the command from step 1.3 into your command line. This installs the agent and adds your account’s unique API key to the configuration file.  If you install our Linux agent on an AWS EC2 or Azure VM, the EC2’s / VM’s power state (it will come in as the attribute hostRunning with a value of true or false) and tags are copied over to the corresponding Linux SERVER element. You can then use this information to create policies.\r3. Edit Linux Agent Config File  Navigate to the Linux Agent configuration file found at /opt/netuitive-agent/conf/netuitive-agent.conf. Ensure the API key provided in step 1 is input in the netuitive-agent.conf file. The section below is only a portion of the config file. Go here to view the full config file.\n[[NetuitiveHandler]] ### MetriclyCloud URL to post the metrics url = https://api.app.metricly.com/ingest/infrastructure ## Metricly Datasource api key api_key = \u0026lt;datasource api key\u0026gt; ### Uncomment to add tags (optional) # tags = tag1:tag1val, tag2:tag2val ### Uncomment to add relations # relations = element1, element2 # How many samples to store before sending to Metricly batch = 100 # how many batches to store before trimming max_backlog_multiplier = 5 # Trim down how many batches trim_backlog_multiplier = 4 # local statsd server [[[statsd]]] enabled = False  Save the configuration file.\n Restart the Linux Agent service to begin monitoring your data with Metricly.\n  Config Options  Option 1: Substitute tags value with desired tags and uncomment the line to pass in tags for your element. Option 2: Substitute relations value with desired element relationships; must include the fully qualified name of the elements. Uncomment the line to pass in relationships for your element. Option 3: Adjust default collectors (CPU, DiskSpace, DiskUsage, Heartbeat, LoadAverage, Memory, VMStat, Network) using the configuration options found here.\n  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/checks/view-checks/",
	"title": "View Checks",
	"tags": ["#alerts", "#notifications", "#checks", "#custom checks"],
	"description": "",
	"content": "Leveraging our saved filters is a good way to find your checks. All checks are tagged with the key n.checks and value check name.\n Click Type and select either SERVER (for Linux) or WINSRV (for Windows) to pick where the check has been configured. Navigate to More \u0026gt; Tag and search for n.checks.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/events/view-an-event/",
	"title": "View an Event",
	"tags": ["#alerts", "#notifications", "#events"],
	"description": "",
	"content": " The following tools allow you to view and analyze events in the Metricly UI:\n Event Explorer: Event Explorer displays a comprehensive list of all the events in your environment. You can filter the list by the event category, source (Metricly or External), element, element type, and/or tag of the element(s) to which an event is associated. You can also filter events within a specific time frame. For more information about Event Explorer, see below. Metrics page: Metrics page displays the events and metric data for a specified element. The amount of data displayed can be limited by selecting a time frame setting and by showing or hiding metric charts. For more information about Metrics page, see Metrics page.  Event Explorer Event Explorer allows you to view, search, and analyze events.\nIf one of your policies is particularly noisy, you can delete all events associated with the policy. See Create or Edit a Policy for more information.\n\r Search: Contains several filters where you can search for Event (i.e. the policy that created the event), event category, source (Metricly or External), element, element type, Element tag, and/or Event tag. Expand the More filter to see additional filters; select a filter to add it to the list of active filters. For more information on creating event tags, see the external events section below. Events list: The Events list lists events by the date and time they occurred, the name of the policy that generated the event, the event category, the source of the event (Metricly or External), the name of the element(s) to which they are associated, and the type of the element(s) to which they are associated. Click the name of the policy in the Event column to view the violating metrics on the Metrics page (source = Metricly) or the event message (source = External). Click the Element’s name to view the element’s Element Detail panel. You can also navigate to Policy Editor to edit the policy associated with the event by clicking the Event name (events from Metricly only). Events graph: The Events graph displays the events in your environment based on the Time Frame setting and other search filters. Click an event to have the option of viewing the violating metrics on the Metrics page or edit the policy the event is associated with. Time Frame: The Time Frame controls the range of data displayed. To refresh data, click the refresh button. Selecting “1w” in the Time Frame displays the most recent week of data and/or elements. By selecting “Ending Now,” you can specify a range of data beginning with a date other than today. For more information, see Time Frame.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/",
	"title": "Alerts &amp; Notifications",
	"tags": ["#alerts", "#notifications", "#events", "#policies"],
	"description": "",
	"content": " New to Metricly? Use this page as an overview for the features related to Alerts, Events, Policies, and Notifications. For a more technical walkthrough on each, see our related articles.\nAlerts Alerts are a continuous series of events. They group anomalous behavior and enable you to view open (active) or closed (inactive) incidents. The Open Policies list is the first you see when navigating to the Alerts menu. This list is updated every 30 seconds.\nYou can view, edit, and create policies in this menu; you can also enable notifications for policies. Clicking on a policy name expands its details, such as conditions and associated elements.\nEvents Events are violations that have met all of a policy’s conditions for a set duration. They indicate that Metricly has detected anomalous behavior in your environment. You can view, categorize, and analyze events. Organized most-to-least recent, finding the right event is easy.\nYou can zoom in on a series of events by clicking and dragging across the timeline.\nNotifications Notifications can be set on any policy that is important to you and your team. From Email, to OpsGenie, to Slack—rest assured you can get notified in the way most convenient to you. You can also customize the frequency of your notifications.\nYou can create a notification by editing a policy and navigating to 3: Notifications\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-docker-install/",
	"title": "Docker Install",
	"tags": ["#agents", "#linux", "#docker"],
	"description": "",
	"content": " 1. Copy API Key From Docker Integration  From the Metricly top navigation menu, select Integrations.\n Click the Docker card.\n Ensure Data Collection is enabled. A unique API key for your account has already been generated.\n Highlight the one-line install command from the instructions and copy them. A unique API key for your account has already been generated and included in the command line.\n  The command runs a container named netuitive-agent in the background and publishes the port values to the host. It then sets the environment variable DOCKER_HOSTNAME and APIKEY to the described values. Lastly, a volume is mounted so the agent has access to the Docker API.\nCommand Line Alternative You can also copy the line below and paste it into your command line. Ensure you replace \u0026lt;my-api-key\u0026gt; with your API key from Metricly and \u0026lt;my-docker-host\u0026gt; with the desired hostname. Additional environment variables are located in the drop-down below if you’d like to include more or edit existing ones.\ndocker run -d -p 8125:8125/udp --name netuitive-agent -e DOCKER_HOSTNAME=\u0026quot;\u0026lt;my-docker-host\u0026gt;\u0026quot; -e APIKEY=\u0026quot;\u0026lt;my-api-key\u0026gt;\u0026quot; -v /proc:/host_proc:ro -v /var/run/docker.sock:/var/run/docker.sock:ro netuitive/docker-agent  Environment Variables    Variable Description Example     LOGLEVEL Changes the log level of the agent. -e LOGLEVEL=DEBUG would set the agent tolog at DEBUG level.   INTERVAL Sets the interval in seconds at which the agent collectors run. -e INTERVAL=120 would set collection attwo-minute intervals.   DOCKER_HOSTNAME Sets the host name of the docker host. -e DOCKER_HOSTNAME=\u0026quot;my-docker-host\u0026quot; would set the host name to my-docker-host.   APIKEY Sets the API key used send data to Metricly. -e APIKEY=myapikey would set the API keyto myapikey.   USE_LOCAL_CONFIG Tells the agent to ignore any environment variables set and to usea local config file. -e USE_LOCAL_CONFIG=true would enable this feature.   LPRT Tells the Netuitive StatsD agent whatUDP port to listen on. 8125 is the default.    FORWARD Enables forwarding from the netuitive-statsd server to anotherStatsD server.    FIP Tells the Netuitive StatsD agent what IP address to forward to.    FPRT Tells the Netuitive StatsD agent what port to forward to. 8125 isthe default     2. Install Linux Agent Docker Container Paste the command from 1.3 into your command line. Replace my-docker-host in the command with the name of the docker host. The command will install the agent and add your account’s unique API key to the configuration file. - Optional: Navigate to the Linux agent configuration file at /opt/netuitive-agent/conf/netuitive-agent.conf and add a metrics blacklist or whitelist under the [[NetuitiveDockerCollector]] section to reduce the number of metrics you receive.\nRegex Examples  Escape special regex characters . * / using a /. The following would match containers.*.blkio. metrics and exclude them from collection.\nmetrics_blacklist = containers\\..*\\.blkio\\..* Match multiple containers between ( ) and separated by |. The following would match any of the following container IDs and exclude them from collection: abcdef123456, 123456abcdef, ghijkl789012.\nmetrics_blacklist = containers\\.(abcdef123456|123456abcdef|ghijkl789012)\\..*  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/aws-iam-installation/",
	"title": "IAM",
	"tags": ["#aws", "#iam role"],
	"description": "",
	"content": " IAM Role Method Setting up an AWS integration via IAM Role is a two step process:\nCreate a new AWS integration in Metricly using an IAM read-only role. Optionally, filter your AWS elements for inclusion in Metricly by creating or choosing an existing tag (key-value pair), then assigning that tag to the desired elements in AWS.\nStep 1: Create a new AWS integration  From the top navigation menu, select Integrations. Click the Amazon Web Services card. Type a name for the new AWS integration. Ensure that Data Collection is selected. For AWS Authentication, select IAM Role. In a separate, new tab, open your AWS console.  Step 2a: Create Read Only Role (with standard permissions)  Log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Once in the IAM dashboard, navigate to the Roles section. Click Create New Role. For Role Name, type Metricly and click Next Step. For Role Type, select Role for Cross-Account Access. Click Select next to the “Provide access between your AWS account and a 3rd party AWS account” option. On the tab that has the AWS Integration Setup page open, copy the Account ID and the External ID provided to you. On the tab that has the AWS console open, paste your Account ID and External ID into the appropriate fields. Leave Require MFA unchecked. Click Next Step. For Attach Policy, add all of the following:  CostExplorerAPIAccess AmazonMQReadOnlyAccess ReadOnlyAccess  Click Next Step to review the role and access the Role ARN. Copy the Role ARN. After copying the Role ARN, click Create Role.  If you are not able to create a new read only role through the AWS Identity \u0026amp; Access Management (IAM) dashboard, see Access Key authentication.\nPlease make sure you save the role in the AWS console before you attempt the next step.\nStep 2b: Creating a Read Only Role (with minimal permissions) If you want to use a limited read only access policy, you’ll need to create a custom policy first.\n Log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Once in the IAM dashboard, navigate to the Policies section. Click Create Policy in the top left-hand corner. Click Select next to Create Your Own Policy. Type a Policy Name into the field. Type a description of the policy. Copy and paste the following code into the Policy Document section.  { \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Action\u0026quot;: [ \u0026quot;autoscaling:Describe*\u0026quot;, \u0026quot;ce:*\u0026quot;, \u0026quot;cloudwatch:Describe*\u0026quot;, \u0026quot;cloudwatch:Get*\u0026quot;, \u0026quot;cloudwatch:List*\u0026quot;, \u0026quot;dynamodb:Describe*\u0026quot;, \u0026quot;dynamodb:Get*\u0026quot;, \u0026quot;dynamodb:List*\u0026quot;, \u0026quot;ec2:Describe*\u0026quot;, \u0026quot;ec2:GetConsoleOutput\u0026quot;, \u0026quot;ecs:Describe*\u0026quot;, \u0026quot;ecs:List*\u0026quot;, \u0026quot;elasticache:Describe*\u0026quot;, \u0026quot;elasticache:List*\u0026quot;, \u0026quot;elasticloadbalancing:Describe*\u0026quot;, \u0026quot;elasticmapreduce:Describe*\u0026quot;, \u0026quot;elasticmapreduce:List*\u0026quot;, \u0026quot;iam:Get*\u0026quot;, \u0026quot;kinesis:DescribeStream\u0026quot;, \u0026quot;kinesis:Get*\u0026quot;, \u0026quot;kinesis:List*\u0026quot;, \u0026quot;lambda:List*\u0026quot;, \u0026quot;rds:Describe*\u0026quot;, \u0026quot;rds:ListTagsForResource\u0026quot;, \u0026quot;redshift:Describe*\u0026quot;, \u0026quot;mq:List*\u0026quot;, \u0026quot;mq:Describe*\u0026quot;, \u0026quot;s3:Describe*\u0026quot;, \u0026quot;s3:Get*\u0026quot;, \u0026quot;s3:List*\u0026quot;, \u0026quot;sqs:Get*\u0026quot;, \u0026quot;sqs:List*\u0026quot;, \u0026quot;tag:Get*\u0026quot; ], \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot; } ] }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/inventory/",
	"title": "Inventory",
	"tags": ["#getting started", "#metrics", "#elements", "#inventory page"],
	"description": "",
	"content": " Your inventory is the elements that make up your environment, from your java virtual machines to your Amazon EC2s. Metricly’s Inventory Explorer allows you to view and search the elements in your inventory.\nAbout Elements The physical or logical components that Metricly monitors are called elements. An element can be a physical entity, such as a server or network element, a virtual entity, such as a transaction, or a business entity, such as a company traded on the stock market. Elements are the base component that Metricly uses to analyze metrics and determine the status of your environment.\nAll elements share the following characteristics:\n A unique name and identifier in Metricly. Descriptive attributes, or characteristics, assigned by an integration. Events that are triggered when the conditions in policies are met. A tag or tags used to label and organize elements. An element type, usually assigned by an integration.  Attributes An attribute is a property or characteristic that describes an element. Having attributes gives you access to more statistical data that can be used to troubleshoot issues. Most elements receive attributes from their integration.\nFor example, with attribute information, you can see the number and type of CPU running on a server element, while also viewing an event that was generated based on that element’s CPU value.\n\rElement Types Each element has a type that determines how it is processed and represented by Metricly. Element type is also used as a filter in list pages in the UI. The types of elements in your environment will vary based on the integration that you use1.\n   Integration Element Type in Metricly     AWS ASG (Auto Scaling Group)   AWS Custom Cloudwatch Metrics   AWS DynamoDB   AWS EBS (Elastic Block Store)   AWS ECS (EC2 Container Service)   AWS EC2 (Elastic Compute Cloud)   AWS Elasticache Elasticache   AWS ELB (Elastic load balance   AWS EMR (Elastic Map Reduce)   AWS Kinesis (Stream)   AWS Lambda   AWS RDS (Relational Database Service)   AWS Redshift   AWS SQS (Simple Queue Service)   Browser BROWSER   Custom N/A   Docker Docker Container   Java JVM   Java CLUSTER   Linux (Metricly) SERVER   Microsoft Azure AZURE VIRTUAL MACHINE   Microsoft Azure APPLICATION GATEWAY   Ruby RUBY   Windows WINSRV   Collectd SERVER   Diamond SERVER   StatsD StatsD    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/getting-started/metric-monitoring/",
	"title": "Metric Monitoring",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/acess-key-aws/",
	"title": "Access Key",
	"tags": ["#aws", "#access key"],
	"description": "",
	"content": " Access key Setting up an AWS integration is a two step process:\n Create a new AWS integration in Metricly and share the Access Key ID and Secret Access Key of the desired IAM read-only user.\n Optionally, filter your AWS elements for inclusion in Metricly by creating or choosing an existing tag (key-value pair), then assigning that tag to the desired elements in AWS.\n  Step 1: Create a new AWS integration  From the top navigation menu, select Integrations.\n Click the Amazon Web Services card.\n Type a name for the new AWS integration. Ensure that Data Collection is selected.\n For AWS Authentication, select Access Key. If you want to create a role that has full access to your AWS data, expand the full permissions instructions and follow those. If you want to create a role that only has access to four AWS 7. elements, expand the modified permissions instructions and follow those.\n  Step 2a: Creating a Read Only User (with standard permissions)  Log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Once in the IAM dashboard, navigate to the Users section. Click Add user.\n For a User Name, type Metricly. Select the Programmatic access checkbox in the Select AWS access type section.\n Click Next: Permissions.\n Click Attach existing policies directly.\n Search “read only,” then select ReadOnlyAccess. You may need to change the Filter type to have the correct policy show.\n Click Next: Review.\n Review the details to ensure you’ve selected all the correct options for the user, and then click Create User.\n Download and/or copy the User Security Credentials.\n You will not be able to access the Secret Access Key again unless you download the credentials.\n Click Close.\n  Step 2b: Creating a Read Only User (with minimal permissions)  If you want to use a limited read only access policy, you’ll need to create a custom policy first. Log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Once in the IAM dashboard, navigate to the Policies section. Click Create Policy in the top left-hand corner. Click Select next to Create Your Own Policy. Type a Policy Name into the field. Type a description of the policy. Copy and paste the following code into the Policy Document section.\n  { \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Action\u0026quot;: [ \u0026quot;autoscaling:Describe*\u0026quot;, \u0026quot;ce:*\u0026quot;, \u0026quot;cloudwatch:Describe*\u0026quot;, \u0026quot;cloudwatch:Get*\u0026quot;, \u0026quot;cloudwatch:List*\u0026quot;, \u0026quot;dynamodb:Describe*\u0026quot;, \u0026quot;dynamodb:Get*\u0026quot;, \u0026quot;dynamodb:List*\u0026quot;, \u0026quot;ec2:Describe*\u0026quot;, \u0026quot;ec2:GetConsoleOutput\u0026quot;, \u0026quot;ecs:Describe*\u0026quot;, \u0026quot;ecs:List*\u0026quot;, \u0026quot;elasticache:Describe*\u0026quot;, \u0026quot;elasticache:List*\u0026quot;, \u0026quot;elasticloadbalancing:Describe*\u0026quot;, \u0026quot;elasticmapreduce:Describe*\u0026quot;, \u0026quot;elasticmapreduce:List*\u0026quot;, \u0026quot;iam:Get*\u0026quot;, \u0026quot;kinesis:DescribeStream\u0026quot;, \u0026quot;kinesis:Get*\u0026quot;, \u0026quot;kinesis:List*\u0026quot;, \u0026quot;lambda:List*\u0026quot;, \u0026quot;rds:Describe*\u0026quot;, \u0026quot;rds:ListTagsForResource\u0026quot;, \u0026quot;redshift:Describe*\u0026quot;, \u0026quot;s3:Describe*\u0026quot;, \u0026quot;s3:Get*\u0026quot;, \u0026quot;s3:List*\u0026quot;, \u0026quot;sqs:Get*\u0026quot;, \u0026quot;sqs:List*\u0026quot;, \u0026quot;tag:Get*\u0026quot; ], \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot; } ] }  Validate Policy  Click Validate Policy to ensure you’ve filled out each section properly.\n Click Create Policy. The policy will now be available under Customer Managed Policies.\n Return to the IAM dashboard and navigate to the Users section.\n Click Create New Users.\n For a User Name, type Metricly. Select the Programmatic access checkbox in the Select AWS access type section.\n Click Next: Permissions.\n Click Attach existing policies directly.\n Select the policy you created in step 1.7. It should be near the top of the list.\n Click Next: Review.\n Review the details to ensure you’ve selected all the correct options for the user, and then click Create User.\n Download and/or copy the User Security Credentials.\nYou will not be able to access the Secret Access Key again unless you download the credentials.\r Click Close.\n Copy and paste the Access Key ID and Secret Access Key for the desired read-only user into the appropriate fields on the AWS Setup page in Metricly.\n Include or exclude as many AWS element types as you want. ASG, EC2, EBS, ELB, RDS, and SQS are enabled by default; everything else is disabled by default.\nThe AWS SQS API limits responses to 1000 queues. Thus if your environment has 1000 or more queues, Metricly won’t gather queues that match your regex filter but exceed the 1000 queue limit.\r If you enable AWS Custom Metrics note that each category you create in Cloudwatch will create a matching element in Metricly. All the metrics under each category will be included in the corresponding element; this means, if you want the metrics divided amongst your dimensions (e.g., App1 errors, App2 errors, App3 errors), you’ll need to create separate categories for each element. To read more about creating and using custom Cloudwatch metrics, go here.\n  Optionally, filter elements or change the display name of your AWS instances.\n If you install our Linux agent or Windows agent on an EC2 server, the EC2’s power state (it will come in as the attribute hostRunning with a value of true or false) and tags are copied over to the corresponding Linux SERVER element / Windows WINSRV element. You can then use this information to create policies.\n  Click Save.\n  This integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/choose-scope/",
	"title": "Choose Scope",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#scope"],
	"description": "",
	"content": " The scope of a policy defines which element(s) get assigned to that policy. A policy can use a combination of criterion to narrow its selection; for example, all elements tagged with region-east + EC2 as a type.\nScope Methods When using multiple fields, an element must meet each criterion to be included in the policy’s scope.\nName Contains or Name Excludes  Input a string of characters into the Name Contains or Name Excludes field. The policy then includes (or excludes) all elements matching the input Name Excludes is located under More \u0026gt; Name Excludes  Element or Exclude Element  Search a drop-down list of all of your elements and check each to include (or exclude) all selections Input a string of characters to search  Type, Attribute, Tag, \u0026amp; More  Search a drop-down list of all each category and check all objects that apply to include them in the policy Input a string of characters to search  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/create-conditions/",
	"title": "Create Conditions",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#conditions"],
	"description": "",
	"content": " When you are creating conditions, the Policy Editor counts the number of metrics that apply to the conditions you have set. To view those metrics, click on the link. This link opens the list of matching metrics in a new tab.\nCreate a Metric Condition  Navigate to Alerts \u0026gt; New Policy \u0026gt; Conditions \u0026gt; Add Condition \u0026gt; Add Metric Condition.  To edit an existing policy, Navigate to Alerts \u0026gt; Show All Policies \u0026gt; Click Policy Name \u0026gt; Edit Policy \u0026gt; Conditions \u0026gt; Add Metric Conditions.  Select either the Single Metric or Regex radio button.  Single Metric: Choose a metric from the Metric drop-down menu. This is the metric to which the condition will apply. Regex: Begin typing into the field. Stop typing when you’ve found the desired matching metrics. Each matching metric used by the policy is joined by an OR, meaning that only a single metric has to trigger the policy, not all of the matching metrics.  Use the Metric Tags field to filter your condition (optional). Select the deviations you want to track. Click Save.  Adding Multiple Metric Conditions to a Policy? Use the Match Conditions feature to toggle between enforcing all conditions listed or just any one condition. See below:\nMetric Condition Deviation Types Baseline Deviation A Baseline Deviation test triggers an event and other optional notifications when the current value of a metric is above and/or below 4 standard deviations from its normal operating range. A Baseline Deviation test can also be used to trigger an event when the value of a metric is or is not deviating from its normal operating range. Metricly determines the normal operating range of a metric based on the history of the actual values for that metric. The different Baseline Deviation tests are described below:\n Upper (Baseline) Deviation: The current value of a metric is greater than or equal to 4 standard deviations above its normal operating range. Lower (Baseline) Deviation: The current value of a metric is greater than or equal to 4 standard deviations below its normal operating range. Is Deviating: The current value of a metric is greater than or equal to 4 standard deviations above or below its normal operating range. Is Not Deviating: The current value of a metric is not deviating.  Contextual Deviation A Contextual Deviation test can be used to indicate when the value of a metric is above and/or below 4 standard deviations from its expected value. A Contextual Deviation test can also be used to indicate when a metric is deviating when it should not be, or is not deviating when it should be. Metricly determines the expected value for a metric based on the actual values of other correlated metrics in the learned model. The different Contextual Deviation tests are described below:\n Upper (Contextual) Deviation: The current value of a metric is greater than or equal to 4 standard deviations above its expected value. Lower (Contextual) Deviation: The current value of a metric is greater than or equal to 4 standard deviations below its expected value. Is Deviating: The current value of a metric is greater than or equal to 4 standard deviations above or below its expected value. Is Not Deviating: The current value of a metric is not deviating.  Static Threshold A Static Threshold test is used to trigger an event and other optional actions when the value of a metric is more than, less than, equal to, or not equal to a specified level. The level for a Static Threshold test can be any real number; the unit of the level depends on the metric to which it is applied.\nFor example, you can use a Static Threshold test to execute an event when the current value for the metric “CPU Utilization” is greater than 95%.\nSudden Change Deviation A Sudden Change deviation test is used to indicate the difference between expected change and unexpected change on a certain metric. This is achieved by using historical data to predict future data intervals. The historical data used to determine the future interval is a sliding window of one hour that contextualizes future intervals.\nThe Analytics Engine uses the following steps to detect a sudden change:\n Collects the last N+1 observed PT5M values, including the most recent value. Applies a regression model to the N PT5M average values before the current one.  If the regression model is a good fit, then use it to forecast a projected value of the metric.  Compares the projected regression model value with the actual observed value.  This step determines whether the observed value is within the projected configurable range of confidence.  If observed value is within expected range, returns a result of NO CHANGE. If observed value is not within expected range, compute percent change.  Percent change = |(observed value - projected value)| / |projected value|\nMetric Threshold Metric thresholds are unchanging levels that are compared against another metric’s current value. A Metric Threshold test can be used to indicate when the value of the specified metric is more than, less than, equal to, or not equal to another metric.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/create-external-event-conditions/",
	"title": "Create External Event Conditions",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#conditions", "#external events", "#webhooks"],
	"description": "",
	"content": "External Event conditions for policies are typically used in conjunction with Webhook integrations. See the Webhook integration setup or Webhook API documentation for more information.\n Open Policy Editor. Click Conditions. Click Add Condition, then select Add External Event Condition.  Type into the fields to create a proper filter:  Message Contains: A regex statement that attempts to match a word or phrase in the event message. Title Contains: A regex statement that attempts to match a word or phrase in the event’s title. Source Contains: A regex statement that attempts to match a word or phrase in the event’s source. Level: What level of event should trigger this condition (Info, Warning, Critical).  After completing the remaining fields in Policy Editor, click Save.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/",
	"title": "Integrations",
	"tags": [],
	"description": "",
	"content": " An integration is a system from which Metricly collects data. Metricly offers integrations with collectors, agents, and automation software.\nCommon Dependencies OS  Redhat 6 and 7 CentOS 6 and 7 Amazon Linux (latest) Ubuntu 12, 14, 15, and 16 Debian 7, 8, and 9  Miscellaneous  Linux Agent  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-elastic-manual-install/",
	"title": "Manual Install",
	"tags": ["#agents", "#linux"],
	"description": "",
	"content": " Via RPM rpm --import https://repos.app.netuitive.com/RPM-GPG-KEY-netuitive rpm -ivh https://repos.app.netuitive.com/rpm/noarch/netuitive-repo-1-0.2.noarch.rpm yum -y install netuitive-agent  Via DEB curl -s https://repos.app.netuitive.com/netuitive.gpg | apt-key add -apt-get install -y apt-transport-https echo \u0026quot;deb https://repos.app.netuitive.com/deb/ stable main\u0026quot; \u0026gt; /etc/apt/sources.list.d/netuitive.list apt-get -y update apt-get install -y netuitive-agent  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/aws-detailed-billing/",
	"title": "Detailed Billing",
	"tags": ["#aws", "#detailed billing", "#s3 bucket"],
	"description": "",
	"content": " How to Enable Detailed Billing  If you already have an S3 bucket receiving billing files from Amazon, then you do not need to complete steps 1 and 2. You can go directly to step 3 to provide Metricly access to the existing files. If you have already created an S3 bucket, you will not need to create a separate one. Just be sure to select the correct S3 bucket in step 2.  1. Create an S3 Bucket  Log into AWS and navigate to the Services \u0026gt; S3.\n Click Create Bucket.\n Type a unique Bucket Name, select a region, and click Create.\n  2. Enable Detailed Billing Reports  In AWS, click your Username \u0026gt; My Billing Dashboard. Then in the left-hand menu, click Preferences.\n Select the Receive Billing Reports checkbox.\n In the Save to S3 Bucket field, enter the bucket name of the bucket you created in Step 1 and click Sample Policy.\n Copy the generated policy. In a new, separate tab, navigate to the S3 bucket you created in Step 1 (Services \u0026gt; S3 \u0026gt; Bucket Name). Navigate to the Permissions tab and click Bucket Policy. Paste the following policy and click Save:   { \u0026quot;Version\u0026quot;: \u0026quot;2008-10-17\u0026quot;, \u0026quot;Id\u0026quot;: \u0026quot;Policy1335892530063\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Sid\u0026quot;: \u0026quot;Stmt1335892150622\u0026quot;, \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;AWS\u0026quot;: \u0026quot;arn:aws:iam::386209384616:root\u0026quot; }, \u0026quot;Action\u0026quot;: [ \u0026quot;s3:GetBucketAcl\u0026quot;, \u0026quot;s3:GetBucketPolicy\u0026quot; ], \u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:s3:::metricly-example\u0026quot; }, { \u0026quot;Sid\u0026quot;: \u0026quot;Stmt1335892526596\u0026quot;, \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;AWS\u0026quot;: \u0026quot;arn:aws:iam::386209384616:root\u0026quot; }, \u0026quot;Action\u0026quot;: [ \u0026quot;s3:PutObject\u0026quot; ], \u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:s3:::metricly-example/*\u0026quot; } ] }   Return to the previous tab (Preferences section in the Billing \u0026amp; Cost Management page), and click Verify next to the Save to S3 Bucket field. For Amazon to correctly verify the bucket, the bucket must exist\u0026ndash;match the name you typed in the field\u0026ndash;and have appropriate permissions set (e.g., the sample policy you added in the previous step).\n Once your bucket is verified, select the check boxes within the Report section next to all of the reports, including Monthly report, Detailed billing report, Cost allocation report, and Detailed billing report with resources and tags.\n Optionally, click Manage report tags below the billing report options and enable all desired tags.\n Click Save Preferences. It can take up to 24 hours before files start arriving in the S3 bucket.\n  3. Update your AWS integration in Metricly  From the top navigation menu, select Integrations. Click the Amazon Web Services card. Toggle Detailed Billing and scroll to the final section.  Type the S3 bucket name into the corresponding field. The bucket name is case sensitive and must exactly match the bucket created in Step 1.\n Click Save.\n  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-elastic-beanstalk-install/",
	"title": "Elastic Beanstalk",
	"tags": ["#agents", "#linux", "#elastic beanstalk"],
	"description": "",
	"content": "Using an existing application file, you can deploy the Netuitive agent to a self-contained EC2 instance complete with a load balancer and everything else it needs to run. The Elastic Beanstalk instance can also scale by itself.\n Before creating your Elastic Beanstalk instance, find or create a folder called .ebextensions in your application’s directory. Copy the netuitive.config file to your .ebextensions folder. Replace the sample API key at the top of the netuitive.config file N_APIKEY=\u0026lt;datasource api key\u0026gt; as well as in the configuration portion of the file api_key = \u0026lt;datasource api key\u0026gt; with the Linux integration API key in your account. Either use the new application files to create a new Beanstalk environment or to update a current application version by replacing it.\n  Locating Your API key:\nTo find your API Key, navigate to the user account and select Integrations.\nYour Linux API key is found next to the integration listed as INFRASTRUCTURE. The default config file included in the netuitive.config file does not include any additional collector files yet (e.g, Flume, Elasticsearch, Kafka, etc.). The collector files can be added to and modified directly on each EC2, but those changes may not be persisted if your Beanstalk application is rebuilt.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/",
	"title": "Visualization",
	"tags": ["#getting started", "#directory page"],
	"description": "",
	"content": "afafa\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/",
	"title": "Agents",
	"tags": ["#agents", "#directory page"],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/aws-optional-config/",
	"title": "Optional Config",
	"tags": ["#aws", "#optional config", "#elements"],
	"description": "",
	"content": " Change Element Display Names You can change how certain elements’ names are displayed in the application to help distinguish between each instance, e.g., you have 15 EC2 instances with the same name and want to know the difference between each.\n Under the Include Types list, expand the desired type.\n Beneath the Tag Key field, click Advanced. A menu expands.\n Hover next to Element Name; an edit icon will appear. Click the icon.\n Type the desired name into the field.\n Select an element to use as a preview for your new element name using the Element To Preview drop-down menu.\n Next to the Element Name field, click Preview to view your new template using the selected element.\n If you’re satisfied with the name, press Enter on your keyboard while in the Element Name field to lock in the name.\n  Exit the integration setup page and wait until the next analytics cycle (5 minutes) to see your changes.\nNaming Tips When choosing a name, replace the following with underscores:\n(space) ! \u0026ldquo; # $ % \u0026amp; \u0026lsquo; ( ) * + , - . / : ; \u0026lt; = \u0026gt; ? @ [ \\ ] ^ _ { | } ~\n example.io/service-name should be ${tags.example_io_service_name}. Variables are compatible, but note that values in key.value pairs are case sensitive. Spaces and dots in any returned value are replaced with underscores.\n An element name of ${meta.originalName} would resolve to whatever name comes in with the original element payload before it would be replaced with the optional element name template.\n  The element name template preview in the UI will resolve this field to [original name] as a placeholder because Metricly only knows what the current name is, not what the incoming name might be.\n An AWS EC2 with element name of ${tags.Name} - (AZ:${attributes.availabilityZone}) would utilize each EC2 instance’s Name (from the tag value) and availability zone (from the attribute). An element name of ${tags.InternalName} (${tags.Name}) will give you something like MyServer (ip-10.101.3.99) An element name of ${tags.Name} (${attributes.availabilityZone}) would return something like ServerX (eu-west-1c)`  Example: Adding the Private IP Address to an Element Name Adding the private IP address to your element names enables your team to immediately begin troubleshooting problematic instances.\n\u0026lt;#if tags.Name??\u0026gt;${tags.Name}\u0026lt;#elseif tags.aws_autoscaling_groupName??\u0026gt;${tags.aws_autoscaling_groupName}\u0026lt;#else\u0026gt;${meta.originalName}\u0026lt;/#if\u0026gt;\u0026lt;#if attributes.privateIpAddress??\u0026gt; (${attributes.privateIpAddress})\u0026lt;/#if\u0026gt;  Filter AWS Elements You can filter what AWS elements are included in Metricly’s monitoring by using regex to match key-value pairs (ASG, EC2, EBS, ELB, RDS, Redshift, Elasticache, EMR), Namespace names (Custom Cloudwatch Metric), queue names (SQS), table names (DynamoDB), cluster names (ECS), function names (Lambda), or stream names (Kinesis). Metricly offers opt-in (include) or opt-out (exclude) element filtering. For more information about tagging elements in AWS, see the following AWS documentation.\nUsing opt-in filtering For key-value pairs (ASG, EC2, EBS, ELB, RDS, Redshift, Elasticache, EMR elements, ALB):\n In your AWS account, create or choose an existing tag (key-value pair). Then, assign the tag to the AWS elements you want Metricly to monitor. On the AWS Integration Setup page, expand the element types you want to filter. Key-value pair fields display.  Select the Filtering checkbox. Select Include. Type the proper Regex to match the tag(s) you created in your AWS account for each element type you want to filter. Click Save.  For names (Custom Cloudwatch, SQS, DynamoDB, Kinesis, ECS, Lambda elements, ALB): 1. Prepate the queue, table, or stream name(s) for the AWS element(s) you want to monitor. 2. On the AWS Integration Setup page, expand the element types you want to filter. Name fields display. 3. Select the Filtering checkbox. 4. Select Include. Type the name of the table, queue, or stream for each element type you want to filter. 5. Click Save.\nSay you want to filter out all Custom Cloudwatch Namespaces except for customnamespace1 and customnamespace2. You would put the following in the field: (customnamespace1|customnamespace2)\rRegex Examples The filtering fields append a .* to the front and back of each value input into the fields. For example, if you input .Prod-app1, it will be interpreted as .*.Prod-app1.*. We recommend testing any regular expressions that you create here.\n Match the start and end of the string contained between ^ and $. The following would match the key-value pair Metricly = true. Match multiple values separated by | between ( ). The following would match any of the following key-value pairs: Name = my-server-one, Name = my-server-two, Name = my-server-three. Match any character(s) using ., which acts as a wildcard. The following would match any value (e.g., Name = myProd-app-1, Name = yourProd-app-1) as long as Prod-app-1 followed. Escape special regex characters . * / using a /. The following would match the key-value pair Name = my.server.one. For a list of special regex characters you may have to escape, consult this page.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/",
	"title": "Reports",
	"tags": ["#reports", "#directory page"],
	"description": "",
	"content": " Reports provide a quick glance at some of the most important parts of your environment, including utilization, policy violation, and estimated cost of your inventory. Report Explorer allows you to toggle between different reports on the elements in your environment.\nRequired Integrations for Metricly Reports    Report Name AWS w/ Cost Explorer AWS w/ CloudWatch AWS Cost w/ Detailed Billing List Price Estimation w/out AWS Cost Time from activation to first report     AWS Services Cost x    Immediate   Resource Utilization  x   Immediate   EC2 Cost  x x x 1 day   RDS Cost  x x  1 day   S3 Cost  x x  1 day   EC2 Recommendations  x x x 1 week   ASG Recommendations  x x x 1 week    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-upgrade/",
	"title": "Upgrade",
	"tags": ["#agents", "#linux", "#upgrade"],
	"description": "",
	"content": "It’s important you upgrade to the latest version of the Linux Agent whenever possible, as we’re constantly improving it. Check out the recently closed issues and pull requests, as well as the release history, to see why you should upgrade.\n Stop the Linux Agent (use the appropriate command for your distro). The most common being:  service netuitive-agent stop /etc/init.d/netuitive-agent stop initctl stop netuitive-agent systemctl stop netuitive-agent  Run yum -y update netuitive-agent.  or apt-get update netuitive-agent or apt-get install --only-upgrade netuitive-agent If you have not customized the Netuitive configuration file in any way (other than inputting the API key), jump to step 6. If you’ve customized the configuration file, continue on.\r  Get the difference between the old configuration file netuitive-agent.conf and the new configuration file netuitive-agent.conf.rpmnew  diff -u /opt/netuitive-agent/conf/netuitive-agent.conf.rpmnew /opt/netuitiveagent/conf/netuitive-agent.conf  Copy your changes from the old file to new file. Rename the old file to netuitive-agent.conf.old and the new configuration file to netuitive-agent.conf. Start the Linux Agent. The most common commands being:  service netuitive-agent start /etc/init.d/netuitive-agent start initctl start netuitive-agent systemctl start netuitive-agent   You can delete the element in Metricly, and it will reappear after the next processing cycle. Your element will not lose any data.\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-collectors/",
	"title": "Collectors",
	"tags": ["#agents", "#linux", "#collectors"],
	"description": "",
	"content": " There are three ways to configure the Linux Agent default collectors: via the BaseCollector, as a combination of individual collectors, or with just the SimpleCollector. This guide outlines their differences and how to use each; however, we encourage you to try the new SimpleCollector.\nUsing the Simple Collector netuitive-diamond/src/collectors/simple\nWhere the base or individual collectors include more data (which may be less useful or actionable), this SimpleCollector guarantees a cleaner streamlined experience. The SimpleCollector can be activated by updating the /opt/netuitive-agent/conf/netuitive-agent.conf file.\nThe SimpleCollector collects a single metric for CPU, Mem, Disk I/O, and Disk Usage and is set to FALSE by default. It should not be used with any of the above collectors active. Here are the metrics collected by the SimpleCollector:\n CPU: cpu.total.utilization.percent MEM: memory.utilizationpercent Disk I/O: iostat.max_util_percentage Disk Space: diskspace.avg_byte_percentused  Using the BaseCollector netuitive-diamond/src/collectors/base\nThe BaseCollector is a compilation of all individual collectors bundled together and reports on all of their supported metrics. The base collector is set to TRUE by default and should not be used with any of the later mentioned diamond collectors active.\nCollectors are turned on or off by updating the /opt/netuitive-agent/conf/netuitive-agent.conf file.\nUsing Individual Collectors netuitive-diamond/src/collectors/*`\nEach individual collector can be turned on or off to get exactly what you want. Set to FALSE by default; should not be used with the base collector set to TRUE. These are the individual collectors:\n CPUCollector MemoryCollector LoadAverageCollector NetworkCollector DiskUsageCollector DiskSpaceCollector VMStatCollector  Some of the individual collectors have their own simple mode. This can be activated by updating the /opt/netuitive-agent/conf/netuitive-agent.conf file.\nConf File Example [[BaseCollector]] -enabled = False +enabled = True [[CPUCollector]] enabled = True simple = False percore = False include_cpu_pct = True [[DiskSpaceCollector]] enabled = True simple = True # exclude everything that begins /boot or /mnt exclude_filters = ^/boot, ^/mnt [[DiskUsageCollector]] enabled = True devices = (PhysicalDrive[0-9]+$|md[0-9]+$|sd[a-z]+$|x?vd[a-z]+$|disk[0-9]+$|dm\\-[0-9]+$|nvme[0-9]+(n[0-9]+)(p[0-9]+)?$) metrics_whitelist = (?:^.*\\.io$|^.*\\.average_queue_length$|^.*\\.await$|^.*\\.iops$|^.*\\.read_await$|^.*\\.reads$|^.*\\.util_percentage|^.*\\.write_await$|^.*\\.writes$) [[LoadAverageCollector]] enabled = True simple = False [[MemoryCollector]] enabled = True [[VMStatCollector]] enabled = True [[NetworkCollector]] enabled = True metrics_whitelist = (?:^.*\\.rx_byte$|^.*\\.rx_errors$|^.*\\.tx_byte$|^.*\\.tx_errors$) [[NetuitiveDockerCollector]] enabled = False  Collector Options    Collector Option Default Description     VM Stat metrics_whitelist None Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   VM Stat metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   VM Stat measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   VM Stat enabled TRUE Enable collecting VM Stat metrics.   VM Stat byte_unit byte Default numeric output(s).   Network metrics_whitelist (?:^.*.rx_byte$ ^.*.rx_errors$   Network metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   Network measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   Network interfaces eth, bond, em, p1p, eno, enp, ens, enx List of interface types to collect.   Network greedy FALSE Greedy match interfaces.   Network enabled TRUE Enable collecting Memory metrics.   Network byte_unit bit, byte, Default numeric output(s).   Memory metrics_whitelist None Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   Memory metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   Memory measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   Memory enabled TRUE Enable collecting Memory metrics.   Memory detailed FALSE Set to True to collect all nodes.   Memory byte_unit byte Default numeric output(s).   Load Avg. simple FALSE Reduces the amount of metrics collected to the bare minimum necessary.   Load Avg. metrics_whitelist None Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   Load Avg. metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   Load Avg. measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   Load Avg. enabled TRUE Enable collecting Load Average metrics.   Load Avg. byte_unit byte Default numeric output(s).   Heartbeat path metricly Path to the Metricly agent.   Heartbeat enabled TRUE Enable collected the Heartbeat metric.   Disk Usage send_zero FALSE Tells the collector to send IO data even when there is no IO.   Disk Usage sector_size 512 The size used to calculate sector usage.   Disk Usage metrics_whitelist (?:^.*.io$ ^.*.average_queue_length$   Disk Usage metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   Disk Usage measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   Disk Usage enabled TRUE Enable collecting Disk Usage metrics.   Disk Usage devices None Regex pattern to determine which device metrics to collect.   Disk Usage byte_unit byte Default numeric output(s).   Disk Space simple TRUE Reduces the amount of metrics collected to the bare minimum necessary. Switching simpleto False will allow inode metrics.   Disk Space metrics_whitelist None Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   Disk Space metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   Disk Space measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   Disk Space filesystems None Types of filesystems to examine.   Disk Space exclude_filters ^/boot, ^/mnt A list of regex patterns to exclude from collection.   Disk Space enabled TRUE Enable collecting Diskspace metrics.   Disk Space byte_unit byte Default numeric output(s).   CPU include_cpu_pct TRUE Includes the CPU percentage metric in collection.   CPU simple FALSE Enable returning only the aggregate CPU percentage metric.   CPU percore FALSE Enable collecting metrics per CPU core or just the total of the cores.   CPU normalize FALSE Enable dividing by the number CPUs for CPU totals.   CPU metrics_whitelist None Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   CPU metrics_blacklist None Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   CPU measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   CPU enabled TRUE Enable collecting CPU metrics.   CPU byte_unit byte Default numeric output(s).   CPU byte_unit byte Default numeric output(s).   CPU enabled TRUE Enable collecting CPU metrics.   CPU measure_collector_time FALSE Measure the collectorâ€™s run time in milliseconds.   CPU include_cpu_pct TRUE Includes the CPU percentage metric in collection.   Disk Space byte_unit byte Default numeric output(s).   Disk Usage byte_unit byte Default numeric output(s).   Heartbeat enabled TRUE Enable collected the Heartbeat metric.   Load Avg. byte_unit byte Default numeric output(s).   Memory byte_unit byte Default numeric output(s).   Network byte_unit bit, byte, Default numeric output(s).   VM Stat byte_unit byte Default numeric output(s).    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/aws-gov-cloud/",
	"title": "Gov Cloud",
	"tags": ["#aws", "#gov cloud"],
	"description": "",
	"content": " AWS GovCloud (US) is a segment of Amazon Web Services cloud offerings that restrict physical and logical administrative access to U.S. citizens only. The region meets the requirements for U.S. International Traffic in Arms Regulations (ITAR), and allows users to move Controlled Unclassified Information (CUI) into the cloud. Check out our blog post, Monitor AWS GovCloud With Metricly, or the official AWS Guide for more information.\nConfiguration Leave GovCloud disabled unless you have signed up for and are using a GovCloud-restricted AWS account.\r Log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Navigate to the Users section and Add User. For User Name, input Metricly. In the Select AWS Access Type section, enable Programmatic Access. Add Read Only permissions to the user. Copy the User Security Credentials. These will be used in Metricly. Open Metricly and navigate to Integrations \u0026gt; AWS. Select the relevant AWS account. Toggle In GovCloud to enable. Input the AWS Access Key and AWS Secret Access Key. Click Save.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-common-commands/",
	"title": "Common Commands",
	"tags": ["#agents", "#linux", "#commands"],
	"description": "",
	"content": " These commands may vary depending on your distro.\rLinux Commands  service netuitive-agent {stop|start|restart}\n /etc/init.d/netuitive-agent {stop|start|restart}\n initctl {stop|start|restart} netuitive-agent\n systemctl {stop|start|restart} netuitive-agent\n  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-optional-config/",
	"title": "Optional Config",
	"tags": ["#agents", "#linux", "#elements", "#FQNs"],
	"description": "",
	"content": " Changing Element Display Names You can change the display name of certain elements to help distinguish between each instance.\n Navigate to Integrations \u0026gt; Linux Integration. Click Advanced; a menu expands.  Click the Element Name field to edit it. Type the desired name into the field.  An element name of ${meta.originalName} would resolve to whatever name comes in with the original element payload before it would be replaced with the optional element name template. The element name template preview in the UI will resolve this field to [original name] as a placeholder because Metricly only knows what the current name is, not what the incoming name might be. An element name of ${tags.InternalName} (${tags.Name}) will give you something like MyServer (ip-10.101.3.99) An element name of ${tags.Name} (${attributes.availabilityZone) would return something like ServerX (eu-west-1c)  Select an element to use as a preview for your new element name using the Element To Preview drop-down menu. Next to the Element Name field, click Preview to view your new template using the selected element. If you’re satisfied with the name, press Enter on your keyboard while in the Element Name field to lock in the name. Exit the integration setup page and wait until the next analytics cycle (5 minutes) to see your changes.  Example: Adding the Private IP Address to an Element Name Adding the private IP address to your element names enables your team to immediately begin troubleshooting problematic instances.\n\u0026lt;#if tags.Name??\u0026gt;${tags.Name}\u0026lt;#elseif tags.aws_autoscaling_groupName??\u0026gt;${tags.aws_autoscaling_groupName}\u0026lt;#else\u0026gt;${meta.originalName}\u0026lt;/#if\u0026gt;\u0026lt;#if attributes.privateIp??\u0026gt; (${attributes.privateIp})\u0026lt;/#if\u0026gt; {noformat}  Write Metric FQNs to Local File If you want to keep a local file with a list of metric FQNs (fully qualified names), you can do so by updating the below lines in your netuitive-agent.conf file, under the [[NetuitiveHandler]]. By default, this ability is set to False. When set to True, this file updates with any new FQNs as long as the agent is running.\nIf the agent is started and write_metric_fqns is set to True, the file is overwritten; it remains unchanged if set to False before starting the agent.\nTo Enable:\n Open your netuitive-agent.conf file.\n Change write_metric_fqns = False to True.\n Confirm your desired path (metric_fqns_path) for the file.\n Save.\n  Update the Hostname Manually If you’re having issues with the default naming method or the hostname isn’t what you desire, you can manually set the hostname via the agent’s configuration file located at /opt/netuitive-agent/conf/netuitive-agent.conf. Consult the table below for more information.\n   Method Description Usage     Hard-coded Force a hard-coded desired hostname. Uncomment the hostname setting. # hostname = my_custom_hostname Replace my_custom_hostname with your desired hostname, keeping in mind that periods are common separators.   smart The agent will initially try to use the short FQDN (fully qualifieddomain name). If the short FQDN is “localhost”, the agent will use the value returned by the hostname -s command. Because smart is the default naming method, do not make changes to this section of the configuration file to continue using it.   fqdn (fully qualifed domain name) Comprises three separate methods:fqdn_short, which is similar to the value returned by the hostname -scommand. fqdn, which is the fullhostname value. fqdn_rev, which is the full hostname value but reversed, e.g., com.example.www. Uncomment the hostname_method setting. # hostname_method = smart Replace smart with the desired fqdn setting. hostname_method = fqdn_rev   uname Comprises two methods:uname_short, which is similar to the value returned by the uname -n (network node hostname) command but only the first portion. uname_rev, which is the value returned by the uname -r (kernel release) command but reversed, e.g., com.example.www. Uncomment the hostname_method setting. Replace smart with the desired uname setting. hostname_method = uname_short   hostname Comprises three separate methods:hostname_short, which is the value returned by the hostname -scommand. hostname, which is the full hostname value. hostname_rev, which is the full hostname value but reversed, e.g., com.example.www. Uncomment the hostname_method setting. # hostname_method = smart Replace smart with the desired hostnamesetting. hostname_method = hostname   shell Uses the string set in the hard-coded hostname variable as ashell command. The agent will use its output (with spaces trimmed from both ends) as the hostname. Uncomment the hostname setting. # hostname = my_custom_hostname Replace my_custom_hostname with your desired shell command. For example, with the following shell command you can use the AWS metadata endpoint to retrieve the instanceId and ensure uniqueness. hostname = curl -sS \u0026quot;http://169.254.169.254/latest/meta-data/instance-id\u0026quot;    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-disable/",
	"title": "Disable",
	"tags": ["#agents", "#linux"],
	"description": "",
	"content": "If you need to disable an existing Linux integration or view the unique API key assigned to your account:\n Navigate to User Profile \u0026gt; Integrations. Find the Integration with an Integration Type of Infrastructure. Click its name. Toggle Data Collection to disable it.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-remove/",
	"title": "Remove",
	"tags": ["#agents", "#linux", "#upgrade"],
	"description": "",
	"content": " Stop the Linux Agent (use the appropriate command for your distro). The most common being:  service netuitive-agent stop /etc/init.d/netuitive-agent stop initctl stop netuitive-agent systemctl stop netuitive-agent  Remove the directory containing the Linux Agent. Default: rm -r /opt/netuitive-agent.  If you don’t want to be prompted for each file that needs to be deleted, use rm -rf /opt/netuitive-agent   "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/linux-troubleshooting/",
	"title": "Troubleshooting",
	"tags": ["#agents", "#linux", "#logs", "#metadata"],
	"description": "",
	"content": " Set Logs to Debugging Mode To set the Linux Agent logs to Debugging Mode, update the netuitive-agent.conf file.\n Navigate to the netuitive-agent.conf file. Update level = INFO to level = DEBUG. Save and restart your agent.  # to increase verbosity, set DEBUG level = DEBUG handlers = rotated_file propagate = 1  Need Help? 1. Save as Zip File Copy /opt/netuitive-agent/bin/get-support and paste it into your command line interface to zip up your agent configurations, logs, and system metadata. The file will be stored in /opt/netuitive-agent/\nSuccess Message:\nCollecting logs and configuration.... creating file.... Please open a support case and upload /opt/netuitive-agent/support-YYYYMMDD_173454 with a detailed description of the issue. Thank you  2. Send Zip to Support Open a support ticket by emailing support@metricly.com with the file attached and a subject / message body describing the issue(s) you experienced.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/_header/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Metricly Help This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here. This page is going to be full of random things until I decide what kind of content should go here.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/access-key/",
	"title": "#Access Key",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/agents/",
	"title": "#Agents",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/alb/",
	"title": "#Alb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/alerts/",
	"title": "#Alerts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/anake/",
	"title": "#Anake",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/analytics/",
	"title": "#Analytics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/ansible/",
	"title": "#Ansible",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/apache/",
	"title": "#Apache",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/asg/",
	"title": "#Asg",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/aws/",
	"title": "#Aws",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/azure/",
	"title": "#Azure",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/bacon/",
	"title": "#Bacon",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/beef/",
	"title": "#Beef",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/bulk-actions/",
	"title": "#Bulk Actions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cassandra/",
	"title": "#Cassandra",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/charts/",
	"title": "#Charts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/checks/",
	"title": "#Checks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/chef/",
	"title": "#Chef",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cli/",
	"title": "#Cli",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cloudformation-script/",
	"title": "#Cloudformation Script",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cloudwatch/",
	"title": "#Cloudwatch",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cluster/",
	"title": "#Cluster",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/collectd/",
	"title": "#Collectd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/collectors/",
	"title": "#Collectors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/commands/",
	"title": "#Commands",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/conditions/",
	"title": "#Conditions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/configuration-management/",
	"title": "#Configuration Management",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/consul/",
	"title": "#Consul",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cost/",
	"title": "#Cost",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cost-explorer/",
	"title": "#Cost Explorer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/cpu/",
	"title": "#Cpu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/custom-checks/",
	"title": "#Custom Checks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/custom-metrics/",
	"title": "#Custom Metrics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/dashboards/",
	"title": "#Dashboards",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/default-policies/",
	"title": "#Default Policies",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/delete/",
	"title": "#Delete",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/detailed-billing/",
	"title": "#Detailed Billing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/df/",
	"title": "#Df",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/diamond/",
	"title": "#Diamond",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/directory/",
	"title": "#Directory",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/directory-page/",
	"title": "#Directory Page",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/disk/",
	"title": "#Disk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/diskspace/",
	"title": "#Diskspace",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/docker/",
	"title": "#Docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/dropwizard/",
	"title": "#Dropwizard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/duration/",
	"title": "#Duration",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/dynamodb/",
	"title": "#Dynamodb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/ebs/",
	"title": "#Ebs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/ec2/",
	"title": "#Ec2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/ecs/",
	"title": "#Ecs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/efs/",
	"title": "#Efs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elastic-beanstalk/",
	"title": "#Elastic Beanstalk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elasticache/",
	"title": "#Elasticache",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elasticsearch/",
	"title": "#Elasticsearch",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elastisearch/",
	"title": "#Elastisearch",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elb/",
	"title": "#Elb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elements/",
	"title": "#Elements",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/elit/",
	"title": "#Elit",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/email/",
	"title": "#Email",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/events/",
	"title": "#Events",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/external-events/",
	"title": "#External Events",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/flume/",
	"title": "#Flume",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/fqns/",
	"title": "#Fqns",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/getting-started/",
	"title": "#Getting Started",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/gov-cloud/",
	"title": "#Gov Cloud",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/hipchat/",
	"title": "#Hipchat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/http/",
	"title": "#Http",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/http-code/",
	"title": "#Http Code",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/httpd/",
	"title": "#Httpd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/iam-role/",
	"title": "#Iam Role",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/idle-resources/",
	"title": "#Idle Resources",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/indices/",
	"title": "#Indices",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/install/",
	"title": "#Install",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/installation/",
	"title": "#Installation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/integrations/",
	"title": "#Integrations",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/interface/",
	"title": "#Interface",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/inventory-page/",
	"title": "#Inventory Page",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/iris/",
	"title": "#Iris",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/java/",
	"title": "#Java",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/kafka/",
	"title": "#Kafka",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/knesis/",
	"title": "#Knesis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/kubernetes/",
	"title": "#Kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/lambda/",
	"title": "#Lambda",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/linux/",
	"title": "#Linux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/load/",
	"title": "#Load",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/load-average/",
	"title": "#Load Average",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/logs/",
	"title": "#Logs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/lorem/",
	"title": "#Lorem",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/maintenance/",
	"title": "#Maintenance",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/memory/",
	"title": "#Memory",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/metadata/",
	"title": "#Metadata",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/metrics/",
	"title": "#Metrics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/microsoft/",
	"title": "#Microsoft",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/microsoft-iis/",
	"title": "#Microsoft Iis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/microsoft-net/",
	"title": "#Microsoft Net",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/microsoft-sql/",
	"title": "#Microsoft Sql",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/microsoft-teams/",
	"title": "#Microsoft Teams",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/mongodb/",
	"title": "#Mongodb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/mq/",
	"title": "#Mq",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/mute/",
	"title": "#Mute",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/mysql/",
	"title": "#Mysql",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/nagios/",
	"title": "#Nagios",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/netuitive/",
	"title": "#Netuitive",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/netuitive-statsd/",
	"title": "#Netuitive Statsd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/network/",
	"title": "#Network",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/ngnix/",
	"title": "#Ngnix",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/nlb/",
	"title": "#Nlb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/node.js/",
	"title": "#Node.js",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/notifications/",
	"title": "#Notifications",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/opsgenie/",
	"title": "#Opsgenie",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/optional-config/",
	"title": "#Optional Config",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/php/",
	"title": "#Php",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/plugins/",
	"title": "#Plugins",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/policies/",
	"title": "#Policies",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/postresql/",
	"title": "#Postresql",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/powerdns/",
	"title": "#Powerdns",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/process-resource-collector/",
	"title": "#Process Resource Collector",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/processes/",
	"title": "#Processes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/puppetdb/",
	"title": "#Puppetdb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/python/",
	"title": "#Python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/rabbitmq/",
	"title": "#Rabbitmq",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/rds/",
	"title": "#Rds",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/redis/",
	"title": "#Redis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/redshift/",
	"title": "#Redshift",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/regex/",
	"title": "#Regex",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/reports/",
	"title": "#Reports",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/riemann/",
	"title": "#Riemann",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/ruby/",
	"title": "#Ruby",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/s3/",
	"title": "#S3",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/s3-bucket/",
	"title": "#S3 Bucket",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/salt/",
	"title": "#Salt",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/scope/",
	"title": "#Scope",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/sensu/",
	"title": "#Sensu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/slack/",
	"title": "#Slack",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/snmp/",
	"title": "#Snmp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/sns/",
	"title": "#Sns",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/solr/",
	"title": "#Solr",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/sqs/",
	"title": "#Sqs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/statsd/",
	"title": "#Statsd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/stride/",
	"title": "#Stride",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/tags/",
	"title": "#Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/tcp/",
	"title": "#Tcp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/threadpool/",
	"title": "#Threadpool",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/tomcat/",
	"title": "#Tomcat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/uninstall/",
	"title": "#Uninstall",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/upgrade/",
	"title": "#Upgrade",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/uptime/",
	"title": "#Uptime",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/user-guide/",
	"title": "#User Guide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/user-scripts/",
	"title": "#User Scripts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/victorops/",
	"title": "#Victorops",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/voluptatibus/",
	"title": "#Voluptatibus",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/webhook/",
	"title": "#Webhook",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/webhooks/",
	"title": "#Webhooks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/widgets/",
	"title": "#Widgets",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/windows/",
	"title": "#Windows",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-alb/",
	"title": "ALB Metrics",
	"tags": ["#aws", "#metrics", "#alb"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) AWS Metric Statistic Sparse Data Strategy (SDS) BASE     Active Connection Count aws.applicationelb.activeconnectioncount ActiveConnectionCount sum none yes   Client TLS Negotiation Error Count aws.applicationelb.clienttlsnegotiationerrorcount ClientTLSNegotiationErrorCount sum none yes   Consumed LCUs aws.applicationelb.consumedlcus ConsumedLCUs sum none no   Healthy Host Count aws.applicationelb.healthyhostcount HealthyHostCount average none yes   HTTP Code ELB 4XX Count aws.applicationelb.httpcode_elb_4xx_count HTTPCode_ELB_4XX_Count sum ReplaceWithZero yes   HTTP Code ELB 5XX Count aws.applicationelb.httpcode_elb_5xx_count HTTPCode_ELB_5XX_Count sum ReplaceWithZero yes   HTTP Code Target 2XX Count aws.applicationelb.httpcode_target_2xx_count HTTPCode_Target_2XX_Count sum ReplaceWithZero yes   HTTP Code Target 3XX Count aws.applicationelb.httpcode_target_3xx_count HTTPCode_Target_3XX_Count sum ReplaceWithZero yes   HTTP Code Target 4XX Count aws.applicationelb.httpcode_target_4xx_count HTTPCode_Target_4XX_Count sum ReplaceWithZero yes   HTTP Code Target 5XX Count aws.applicationelb.httpcode_target_5xx_count HTTPCode_Target_5XX_Count sum ReplaceWithZero yes   New Connection Count aws.applicationelb.newconnectioncount NewConnectionCount sum none yes   Processed Bytes aws.applicationelb.processedbytes ProcessedBytes sum none yes   RequestCount aws.applicationelb.requestcount RequestCount sum ReplaceWithZero yes   Request Count Per Target aws.applicationelb.requestcountpertarget RequestCountPerTarget average none yes   Rule Evaluations aws.applicationelb.ruleevaluations RuleEvaluations average none yes   Target Connection Error Count aws.applicationelb.targetconnectionerrorcount TargetConnectionErrorCount sum ReplaceWithZero yes   Target Response Time aws.applicationelb.targetresponsetime TargetResponseTime average ReplaceWithZero yes   Unhealthy Host Count aws.applicationelb.unhealthyhostcount UnHealthyHostCount average none yes    Computed    Fully Qualified Name (FQN) Description Units BASE     netuitive.aws.alb.totaltargethttperrors Total Target HTTP Errors count yes   netuitive.aws.alb.totalelbhttperrors Total ALB HTTP Errors count yes   netuitive.aws.alb.httpcodeelberrorpercent ALB HTTP Error Percent percent yes   netuitive.aws.alb.unhealthyhostpercent Unhealthy Host Percent count yes   netuitive.aws.alb.requestspersecond Requests per Second operations yes   netuitive.aws.alb.httpcodeelb4xxerrorpercent ELB HTTP 4xx Error Percent percent yes   netuitive.aws.alb.httpcodeelb5xxerrorpercent ELB HTTP 5xx Error Percent percent yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/ruby-agent-api-options/",
	"title": "API Options",
	"tags": ["#ruby", "#integrations", "#agents"],
	"description": "",
	"content": " Log properties  logLocation: The absolute path of the log file. Leave this option blank to use the default location in the gem directory. logAge: Specify either the number of log files to keep or the frequency of rotation (daily, weekly, or monthly). logSize: Specify the maximum log file size (in bytes). debugLevel: Options include (in ascending order of severity) error, info, and debug.  Netuitived Connection Properties Netuitived address and port information.\nCache Properties The cache settings are related to the threads and events on your host ruby application. It allows for a small buffer to limit the amount of calls made to the daemon. The main purpose is to cache enough data to not have excessive thread growth when making calls to the daemon.\n sampleCacheEnabled: Set to true to enable the sample cache. sampleCacheSize: The maximum number of samples cached before the samples are sent to netuitived. sampleCacheInterval: Interval (in seconds) at which the cached samples are sent to netuitived. eventCacheEnabled: Set to true to enable the sample cache. eventCacheSize: The maximum number of events cached before the events are sent to netuitived. eventCacheInterval: Interval (in seconds) at which the cached events are sent to netuitived.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-asg/",
	"title": "ASG Metrics",
	"tags": ["#aws", "#metrics", "#asg"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) AWS Metric Statistic Units Max BASE CORR UTIL     CPU Credit Balance aws.ec2.cpucreditbalance CPUCreditBalance average  none yes no no   CPU Credit Usage aws.ec2.cpucreditusage CPUCreditUsage sum  none yes no no   CPU Utilization Percent aws.ec2.cpuutilization CPUUtilizationPercent average percent 100 yes yes yes   Ephemeral Disk Read Bytes aws.ec2.diskreadbytes DiskReadBytes sum bytes none no no no   Ephemeral Disk Read Ops aws.ec2.diskreadops DiskReadOps sum  none no no no   Ephemeral Disk Write Bytes aws.ec2.diskwritebytes DiskWriteBytes sum bytes none no no no   Ephemeral Disk Write Ops aws.ec2.diskwriteops DiskWriteOps sum  none no no no   Network Bytes In Counter aws.ec2.networkin NetworkIn sum bytes none no no no   Network Bytes Out Counter aws.ec2.networkout NetworkOut sum bytes none no no no   Status Check Failed aws.ec2.statuscheckfailed StatusCheckFailed sum  5 no no no   Status Check Failed – Instance aws.ec2.statuscheckfailed_instance StatusCheckFailed_Instance sum  5 no no no   Status Check Failed – System aws.ec2.statuscheckfailed_system StatusCheckFailed_System sum  5 no no no   RequestCount aws.applicationelb.requestcount RequestCount sum ReplaceWithZero yes no no no   Request Count Per Target aws.applicationelb.requestcountpertarget RequestCountPerTarget average none yes no no no   Rule Evaluations aws.applicationelb.ruleevaluations RuleEvaluations average none yes no no no   Target Connection Error Count aws.applicationelb.targetconnectionerrorcount TargetConnectionErrorCount sum ReplaceWithZero yes yes no no   Target Response Time aws.applicationelb.targetresponsetime TargetResponseTime average ReplaceWithZero yes yes no no   Unhealthy Host Count aws.applicationelb.unhealthyhostcount UnHealthyHostCount average none yes yes no no    Computed    Fully Qualified Name (FQN) Description Units BASE CORR Related Global Policies     netuitive.aws.autoscaling.grouptotalinstrances This is currently available as an attribute, but making it a metric allows Metricly to graph it over time. Customers with detailed monitoring enabled will already get this information in a collected metric (aws.autoscaling.grouptotalinstances), so this is primarily tobenefit customers without detailed monitoring.Computation:attribute[‘totalinstances’].value Count yes no    netuitive.aws.ec2.diskreadbytespersec This metric expresses the number of bytes read per second from the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk read activity.Computation:metricly.aws.ec2.diskreadbytespersec / 300 bytes/second yes yes    netuitive.aws.ec2.diskwritebytespersec This metric expresses the number of bytes written per second to the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk write activity.Computation:metricly.aws.ec2.diskwritebytespersec / 300 bytes/second yes yes    netuitive.aws.ec2.diskreadopspersec This metric expresses the number of read operations per second from the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk read activity.Computation:metricly.aws.ec2.diskreadopspersec / 300 operations/second yes yes Elevated ASG Ephemeral Disk Activity   netuitive.aws.ec2.diskwriteopspersec This metric expresses the number of write operations per second to the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk write activity.Computation:metricly.aws.ec2.diskwriteopspersec / 300 operations/second yes yes Elevated ASG Ephemeral Disk Activity   netuitive.aws.ec2.disktotalops This metric expresses the total number of read and write operations against the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk I/O activity.Computation:metricly.aws.ec2.diskreadops + metricly.aws.ec2.diskwriteops operations yes no    netuitive.aws.ec2.diskiops This metric expresses the total IOPS performed against the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk I/O activity.Computation:(metricly.aws.ec2.disktotalops) / 300 operations/second no no    netuitive.aws.ec2.bytesinpersec This metric expresses the number of network bytes received per second by an EC2 instance. This metric is useful for monitoring network receive activity.Computation:netutitive.aws.ec2.networkin / 300 bytes/second yes yes Elevated ASG CPU Activity (Normal Network Activity) Elevated ASG Network Activity   netuitive.aws.ec2.bytesoutpersec This metric expresses the number of network bytes written per secondby an EC2 instance. This metric is useful for monitoring networktransmit activity.Computation:metricly.aws.ec2.networkout / 300 bytes/second yes yes Elevated ASG CPU Activity (Normal Network Activity) Elevated ASG Network Activit    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-asg-recommendations/",
	"title": "ASG Recommendations",
	"tags": ["#reports", "#asg"],
	"description": "",
	"content": " The Auto Scaling Group (ASG) Recommendations report provides a summary of the EC2 instance hours managed by all of your Auto Scaling Groups over the past few weeks. The data is summarized by hour and day for the preceding one-to-four weeks depending on how long Metricly has been monitoring the ASG.  Total Instance Count graph: This graph depicts the average total number of instances managed by all of your ASG(s) by hour and day. It also shows the maximum and minimum total instance counts observed by hour and day. Auto Scaling Groups table: This table summarizes the observed EC2 instance counts managed by your ASGs, including Estimated Cost, Minimum Instances Seen, Minimum Instances Allowed, Maximum Instances Seen, Maximum Instances Allowed, Instance Hours, whether the Recommended Instance Count Metric is enabled, Instance Type, Region, whether the ASG is using Spot Instances, the Platform on each ASG, and the type of Tenancy. Use the filters at the top of the page to filter the elements displayed in the table/graph. Element Usage Summary: The number on the left is the number of ASGs monitored by Metricly for which there is sufficient data to produce the report. Some ASGs that are monitored by Metricly may be missing from the report if there is less than a week of data available for them. The number on the right is the total average EC2-instance hours across all of your ASGs.  The maximum number of instance hours in a week for a single EC2 instance is 168. So an ASG with 2 instances active for an entire week will contribute 336 instance-hours to the total.\n\rTuning your ASGs By analyzing the instance count and the CPU utilization across managed instances over several weeks, the ASG Recommendations report can provide simple recommendations to help you right-size each ASG to match the observed and expected load. You can use the ASG Recommendations report to try out different settings, from aggressively minimized to more conservative instance counts to see how this might affect the overall utilization and EC2 costs.\nOpening the Tuning Settings  Navigate to Reports \u0026gt; ASG. In the Auto Scaling Groups table, click one of the Element names. A menu will appear. Click Tune Auto Scaling Group. You can now tune the ASG as you wish using the settings in the left menu.  Refer to the image above when reading the following sections.\n(1) Historical Charts These charts let you visualize the historical behavior of the ASG. The Historical Instance Count chart displays the average instance count (and max/min instance count range) for the ASG over the last one-to-four weeks (depending on the available data). The Historical Utilization chart displays the average utilization across the EC2 instances managed by the selected ASG over the same period.\n(2) Projected Charts The Tuned Instance Count chart shows the recommended instance count for the ASG by hour of day as determined from the historical utilization, historical instance count, and the selected tuning settings (see below). The Projected Tuned Utilization chart shows the expected average CPU utilization across the instances managed by the ASG based upon the recommended hourly instance counts.\n(3) Tuning Settings You can try different tuning settings to do a what-if analysis on the ASG. The tuning settings directly control the Tuned Instance Count and Projected Tuned Utilization charts. The settings are:\n Utilization Statistic: The utilization statistic used to tune the instance count. Using the maximum utilization is the most conservative, as the target should never exceed the value. The other settings here are increasingly more aggressive the further the setting is away from the maximum average utilization, e.g., 80th Percentile signifies that the utilization should exceed the target utilization 20% of the time. Target Utilization: The target average utilization across the EC2 instances manged by the ASG. A higher target will result in smaller number of instances with a higher average utilization. Maximum Scale-In Rate: Controls the rate at which the instance count can reduce. A higher scale-in rate results in a tighter profile and a lower overall instance count. For example, if your usage profile is fixed in time it may be acceptable to scale-in abruptly when a period of heavy load stops. Conversely, if your usage profile is more fluid, it may be more appropriate to slowly decrease the number of instances in case of lag in the load. Scale-out Early: If the utilization is expected to rise in the next hour, the setting increases the instance count early to allow for provisioning time and variances in the time of utilization increase. Minimum Instance Count: This is a hard lower limit on the number of instances the ASG should maintain at all times. If you allow the ASG to scale-in to zero instances, an additional Zero Utilization Threshold setting is enabled. Update frequency: This setting controls how often the instance count should update. The default is hourly, which gives the optimal tuning results. The weekly setting calculates the peak instance count needed and uses this value for the entire week. The daily setting calculates the peak instance count needed each day and uses this for the entire day.  (4) Tuning Model The Aggressive and Conservative options apply default presets to the tuning settings. The Aggressive profile aims for a high utilization and low instance count. The Conservative profile aims for a lower utilization with allowances for scaling out early. Note that the aggressive profile is not the most aggressive nor is the conservative profile the most conservative combination of settings. The individual tuning options can be refined after choosing a preset. Changing any of the tuning settings will automatically change the tuning model to Custom.\n(5) Estimated Cost / Projected Savings This section shows the estimated historical cost over the observed period. Click the expand icon to show additional data about the instance and observed period. To the right of the Estimated Historical cost is the Projected savings (percent change) and cost if you were to implement the Tuning Settings on the left. Clicking the expand icon on the Estimated Historical Cost drop-down will also show additional information about the projection.\n(6) Recommended Instance Count Click Activate to enable the Recommended Instance Count metric.\nEnabling the Recommended Instance Count metric After reviewing tuning settings and choosing a recommended instance count profile that you are happy with, you can enable the instance count profile as a metric on the ASG available for use in dashboards, policies, etc.\n Adjust the tuning settings and/or choose a preset as necessary. Click Activate Settings (or Update Settings if you’ve already activated settings but made additional changes). It may take a few minutes, but the Recommended Instance Count metric will now be available on the selected ASG element.  You can disable the metric by clicking Deactivate Settings.\n\rTips Creating a Recommended Instance-related policy You can use the Recommended Instance Count in a policy to adjust an ASG instance to the desired value.\n Enable the Recommended Instance Count metric (if it’s not enabled already). It may take a few minutes to appear, but the Recommended Instance Count metric (metricly.aws.autoscaling.recommendedinstances) is now available on the selected element. Navigate to the Policies page, and click New Policy. Set the scope of the policy to the desired ASG instance(s). Click the Conditions tab. For the condition, set the Metric field to metricly.aws.autoscaling.grouptotalinstances.  Select the Metric Threshold checkbox under Deviation(s), set the drop-down to Not Equal To, and set the metric field to metricly.aws.autoscaling.recommendedinstances.  Click the Actions tab. Select a category and add a desired notification so you’ll be notified whenever the metric metricly.aws.autoscaling.grouptotalinstances has a different value than metricly.aws.autoscaling.recommendedinstances.  You can now use this notification in a script to adjust your instance count as performance needs fluctuate.\nGeneral Tips  If you currently have a fixed instance count for your ASG and cannot scale every hour, consider setting the Update Frequency to daily or weekly—this can often still provide considerable savings. Change the Utilization Metric setting to see the statistic within the minimum/maximum range in the historical utilization chart. For instance, if the 95th percentile utilization is much lower than the maximum utilization it demonstrates greater volatility. If the Utilization Metric is set to 80th percentile, then we expect the projected CPU utilization to exceed the target 20% of the time. If the Target Utilization is high, it is possible that the projected CPU utilization will exceed 100%. This indicates that the settings are incompatible, and it is recommend that you use a higher utilization statistic, such as the 95th percentile or maximum. The report can sometimes recommend an increase in the instance count. This typically occurs if the historical utilization is higher than the target utilization. This is not a problem but simply indicates that you may want to increase the instance count in your ASG to meet your utilization goal. You can zoom in on any of the graphs by clicking and dragging across a section of the graph (similarly to zooming in on the Event Explorer graph).  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/",
	"title": "AWS",
	"tags": ["#aws", "#detailed billing", "#iam role", "#cost explorer"],
	"description": "",
	"content": " The Amazon Web Services (AWS) Integration allows performance data to be collected at regular intervals from AWS for analysis in Metricly.\nMetrics\nFor a list of collected and computed metrics, visit our Metrics List.\nDependencies\nMust have access to an AWS account and CloudWatch metrics.\n   ASG EC2 EBS     ELB RDS SQS   DynamoDB Kinesis Stream Redshift   ElastiCache EMR ECS   Lambda Custom CloudWatch Metric S3 Bucket   Application Load Balancer Target Group MQ Broker    Prerequisite: Enable Cost Explorer Regardless of the installation method used below, Cost Explorer must be enabled from the master billing account–even if set up on a sub-account. IAM Roles set up with the master billing account allow Metricly to present reports spanning all of your accounts; IAM Roles set up with a sub-account only reports cost for that one account.\n Log in to your AWS master billing account. Navigate to Cost Explorer. Click Enable Cost Explorer.  The API is now available for use but has no data; you can request up to a year of cost billing data from AWS.  Installation Methods The Access Key Method is no longer recommended; AWS recommends always using IAM Roles. Check out AWS’s Security Best Practices for more information.\n CloudFormation Script\n IAM Method\n Access Keys\n  Plan to Create Multiple AWS Integrations? You can create multiple AWS integrations if you wish. If you haven’t created an AWS integration yet, continue with the installation instructions.\nCreate Additional AWS Integrations If you’ve already created an AWS integration but want to create another one, navigate to the Integrations page (top navigation menu) and click the Amazon Web Services card. Your most recently created integration’s information will be available in the fields. Click Add Integration; a blank AWS integration setup page will appear.\nElastic Map Reduce (EMR) clusters work a little differently than other AWS element types in that terminated clusters remain in your AWS console for two months. To avoid any confusion with your inventory and metric collection, Metricly does not show terminated clusters in the UI.\nEdit Most Recently Added AWS Integration If you’ve already created an AWS integration and want to edit the configuration information, navigate to the Integrations page (top navigation menu) and click the Amazon Web Services card. Your most recently created integration’s information will be available in the fields; edit as necessary.\nEdit Any AWS Integration If you want to edit a different AWS integration, click View Current Integrations on the AWS integration setup page, then select the desired AWS integration.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-asg/",
	"title": "AWS ASG Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#asg", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS ASG –\n\r   Policy name Duration Condition 1 (and) Condition 2 (and) Condition 3 Cat. Description     Elevated CPUActivity (Normal Network Activity) 30 min aws.ec2.cpuutilization has an upper baseline + upper contextual deviation metricly.aws.ec2.bytesinperse does not have a upper baseline + upper contextual deviation metricly.aws.ec2.bytesoutpersec does not have a upper baseline + upper contextual deviation. INFO This policy is designed to catch cases where CPU activity is higher than than normal and cannot be explained by a corresponding increase in network traffic. Operates on the average CPU and network utilization across all EC2’sin the ASG.   Elevated Network Activity 30 min metricly.aws.ec2.bytesinpersec has an upper baseline + upper contextual deviation metricly.aws.ec2.bytesoutperse has an upper baseline + upper contextual deviation  INFO Indicates an increase in network activity above what is considered to be normal. Operates on the average network utilization across all EC2’s in the ASG.   Elevated EphemeralDisk Activity 30 min metricly.aws.ec2.diskreadopspersec has an upper baseline + upper contextual deviation metricly.aws.ec2.diskwriteopspersec has an upper baseline + upper contextual deviation  INFO Indicates an increase in disk activity above what is considered to be normal. Operates on the average disk utilization across all EC2’s in the ASG.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-dynamodb/",
	"title": "AWS DynamoDB Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#dynamoDB", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS DynamoDB –\n\r   Policy Name Duration Condition 1 Cat. Description     Elevated Read Capacity Utilization 30 Min metricly.aws.dynamodb.readcapacityutilization has an upper baseline deviation + an upper contextual deviation + a static threshold ≥ 50. WARNING Read Capacity Utilization has been higher than expected for over 30 minutes; also, the actual value has been above 50% for that time.   Elevated Write Capacity Utilization 30 Min metricly.aws.dynamodb.writecapacityutilizationhas an upper baseline deviation +an upper contextual deviation, + a static threshold ≥ 50. WARNING Write Capacity Utilization has been higher than expected for over 30 minutes; also, the actual value has been above 50% for that time.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-ebs/",
	"title": "AWS EBS Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#ebs", "#aws"],
	"description": "",
	"content": "Before reading about the EBS default policy, it is important to understand the following Metricly computed metrics.\n Average Latency: Average Latency is straightforward as it represents the average amount of time that it takes for a disk operation to complete. Queue Length Differential: Queue Length Differential measures the difference between the actual disk queue length and the “ideal” disk queue length.The ideal queue length is based on Amazon’s rule of thumb that for every 200 IOPS you should have a queue length of 1. In theory, a well-optimized volume should have a queue length differential that tends to hover around 0. In practice, we have seen volumes with extremely low latency (\u0026lt; 0.0001) have queue length differentials that are higher than 0; presumably this is because the latency is much lower than Amazon is assuming for their rule of thumb. Even in these cases, the differential is a pretty steady number.     Policy name Duration Condition 1 (and) Condition 2 Cat. Description     Elevated Queue Length Differential with Elevated Latency 30 min metricly.aws.ebs.queuelengthdifferentialhas an upper baseline deviation + static threshold \u0026gt; 1 metricly.aws.ebs.averagelatency has an upper baseline CRITICAL The first condition of the policy looks for an upper deviation as the first indication that the disk may be getting more traffic than it can keep up with. It also checks for the differential to be greater than 1 in order to avoid false alarming in cases where the differential is very low.The second condition is added because an elevated queue differential by itself is not necessarily a bad thing. We only want to alarm if your differential is higher than normal AND your latency is higher than normal.   Elevated iops Utilization with low Burst Balance 5 min netuitive.aws.ebs.iopsutilization =\u0026gt; 90 aws.ebs.burstbalance \u0026lt;= 10.  This policy looks at two metrics: IOPS Utilizaton and EBS Burst Balance. High IOPS Utilization (a Metricly computed metric) indicates the disk is highly utilized and a low EBS Burst Balance indicates the disk is so highly utilized that most of the burst available to the disk is depleted. Once the burst balance is fully depleted available disk IOPS will fall causing slowdowns in I/O and deteriorated performance of the application using the volume.\\n\\nCheck this volume and the application using it to see if the I/O profile has changed. Consider using Provisioned IOPS to increase the disk performance if this new profile is normal.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-ec2/",
	"title": "AWS EC2 Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#ec2", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS EC2 –\n\r   Policy name Duration Condition 1 (and) Condition 2 (and) Condition 3 Cat. Description     Elevated CPUActivity (Normal Network Activity) 30 min aws.ec2.cpuutilization has an upper baseline deviation + an upper contextual deviation metricly.aws.ec2.bytesinpersec does not have a upper baseline deviation + does not have a upper contextual deviation metricly.aws.ec2.bytesoutpersec does not have a upper baseline deviation + does not have a upper contextual deviationn INFO Increases in CPU activity are not uncommon when there is a rise in network activity. Increased traffic to a server means more work for that server to do. This policy is designed to catch cases where CPU activity is higher than than normal, and said behavior cannot be explained by a corresponding increase in network traffic. It may or may not represent a problem, but it is useful to know about.   Elevated Network Activity 30 min metricly.aws.ec2.bytesinpersec has an upper baseline deviation + an upper contextual deviation metricly.aws.ec2.bytesoutpersec has an upper baseline deviation + an upper contextual deviation  INFO Indicates an increase in network activity above what is considered to be normal.   ElevatedEphemeral Disk Activity 30 min metricly.aws.ec2.diskreadopspersec has an upper baseline deviation + an upper contextual deviation metricly.aws.ec2.diskwriteopspersec has an upper baseline deviation + an upper contextual deviation  INFO Indicates an increase in disk activity above what is considered to be normal.   ElevatedEphemeral Disk Activity 30 min aws.ec2.cpuutilization has a static threshold \u0026gt;95%   WARNING The CPU on the EC2 instance has exceeded 95% for at least 15 minutes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-efs/",
	"title": "AWS EFS Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#efs", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS EFS –\n\r   Policy name Duration Condition 1 (and) Condition 2 (and) Condition 3 Cat. Description     AWS EFS – Depleted Burst Credit Balance 15 minutes aws.efs.burstcreditbalance = 0   Critical There are no burst credits left. The number of burst credits that a file system has is zero.   AWS EFS – IO Percentage Critical 15 minutes aws.efs.percentiolimit = 95%   Critical File system has almost reached its limit of the General Purpose performance mode. If this metric is at 100% more often than not, consider moving your application to a file system using the Max I/O performance mode.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-elb/",
	"title": "AWS ELB Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#elb", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS ELB –\n\r   Policy name Duration Condition 1 (and) Condition 2 Category Description     Elevated BackendError Rate (Low Volume) 15 min metricly.aws.elb.httpcodebackenderrorpercent has an upper baseline deviation + an upper contextual deviation metricly.aws.elb.requestcount has a static threshold \u0026lt;1,000 WARNING This is the first of three policies that look at elevated backend error rates. This policy looks specifically at low traffic volume cases. When traffic volumes are low, elevated error rates tend to be less important. For example, a 50% error rate is pretty significant if the total number of requests is 1 million; it is less so if the total number of requests is 10. Thus, this policy will generate a Warning if error rates are higher than normal and traffic volumes are low. By default, “low” is defined as less than 1,000 requests; you may wish to tune this for your own environment.   ElevatedBackend Error Rate (High Volume, Low Error Rate) 15 min metricly.aws.elb.httpcodebackenderrorpercent has an upper baseline deviation + an upper contextual deviation + a static threshold \u0026lt;2% metricly.aws.elb.requestcount has a static threshold ≥ 1,000 WARNING This is the second of three policies that look at elevated backend error rates. For many customers, an error rate which is low enough is not cause for concern even if it is higher than normal. For example, if the normal error rate is between 0.25% and 0.75%, and observed error rate of 1.1% is higher than expected, but may not be worth more than a Warning. Thus, this policy looks for those cases where the error rate is higher than expected, but is under 2%. It also looks for traffic volumes to not be low, since the low traffic scenario is covered by the “Elevated Backend Error Rate (Low Volume)” policy. You may wish to tune either the 1,000 request count threshold, the 2% error threshold, or both, to better suit your environment.   ElevatedBackend Error Rate (High Volume, High Error Rate) 15 min metricly.aws.elb.httpcodebackenderrorpercent has an upper baseline deviation + an upper contextual deviation + a static threshold ≥ 2% metricly.aws.elb.requestcount has a static threshold ≥ 1,000 CRITICAL This is the third of three policies that look at elevated backend error rates. In this case, we are looking for both high traffic volumes (\u0026gt;1000) as well as error rates that are not just higher than normal, but are above the 2% threshold. In those cases, a Critical event will be generated. You may wish to tune either the 1,000 request count threshold, the 2% error threshold, or both, to better suit your environment.   Elevated Latency 30 min aws.elb.latency has an upper baseline deviation + an upper contextual deviation metricly.aws.elb.requestcount has a static threshold ≥ 1,000 CRITICAL This policy will generate a Critical event when average latency is higher than normal for half an hour or longer. Note that there must also be a minimum number of requests for this policy to trigger; this is because with too few requests, the average can tend to be skewed by outliers. The default request threshold is 1,000; you may wish to tune this for your environment.   Surge Queue UtilizationGreater Than 5% 15 min metricly.aws.elb.surgequeueutilization has a static threshold \u0026gt; 5%  WARNING The ELB surge queue holds requests until they can be forwarded to the backend servers. The surge queue can hold a maximum of 1,024 requests, after which it will be full and will start rejecting requests. Metricly’s Surge Queue Utilization metric reflects as a percentage how full the surge queue currently is. If the surge queue is more than 5% full for 15 minutes or longer, a Warning event is generated.   Surge Queue UtilizationGreater Than 50% 15 min metricly.aws.elb.surgequeueutilization has a static threshold \u0026gt; 50%  CRITICAL The ELB surge queue holds requests until they can be forwarded to the backend servers. The surge queue can hold a maximum of 1,024 requests, after which it will be full and will start rejecting requests. Metricly’s Surge Queue Utilization metric reflects as a percentage how full the surge queue currently is. If the surge queue is more than 50% full for 15 minutes or longer, a Critical event is generated.   Unhealthy Host Percent Above 50% 15 min metricly.aws.elb.unhealthyhostpercent has a static threshold ≥ 50% + a static threshold \u0026lt; 75%  WARNING More than half (50%) of the hosts associated with this ELB are in an unhealthy state.   Unhealthy Host Percent Above 75% 5 min metricly.aws.elb.unhealthyhostpercent has a static threshold ≥ 75%  CRITICAL More than three quarters (75%) of the hosts associated with this ELB are in an unhealthy state.   Elevated ELB Error Rate 15 min metricly.aws.elb.httpcodeelberrorpercent has an upper baseline deviation + an upper contextual deviation + a static threshold ≥ 2% aws.elb.requestcount has a static threshold ≥ 1000 CRITICAL This is another error rate policy, but rather than looking at backend error rates, it is looking at errors from the ELB itself. In this case, we look for both high traffic volumes (\u0026gt; 1000) as well as error rates that are not just higher than normal, but are above a 2% threshold. In those cases, a Critical event will be generated. You may wish to tune either the 1,000 request count threshold, the 2% error threshold, or both, to better suit your environment.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-elasticache/",
	"title": "AWS Elasticache Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#elasticache", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS Elasticache –\n\r   Policy name Duration Condition 1 (and) Condition 2 Category Description     Memcached – CPU Threshold Exceeded 5 min aws.elasticache.cpuutilization has a static threshold \u0026gt;90%  CRITICAL The Memcached Node has exceeded the CPU threshold of 90%. The cache cluster may need to be scaled, either by using a larger node type or by adding more nodes.   Memcached – Elevated CPU Utilization 30 min aws.elasticache.cpuutilization has an upper baseline deviation + has a static threshold\u0026gt; 50%  WARNING CPU utilization for the Memcached Node has been higher than expected for at least 30 minutes.   Memcached – Elevated Swap Usage 5 min aws.elasticache.swapusage has a static threshold \u0026gt;53428800  CRITICAL Swap usage on the Memcached Node has exceeded 50 MB. It is recommended that you increase the value of the ConnectionOverhead parameter.   Redis – Elevated Command Executions 30 min aws.elasticache..*cmds has an upper baseline deviation + an upper contextual deviation  WARNING One or more command types on the Redis node have been experiencing a higher than expected number of executions for at least 30 minutes.   Redis – Elevated CPU Utilization 30 min aws.elasticache.cpuutilization has an upper baseline deviation + a static threshold \u0026gt; 30%  WARNING CPU utilization for the Redis Node has been higher than expected for at least 30 minutes.   Redis – Elevated Network Activity 30 minutes aws.elasticache.networkbytesin has an upper baseline deviation + an upper contextual deviation aws.elasticache.networkbytesouthas an upper baseline deviation + an upper contextual deviation WARNING Network activity to/from the Redis node has been higher than expected for at least 30 minutes.   Redis – Elevated Number of New Connections 30 min aws.elasticache.newconnections has an upper baseline deviation + an upper contextual deviation  WARNING The number of new connections being opened to the Redis node has beenhigher than expected for at least 30 minutes.   Redis – Elevated Replication Lag 30 min aws.elasticache.replicationlag has an upper baseline deviation  WARNING Replication lag for the Redis node has been higher than expected for atleast 30 minutes.   Redis – Elevated Swap Usage 30 min aws.elasticache.swapusage has an upper baseline deviation  WARNING Swap usage on the Redis Node has been higher than expected for at least30 minutes. Extended swapping indicates a low physical memory condition,and can lead to performance degradation.   Redis – Extended Period of Evictions 30 min aws.elasticache.swapusage has a static threshold \u0026gt; 0  WARNING Evictions for the Redis node have been greater than 0 for at least 30minutes. This could indicate a low memory condition, and may impactperformance.   Redis – Low Cache Hit Rate 30 min aws.elasticache.cachehitrate has an upper baseline deviation + an upper contextual deviation  WARNING The cache hit rate for the Redis node has been lower than expected forat least 30 minutes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-lambda/",
	"title": "AWS Lambda Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#elb", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS Lambda –\n\r   Policy name Duration Conditions Category Description     Elevated Invocation Count 30 min aws.lambda.invocations has an upper baseline deviation + an upper contextual deviation WARNING The number of calls to the function (invocations) have been greater than expected for at least the last 30 minutes.   Depressed Invocation Count 10 min aws.lambda.invocations has a lower baseline deviation + a lower contextual deviation WARNING The number of calls to the function (invocations) have been lower than expected for at least the last 10 minutes.   Elevated Latency 30 min aws.lambda.duration has an upper baseline deviation + an upper contextual deviation WARNING The average duration per function call (latency) has been higher than expected for at least the past 30 minutes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-rds/",
	"title": "AWS RDS Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#rds", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS RDS –\n\r   Policy name Duration Condition 1 (and) Condition 2 (and) Condition 3 Cat. Description     Elevated RDS CPU Activity (Normal Network Activity) 30 min metricly.aws.rds.cpuutilization has an upper baseline deviation + an upper contextual deviation + a static threshold \u0026gt; 20 metricly.aws.rds.networkreceivethroughput does not have an upper baseline deviation + does not have a upper contextual deviation metricly.aws.rds.networktransmitthroughput does not have a upper baseline deviation + does not have a upper contextual deviation INFO Increases in CPU activity are not uncommon when there is a rise in network activity. Increased traffic to a server means more work for that server to do. This policy is designed to catch cases where CPU activity is higher than than normal, and said behavior cannot be explained by a corresponding increase in network traffic. It may or may not represent a problem, but it is useful to know about.   Elevated RDS Network Activity 30 min metricly.aws.rds.networkreceivethroughputhas an upper baseline deviation + an upper contextual deviation metricly.aws.rds.networktransmitthroughputhas an upper baseline deviation + an upper contextual deviation  INFO Indicates an increase in network activity above what is considered to benormal.   Elevated RDS Disk Activity 30 min metricly.aws.rds.readiops has an upper baseline deviation + an upper contextual deviation metricly.aws.rds.writeiops has an upper baseline deviation + an upper contextual deviation  INFO Indicates an increase in disk activity above what is considered to be normal.   Elevated RDS Latency 30 min metricly.aws.rds.readlatency has an upper baseline deviation + an upper contextual deviation metricly.aws.rds.writelatency has an upper baseline deviation + an upper contextual deviation metricly.aws.rds.totalthroughput has a static threshold ≥ 1,000 CRITICAL This policy will generate a Critical event when both read and write latency is higher than normal for half an hour or longer. Note that there must also be a minimum number of requests for this policy to trigger; this is because with too few requests, the average can tend to be skewed by outliers. The default request threshold is 1,000; you may wish to tune this for your environment.   AWS RDS – Elevated Number of Connections 15 min metricly.aws.rds.databaseconnections has an upper baseline deviation + an upper contextual deviation   WARNING The number of database connections open on the RDS instance is higher than expected.   AWS RDS – Elevated Read IOPS 15 min metricly.aws.rds.readiops has an upper baseline deviation + an upper contextual deviation   WARNING Read activity on the RDS instance is greater than expected.   AWS RDS – Elevated Write IOPS 15 min metricly.aws.rds.writeops has an upper baseline deviation + an upper contextual deviation   WARNING Write activity on the RDS instance is greater than expected.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-aws-sns/",
	"title": "AWS SNS Notifications",
	"tags": ["#alerts", "#notifications", "#sns"],
	"description": "",
	"content": " You can leverage AWS’s Simple Notification Service as one of your notification methods in Metricly. There are two ways to accomplish this: through an IAM Role or Access Key. It is recommended that you have first set up the AWS Integration and are familiar with terms such as ARN (Amazon Resource Names), which are needed to complete setup.\nInbound \u0026amp; Outbound This guide tackles outbound SNS setup, however you can also ingest inbound SNS notifications. Check out how we leverage SNS to ingest CloudWatch logs for a great example of inbound usage.\nConfiguration Methods IAM Role Setup 1. Add SNS Permissions to your AWS IAM Role You must add SNS permissions to your AWS IAM Role in order to complete setup. Completing this section provides you with the required IAM Role ARN for section 4. Haven’t created an IAM Role? Complete our AWS setup documentation.\n In a separate tab from Metricly, log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Once in the IAM dashboard, navigate to the Roles section. Search for your AWS Metricly IAM Role. Select your AWS Metricly IAM role. Click Attach Policy. For Attach Policy, search sns, then select AmazonSNSFullAccess.  Click Attach Policy to add the policy. Return to step 2.5 in the previous section and input the IAM Role ARN.  2. Obtain Topic ARN You must have a Topic ARN set up in AWS to use SNS with Metricly. Completing this section provides you with that number.\n Navigate to the SNS console. Click Topics on the left-hand menu. Copy the ARN from the ARN column next to the desired topic. Paste the value into the Topic ARN field in the SNS Notification window in Metricly. Back in the SNS console, select the same topic, and then click Edit topic policy in the Actions menu. Under the Allow these users to publish messages to this topic section, select Only these AWS users and add the Account ID from Metricly to the field. Click Update Policy. Return to Metricly and optionally select Custom from the Payload drop-down menu. A text field will open after selecting Custom. Create a custom JSON payload in the textbox. You can use the following variables to make your notification more dynamic. Click Save.     Variable Description     ${event.data.results} The description of the event as a policy violation.   ${event.id} The ID of the event   ${eventCategory.name} The event category ( (Info), (Warning), or (Critical)).   ${elementFqn} The Fully Qualified Name (FQN) of the element.   ${elementId} The type of element (e.g., SERVER, ELB, EC2, RDS, etc.).   ${elementType} The type of element (e.g, SERVER, ELB, RUBY, etc.)   ${elementLocation} The location of the element.   ${elementName} The friendly name for the element.   ${policyId} The policy identification number.   ${policyName} The name of the policy.   ${eventTimestamp} The time (in UTC) the event occurred.   ${policyDescription} The description of the policy that generated the event.    Below is the default payload used in the SNS integration, but it’s a good starting place for creating a custom JSON payload.\n{ \u0026quot;timestamp\u0026quot;: \u0026quot;${eventTimestamp}\u0026quot;, \u0026quot;category\u0026quot;: \u0026quot;${eventCategory}\u0026quot;, \u0026quot;element\u0026quot;: { \u0026quot;fqn\u0026quot;: \u0026quot;${elementFqn}\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;${elementId}\u0026quot;, \u0026quot;location\u0026quot;: \u0026quot;${elementLocation}\u0026quot; }, \u0026quot;policy\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;${policyName}\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;${policyDescription}\u0026quot; } }  3. Navigate to Integrations  Click your Username \u0026gt; Notifications. Click SNS. Click Add SNS.   4. Input Information  Input a Name for the SNS notification. Ensure Enabled checkbox is selected. Provide a Topic ARN. Select IAM Role for AWS Authentication. Provide existing IAM role ARN. (Or, skip to next section to create one). Choose a payload type (Default or Custom).  Click Test and Save.  Access Key Setup Method 1. Create a User and Add SNS Permissions. You must have a user with SNS permissions to complete the setup of an SNS with Metricly. Completing this section provides you with the required Access key ID and Secret access key. 1. In the AWS Console, navigate to Users. 2. Click Add a User. 3. Prove a Name and check Programmatic Access. 4. Click Next: Permissions. 5. Click Attach existing policies directly and select AmazonSNSFullAccess. 6. Click Next: Review. 7. Click Create User. 8. Copy the Access key ID and Secret access key.\n2. Obtain Topic ARN You must have a Topic ARN set up in AWS to use SNS with Metricly. Completing this section provides you with that number.\n Navigate to the SNS console. Click Topics on the left-hand menu. Copy the ARN from the ARN column next to the desired topic. Paste the value into the Topic ARN field in the SNS Notification window in Metricly. Back in the SNS console, select the same topic, and then click Edit topic policy in the Actions menu. Under the Allow these users to publish messages to this topic section, select Only these AWS users and add the Account ID from Metricly to the field. Click Update Policy. Return to Metricly and optionally select Custom from the Payload drop-down menu. A text field will open after selecting Custom. Create a custom JSON payload in the textbox. You can use the following variables to make your notification more dynamic. Click Save.     Variable Description     ${event.data.results} The description of the event as a policy violation.   ${event.id} The ID of the event   ${eventCategory.name} The event category ( (Info), (Warning), or (Critical)).   ${elementFqn} The Fully Qualified Name (FQN) of the element.   ${elementId} The type of element (e.g., SERVER, ELB, EC2, RDS, etc.).   ${elementType} The type of element (e.g, SERVER, ELB, RUBY, etc.)   ${elementLocation} The location of the element.   ${elementName} The friendly name for the element.   ${policyId} The policy identification number.   ${policyName} The name of the policy.   ${eventTimestamp} The time (in UTC) the event occurred.   ${policyDescription} The description of the policy that generated the event.    Below is the default payload used in the SNS integration, but it’s a good starting place for creating a custom JSON payload.\n{ \u0026quot;timestamp\u0026quot;: \u0026quot;${eventTimestamp}\u0026quot;, \u0026quot;category\u0026quot;: \u0026quot;${eventCategory}\u0026quot;, \u0026quot;element\u0026quot;: { \u0026quot;fqn\u0026quot;: \u0026quot;${elementFqn}\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;${elementId}\u0026quot;, \u0026quot;location\u0026quot;: \u0026quot;${elementLocation}\u0026quot; }, \u0026quot;policy\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;${policyName}\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;${policyDescription}\u0026quot; } }  3. Navigate to Integrations in Metricly  Click your Username \u0026gt; Notifications. Click SNS. Click Add SNS.   4. Input Information  Input a Name for the SNS notification. Ensure Enabled checkbox is selected. Provide the Topic ARN from previous section. Select IAM Role for AWS Authentication. Provide the Access Key and Secret Key from previous section. Choose a payload type (Default or Custom).  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/aws-policies-sqs/",
	"title": "AWS SQS Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#sqs", "#aws"],
	"description": "",
	"content": "Policy names are prefixed with AWS SQS –\n\r   Policy name Duration Conditions Category Description     AWS SQS – Queue Falling Behind 2 hours metricly.aws.sqs.arrivalrate has a metric threshold \u0026gt; metricly.aws.sqs.completionrate CRITICAL The arrival rate for the queue has been greater than the completion rate for at least 2 hours. This is an indication that processing of the queue is falling behind.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/metrics/metric-add-to-dashboard/",
	"title": "Add Metric to Dashboard",
	"tags": ["#getting started", "#metrics", "#charts"],
	"description": "",
	"content": " Add as Single Metric Widget  Open the Metric chart sub-menu \r. Click Add to Dashboard. In the Add to Dashboard window, click Dashboards and select a dashboard or type to search. Change the widget name if desired. Click Save. The widget is now available on the selected dashboard.  Add as Multi-Metric Widget  Merge as many metrics as desired. Open the Metric Chart sub-menu \r. Click Add to Dashboard. In the Add to Dashboard window, click Dashboards and select a dashboard or type search. Change the widget name if desired. Click Save. The widget is now available on the selected dashboard  View Charts of Same Type on Other Elements  Open the Metric Chart sub-menu \r. Click Other Elements with this Metric. Select as many elements as desired.  Click All to select all the elements with the selected metric. Click None to clear all elements with the selected metrics. You can also search for an element using the Search Elements field.  Click Done. The metric charts open in the Metrics page.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/categories/admin-guide/",
	"title": "Admin Guide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/checks/checks-alerting/",
	"title": "Alert on a Check",
	"tags": ["#alerts", "#notifications", "#checks", "#custom checks"],
	"description": "",
	"content": "Setting up an alert in Metricly requires the creation of a policy and the system checks are no exception. Any check coming into the system can have a corresponding alert as well as a notification.\n Click on policies and select New Policy. Name the policy and apply any scoping or filtering required (for example, narrowing the scope to WinServ in US-West region with Tag Environment:Production). Next click Conditions \u0026gt; Add Condition, and from the drop down you will see Add System Check Condition. Now you just have to select the particular check. As long as the check has been posted at least once to the API, it would automatically show up on this menu. Then save, and you are done. To add notifications, click the tab, and select the notification type.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/alerts-page/",
	"title": "Alerts Page",
	"tags": ["#alerts", "#notifications", "#events", "#policies"],
	"description": "",
	"content": " The Alerts page shows a list of all your configured policies, both enabled and disabled. It includes:\n Policy name Number of elements in scope Filters on the policy State of the policy (Enabled/Disabled) Current status (OK, Info, Warning, Critical).  This page has additional filters to display all Open and Closed policies.\n Filtering by Open will display only the policies that are currently (Now) violating a set condition(s). We use the term “firing” to refer to policies that are violating a set of conditions. Clicking on Closed will show any policies that have fired during the selected time range.  Search Policies You can search for a particular policy or filter the policy by using the policy filters.\n Open the alerts page. At the top of the page, use the available fields to search for the desired policy or filter the list:  Name contains: Text field used to match characters contained in a policy name. Created By: Drop-down menu used for selecting the user that created a policy. State: Drop-down menu used for selected if a policy is disabled or enabled. Type: Text field used to match an element type used in a policy. You can only select one element type to search for.   Available Views Table View The table view will display all the policies configured in your tenant account. These are both the Metricly best practices and your user defined policies. In the table you will also see the details (status, state, enabled, notifications) about each policy. To see what is firing right now click on Open. By clicking Closed you will see all the policies that fired over the selected time range.\nSlide Out View Click on the policy name to open more details about the policy. The slide out will display any elements that have Open or Closed policy violations. Remember the Closed policies are tied to the time control. You can click on the graph to see the metrics view. This feature is disabled for the checks because it does not apply. The view can be closed by clicking the the X in the top right corner.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/elastisearch/elastisearch-all-metrics/",
	"title": "All Elastisearch Metrics",
	"tags": ["#elastisearch", "#integrations", "#metrics", "#cluster", "#disk", "#threadpool", "#indices"],
	"description": "",
	"content": " Collected For the table below, all metrics that begin with elasticsearch.indices.* are duplicated for each index being monitored, with the * replaced by the index name (your indices will vary based on your implementation). All metrics that start with elasticsearch.thread_pool.* are duplicated for each thread pool, with the * replaced by the thread pool name. The various thread pools are:\n bench bulk fetch_shard_started fetch_shard_store flush generic get index listener management merge optimize percolate refresh search snapshot suggest warmer     Fully Qualified Name (FQN) Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     elasticsearch.cache.filter.evictions max count 0 none none yes yes no   elasticsearch.cache.filter.size average bytes 0 none none yes yes no   elasticsearch.cluster_health.nodes.data average count 0 none none yes no no   elasticsearch.cluster_health.nodes.total average count 0 none none yes no no   elasticsearch.cluster_health.shards.active average count 0 none none yes no no   elasticsearch.cluster_health.shards.active_primary average count 0 none none yes no no   elasticsearch.cluster_health.shards.initializing average count 0 none none yes no no   elasticsearch.cluster_health.shards.relocating average count 0 none none yes no no   elasticsearch.cluster_health.status average count 0 none none yes no no   elasticsearch.cluster_health.unassigned average count 0 none none yes no no   elasticsearch.disk.reads.count max count 0 none none yes yes no   elasticsearch.disk.reads.size max bytes 0 none none yes yes no   elasticsearch.disk.writes.count max count 0 none none yes yes no   elasticsearch.disk.writes.size max bytes 0 none none yes yes no   elasticsearch.fielddata.evictions average count 0 none none yes no no   elasticsearch.fielddata.size average bytes 0 none none yes no no   elasticsearch.http.current average count 0 none none yes yes no   elasticsearch.indices.*.datastore.size max bytes 0 none none yes yes no   elasticsearch.indices.*.docs.count max count 0 none none yes yes no   elasticsearch.indices.*.docs.deleted max count 0 none none yes yes no   elasticsearch.indices.*.flush.total max count 0 none none yes yes no   elasticsearch.indices.*.flush.total_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.get.exists_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.get.exists_total max count 0 none none yes yes no   elasticsearch.indices.*.get.missing_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.get.missing_total max count 0 none none yes yes no   elasticsearch.indices.*.get.time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.get.total max count 0 none none yes yes no   elasticsearch.indices.*.indexing.delete_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.indexing.delete_total max count 0 none none yes yes no   elasticsearch.indices.*.indexing.index_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.indexing.index_total max count 0 none none yes yes no   elasticsearch.indices.*.indexing.noop_update_total max count 0 none none yes yes no   elasticsearch.indices.*.indexing.throttle_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.merges.total max count 0 none none yes yes no   elasticsearch.indices.*.merges.total_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.percolate.time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.percolate.total max count 0 none none yes yes no   elasticsearch.indices.*.recover.throttle_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.refresh.total max count 0 none none yes yes no   elasticsearch.indices.*.refresh.total_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.search.fetch_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.search.fetch_total max count 0 none none yes yes no   elasticsearch.indices.*.search.query_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.search.query_total max count 0 none none yes yes no   elasticsearch.indices.*.store.throttle_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.suggest.time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.suggest.total max count 0 none none yes yes no   elasticsearch.indices.*.warmer.total max count 0 none none yes yes no   elasticsearch.indices.*.warmer.total_time_in_milliseconds max ms 0 none none yes yes no   elasticsearch.indices.*.datastore.size max bytes 0 none none yes yes no   elasticsearch.indices.*.docs.count max count 0 none none yes yes no   elasticsearch.indices.*.docs.deleted max count 0 none none yes no no   elasticsearch.jvm.gc.collection.count max count 0 none none yes no no   elasticsearch.jvm.gc.collection.old.count max count 0 none none yes no no   elasticsearch.jvm.gc.collection.old.time max ms 0 none none yes no no   elasticsearch.jvm.gc.collection.young.count max count 0 none none yes no no   elasticsearch.jvm.gc.collection.young.time max ms 0 none none yes no no   elasticsearch.jvm.mem.heap_committed average bytes 0 none none yes no no   elasticsearch.jvm.mem.heap_used average bytes 0 none none yes no no   elasticsearch.jvm.mem.heap_used_percent average percent 0 none none yes yes no   elasticsearch.jvm.mem.non_heap_committed average bytes 0 none none yes no no   elasticsearch.jvm.mem.non_heap_used average bytes 0 none none yes no no   elasticsearch.jvm.mem.pools.old.max average bytes 0 none none yes no no   elasticsearch.jvm.mem.pools.old.used average bytes 0 none none yes no no   elasticsearch.jvm.mem.pools.survivor.max average bytes 0 none none yes no no   elasticsearch.jvm.mem.pools.survivor.used average bytes 0 none none yes no no   elasticsearch.jvm.mem.young.max average bytes 0 none none yes no no   elasticsearch.jvm.mem.young.used average bytes 0 none none yes no no   elasticsearch.jvm.threads.count average count 0 none none yes no no   elasticsearch.network.tcp.active_opens max count 0 none none yes no no   elasticsearch.network.tcp.attempt_fails max count 0 none none yes no no   elasticsearch.network.tcp.curr_estab max count 0 none none yes no no   elasticsearch.network.tcp.estab_resets max count 0 none none yes no no   elasticsearch.network.tcp.in_errs max count 0 none none yes no no   elasticsearch.network.tcp.in_segs max count 0 none none yes no no   elasticsearch.network.tcp.out_rate max count 0 none none yes no no   elasticsearch.network.tcp.out_segs max count 0 none none yes no no   elasticsearch.network.tcp.passive_opens max count 0 none none yes no no   elasticsearch.network.tcp.retrans_segs max count 0 none none yes no no   elasticsearch.process.cpu.percent average percent 0 none none yes no no   elasticsearch.process.mem.resident average bytes 0 100 none yes no no   elasticsearch.process.share average bytes 0 100 none yes no no   elasticsearch.process.virtual average bytes 0 100 none yes no no   elasticsearch.thread_pool.*.active average count 0 100 none yes no no   elasticsearch.thread_pool.*.completed max count 0 100 none yes no no   elasticsearch.thread_pool.*.largest average count 0 100 none yes no no   elasticsearch.thread_pool.*.queue average count 0 100 none yes no no   elasticsearch.thread_pool.*.rejected max count 0 100 none yes no no   elasticsearch.thread_pool.*.threads average count 0 100 none yes no no   elasticsearch.transport.rx.count max count 0 100 none yes no no   elasticsearch.transport.rx.size max count 0 100 none yes no no   elasticsearch.transport.tx.count max count 0 100 none yes no no   elasticsearch.transport.tx.size max count 0 100 none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/tcp-collector/tcp-metric-names/",
	"title": "Allowed Metric Names",
	"tags": ["#tcp", "#integrations"],
	"description": "",
	"content": "   Name Description     SyncookiesSent An application wasn’t able to accept a connection fast enough, so the kernel couldn’t store an entry in the queue for this connection. Instead of dropping it, it sent a cookie to the client.   SyncookiesRecv After sending a cookie, it came back to us and passed the check.   SyncookiesFailed After sending a cookie, it came back to us but looked invalid.   EmbryonicRsts    PruneCalled    RcvPruned If the kernel is really really desperate and cannot give more memory to this socket even after dropping the ofo queue, it will simply discard the packet it received. This is Really Bad.   OfoPruned When a socket is using too much memory (rmem), the kernel will first discard any out-of-order packet that has been queued (with SACK).   OutOfWindowIcmps    LockDroppedIcmps    ArpFilter    TW    TWRecycled    TWKilled    PAWSPassive    PAWSActive    PAWSEstab    DelayedACKs We waited for another packet to send an ACK, but didn’t see any, so a timer ended up sending a delayed ACK.   DelayedACKLocked We wanted to send a delayed ACK but failed because the socket was locked. So the timer was reset.   DelayedACKLost We sent a delayed and duplicated ACK because the remote peer retransmitted a packet, thinking that it didn’t get to us.   ListenOverflows We completed a 3WHS but couldn’t put the socket on the accept queue, so we had to discard the connection.   ListenDrops We couldn’t accept a connection because one of: we had no route to the destination, we failed to allocate a socket, we failed to allocate a new local port bind bucket. Note: this counter also include all the increments made to ListenOverflows   TCPPrequeued    TCPDirectCopyFromBacklog    TCPDirectCopyFromPrequeue    TCPPrequeueDropped    TCPHPHits    TCPHPHitsToUser    TCPPureAcks    TCPHPAcks    TCPRenoRecovery A packet was lost and we recovered after a fast retransmit.   TCPSackRecovery A packet was lost and we recovered by using selective acknowledgements.   TCPSACKReneging    TCPFACKReorder We detected re-ordering using FACK (Forward ACK — the highest sequence number known to have been received by the peer when using SACK — FACK is used during congestion control).   TCPSACKReorder We detected re-ordering using SACK.   TCPRenoReorder We detected re-ordering using fast retransmit.   TCPTSReorder We detected re-ordering using the timestamp option.   TCPFullUndo We detected some erroneous retransmits and undid our CWND reduction.   TCPPartialUndo We detected some erroneous retransmits, a partial ACK arrived while we were fast retransmitting, so we were able to partially undo some of our CWND reduction.   TCPDSACKUndo We detected some erroneous retransmits, a D-SACK arrived and ACK’ed all the retransmitted data, so we undid our CWND reduction.   TCPLossUndo We detected some erroneous retransmits, a partial ACK arrived, so we undid our CWND reduction.   TCPLoss    TCPLostRetransmit    TCPRenoFailures    TCPSackFailures    TCPLossFailures    TCPFastRetrans    TCPForwardRetrans    TCPSlowStartRetrans    TCPTimeouts    TCPRenoRecoveryFail    TCPSackRecoveryFail    TCPSchedulerFailed    TCPRcvCollapsed    TCPDSACKOldSent    TCPDSACKOfoSent    TCPDSACKRecv    TCPDSACKOfoRecv    TCPSACKDiscard We got a completely invalid SACK block and discarded it.   TCPDSACKIgnoredOld We got a duplicate SACK while retransmitting so we discarded it.   TCPDSACKIgnoredNoUndo We got a duplicate SACK and discarded it.   TCPAbortOnSyn We received an unexpected SYN so we sent a RST to the peer.   TCPAbortOnData We were in FIN_WAIT1 yet we received a data packet with a sequence number that’s beyond the last one for this connection, so we RST’ed.   TCPAbortOnClose We received data but the user has closed the socket, so we have no wait of handing it to them, so we RST’ed.   TCPAbortOnMemory This is Really Bad. It happens when there are too many orphaned sockets (not attached a FD) and the kernel has to drop a connection. Sometimes it will send a reset to the peer, sometimes it wont.   TCPAbortOnTimeout The connection timed out really hard.   TCPAbortOnLinger We killed a socket that was closed by the application and lingered around for long enough.   TCPAbortFailed We tried to send a reset, probably during one of teh TCPABort* situations above, but we failed e.g. because we couldn’t allocate enough memory (very bad).   TCPMemoryPressures Number of times a socket was put in “memory pressure” due to a non fatal memory allocation failure (reduces the send buffer size etc).   TCPBacklogDrop We received something but had to drop it because the socket’s receive queue was full.   RtoAlgorithm The algorithm used to determine the timeout value used for retransmitting unacknowledged octets.   RtoMin The minimum value permitted by a TCP implementation for the retransmission timeout, measured in milliseconds. More refined semantics for objects of this type depend upon the algorithm used to determine the retransmission timeout. In particular, when the timeout algorithm is “rsre ” (3), an object of this type has the semantics of the LBOUND quantity described in RFC 793.   RtoMax The maximum value permitted by a TCP implementation for the retransmission timeout, measured in milliseconds. More refined semantics for objects of this type depend upon the algorithm used to determine the retransmission timeout. In particular, when the timeout algorithm is “rsre” (3), an object of this type has the semantics of the UBOUND quantity described in RFC 793.   MaxConn The limit on the total number of TCP connections theentity can support. In entities where the maximum number of connections isdynamic, this object should contain the value -1.   ActiveOpens The number of times TCP connections have made a direct transition to the SYN-SENT state from the CLOSED state.   PassiveOpens The number of times TCP connections have made a direct transition to the SYN-RCVD state from the LISTEN state.   AttemptFails The number of times TCP connections have made a direct transition to the CLOSED state from either the SYN-SENT state or the SYN-RCVD state, plus the number of times TCP connections have made a direct transition to the LISTEN state from the SYN-RCVD state.   EstabResets The number of times TCP connections have made a direct transition to the CLOSED state from either the ESTABLISHED state or the CLOSE-WAIT state.   CurrEstab The number of TCP connections for which the current state is either ESTABLISHED or CLOSE- WAIT.   InSegs The total number of segments received, including those received in error. This count includes segments received on currently established connections.   OutSegs The total number of segments sent, including those on current connections but excluding those containing only retransmitted octets.   RetransSegs The total number of segments retransmitted – that is, the number of TCP segments transmitted containing one or more previously transmitted octets.   InErrs The total number of segments received in error (for example, bad TCP checksums).   OutRsts The number of TCP segments sent containing the RST flag.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/anake/",
	"title": "Anake",
	"tags": ["#anake", "#integrations", "#custom metrics", "#java"],
	"description": "",
	"content": " Ananke is a Java library that allows Java applications to communicate with and send information to a StatsD listener. You can use Ananke to send metrics from your Java applications to a StatsD server, which will then send the metrics to Metricly.\nConfiguration  Setup the Metricly StatsD integration or the Etsy StatsD integration if you haven’t already. We recommend setting up the Metricly StatsD integration if you don’t have a StatsD server already; if you have a StatsD server setup, we recommend setting up the Etsy StatsD integration. Include the proper dependency from Maven for the appropriate build manager. Invoke the StatsD client interface in a central location that your various Java classes can access.  StatsDClient client = new NetuitiveStatsDClient(\u0026quot;localhost\u0026quot;, \u0026quot;8000\u0026quot;);  4. Utilize code instrumentation to send metrics, events, service checks, and more into Metricly (basic examples included below each type). Metricly supports the following metric types: - Decrement (Counter – Down): Decrease the count of how many times something happened per second.\n client.decrement(new DecrementRequest() .withMetric(\u0026quot;tokens_left.count\u0026quot;) .withValue(-1));   Event: A log of something that happened, including a title and a description of the event.   client.event(new EventRequest() .withTitle(\u0026quot;Event Title\u0026quot;) .withText(\u0026quot;Send help!\u0026quot;));   Gauge: An arbitrary, persistent value (e.g., a fuel meter).   client.gauge(new GaugeRequest() .withMetric(\u0026quot;gas_tank.level\u0026quot;) .withValue(1L));   Histograms: The statistical distribution of a set of values.   client.histogram(new HistogramRequest() .withMetric(\u0026quot;file.upload.size\u0026quot;) .withValue(2MB));   Increment (Counter – Up): Increase the count of how many times something happened per second.   client.increment(new IncrementRequest() .withMetric(\u0026quot;page_view.count\u0026quot;) .withValue(1));   Service Check: A check to see if a service is either up or down.   client.servicecheck(new ServiceCheckRequest() .withName(\u0026quot;my_service\u0026quot;) .withStatus(1));   Sets: A number of unique elements received over a set interval.   client.set(new SetRequest() .withName(\u0026quot;users.unique\u0026quot;) .withValue(user.id));   Timed: Pass in a callable function that Ananke will time how long it takes to run and then passes the value on.   client.timed(new TimedRequest() .withFunc(\u0026quot;pageloadtime()\u0026quot;);   Timing: Measure in milliseconds how long an action took.   client.timing(new TimingRequest() .withMetric(\u0026quot;x\u0026quot;) .withValue(xms));  Java Integration Options We have several different options for monitoring Java applications. Each method varies in terms of setup difficulty and the amount / type of information it collects.\n   Method Description     Ananke Java library you can use to push metrics to the StatsD listener embedded in our Linux agent. This approach requires that you integrate the StatsDReporter into your applications.   Dropwizard Integrate the dropwizard-metrics library into your Dropwizard application and configure it to send metrics to the StatsD listener embedded in our Linux agent.   Iris Java library you can use to push metrics directly to Metricly’s REST API.   Java Agent Open-source and open-license Java agent the does the byte-code instrumentation for you. No changes to source code required.   JMX Integration that relies on our Linux agent to collect JVM metrics (e.g., heap size, garbage collection, etc.) without code-level instrumentation.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/analytics/",
	"title": "Analytics",
	"tags": ["#getting started", "#directory page"],
	"description": "",
	"content": "Metricly uses advanced analytics to monitor your environment and proactively notify you when problems occur. There are 3 basic data types that Metricly uses to do so:\n Raw data: Data collected from a third party integration that has not been interpreted, or aggregated, by Metricly. Because it has not been aggregated, raw data does not contribute to event creation. Aggregate data: Data collected from an integration that has been interpreted by Metricly. To generate aggregate data, Metricly averages the raw data collected from an integration at 5 minute intervals. Aggregate data is used to represent a metric’s actual value. Sparse data: Data generated by Metricly when no data is collected from an integration for a given period of time. The value of sparse data is always 0.\n  Metricly determines when a metric’s behavior is abnormal through the use of static thresholds, Baseline bands, and Contextual bands. In each case, the value of a metric is based on aggregate or sparse data. Raw data cannot be used to generate events.\nOn the Metrics page, the Element Detail panel, and Event Explorer, the colors of data points in metric charts indicate the type of data that is shown.\n   DP Color Description      Black data points indicate aggregate data or data that has been interpreted by Metricly. To generate aggregate data, Metricly averages the data collected from a given integration at 5 minute intervals.    Gray data points also indicate aggregate data but for data collected that Metricly averages at 1 hour intervals.    Green data points indicate sparse data or data generated by Metricly when data is not collected from a integration within a given period of time. The metric value for sparse data is always 0.    Red data points indicate a deviation or data that falls outside the learned Contextual or Baseline bands.    Blue data points indicate raw data or data that has not been interpreted by Metricly. Because raw data is not interpreted by Metricly, it does not produce deviations.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/ansible/",
	"title": "Ansible",
	"tags": ["#ansible", "#integrations", "#configuration management"],
	"description": "",
	"content": " Ansible is a configuration management tool that can be used to automate setup of servers, databases, and more. The Metricly Agent playbook will help get the Metricly Linux agent up and running in your environment quickly.\nConfiguration  Copy the Metricly Agent playbook to your Ansible directory.\n cd /ansible git clone https://github.com/netuitive/ansible-netuitive-agent.git  In the Metricly Agent playbook (netuitive-agent.yml), update the hosts setting to use desired host or inventory file. Replace apikey in the metricly_linux_api setting with the API key from the Linux integration in your Metricly account. To find this API key, point to the user account menu in the top right-hand corner of Metricly and select Integrations. Your Linux API key is found next to the integration listed as INFRASTRUCTURE. Run the Metricly Agent playbook, replacing hosts-file-name with the name of your hosts file.\n ansible-playbook -i hosts-file-name netuitive-agent.yml   "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/apache-policies-httpd/",
	"title": "Apache HTTPD Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#apache", "#httpd"],
	"description": "",
	"content": "   Linux Apache HTTPD – Depressed Traffic Volume 30 min httpd..ReqPerSec has a lower baseline deviation WARNING The number of requests per second has been lower than expected for at least the past 30 minutes.     Linux Apache HTTPD – Elevated Traffic Volume 30 min httpd..ReqPerSec has an upper baseline deviation WARNING The number of requests per second has been higher than expected for at least the past 30 minutes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-metrics/azure-app-gateway/",
	"title": "Application Gateway",
	"tags": ["#microsoft", "#azure", "#integrations", "#metrics"],
	"description": "",
	"content": "   Fully Qualified Name (FQN) Type Units Statistic Min Max Sparse Data Strategy BASE CORR UTIL Description     azure.applicationgateway.throughput GAUGE bytes/second average 0 none none yes no no The number of bytes per second being processed by the gateway.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-installation/",
	"title": "Azure Installation",
	"tags": ["#microsoft", "#azure", "#integrations", "#installation"],
	"description": "",
	"content": " 1. Create a Microsoft Azure Integration Card  From the top navigation menu, select Integrations. Click the Microsoft Azure card. In a separate, new tab, open the Azure portal.  The following instructions were created using the Azure portal not the classic portal. Instructions vary depending on which portal you’re using.\n\r2. Create an Active Directory Application in Azure  Once in the Azure portal, click Azure Active Directory from the left side menu. Click the App registrations widget. Click Add at the top. A Create window will open. Type the name of the application. We recommend Azure / Metricly Integration, or something similar. Ensure the Application Type is Web app / API. Input https://app.metricly.com for the Sign-on URL. Click Create at the bottom of the window.  3. Get the Application ID, Application Key, \u0026amp; Tenant ID  Select your new application from the App registrations list. The application’s Essentials and Settings windows open. Copy the Application ID (also known as the Client ID) and return to the tab with Metricly open. Paste it into the Client ID field. Once it’s pasted, return to the Azure tab. From the Settings window, click Keys. In the Keys window, add a description for the key. Select a duration for the key. Click Save at the top of the Keys window. Copy the Key’s Value and return to the tab with Metricly open. Paste it into the Access Key field. Once it’s pasted, return to the Azure tab. Return to the App registrations window and click Endpoints. From the list of endpoints, you’ll notice your Tenant ID in each of the URLs. Copy the Tenant ID from one of the endpoints and return to the tab with Metricly open. Paste it into the Tenant ID field. Once it’s pasted, return to the Azure tab.  4. Set Delegated Permissions  Open the application’s settings window and click Required permissions. Click Add at the top of the Required permissions window. In the Add API access window, click step 1. Click Windows Azure Service Management API, then click Select at the bottom of the Select an API window. Click step 2 and select the Delegated Permissions checkbox, then click Select at the bottom of the Enable Access window. After selecting the Delegated Permissionscheckbox, you may have to clear and then select the Access Azure Service Management as organization users (preview) checkbox again to activate the Select button.\n\r Click Done in the Add API access window.  5. Collect Subscription ID and Set Role To assign a role to the application, you’ll need the Owner or User Access Administrator role in Azure (the Contributor role will not work) or a custom role that grans write access for Microsoft.Authorization. You can check your permissions for the subscription by opening the user account menu (top right-hand corner), clicking My permissions, and then selecting the relevant subscription from the drop-down menu. If you don’t have the correct permissions, contact your subscription administrator.\n Navigate to Subscriptions in Azure. If you don’t see Subscriptions in your side menu, click More services and search for Subscriptions using the filter.\n\r Copy the Subscription ID and return to the tab with Metricly open. Paste it into the appropriate field. Once it’s pasted, return to the Azure tab. Click the appropriate subscription. Click Access Control (IAM). Click Add. Select Reader for the role. Search for the application you created in Step 1, and select it. Click Select at the bottom of the window.  After permissions have been set, return to Metricly to include or exclude as many Azure element types as you want. Azure VM and Azure Application Gateway are enabled by default.\nOptionally, filter elements.\nUse with Agents If you install our Linux agent or Windows agent on an Azure VM, the VM’s power state (attribute hostRunning with a value of true or false) and tags are copied over to the corresponding Linux SERVER element / Windows WINSRV element. You can then use this information to create policies.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-metrics/",
	"title": "Azure Metrics",
	"tags": ["#microsoft", "#azure", "#integrations", "#metrics"],
	"description": "",
	"content": " All of the metrics for Azure can be found in this folder.\nMetrics Available \rApplication Gateway\r\r\rBasic Metrics\r\r\rBoot Diagnostics\r\r\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/microsoft-azure-policies/",
	"title": "Azure Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#azure"],
	"description": "",
	"content": "Policy names are prefixed with Azure VM –\n\r   Policy name Metrics Required Duration Condition 1 (and) Condition 2 (and) Condition 3 Cat. Description     CPU Threshold Exceeded Boot Diagnostics 15 min Processor.PercentProcessorTime has a static threshold \u0026gt; 50%   WARNING The CPU on the Azure Virtual Machine has exceeded 95% for at least 15 minutes.   Elevated CPU Activity (Normal Network Activity) Boot Diagnostics 30 min Processor.PercentProcessorTime has an upper baseline deviation + an upper contextual deviation + a static threshold \u0026gt; 20% NetworkInterface.BytesReceived has no deviation NetworkInterface.BytesTransmitted has no deviation INFO Increases in CPU activity are not uncommon when there is a rise in network activity. Increased traffic to a server means more work for that server to do. This policy is designed to catch cases where CPU activity is higher than than normal and said behavior cannot be explained by a corresponding increase in network traffic. It may or may not represent a problem, but it is useful to know about. This policy will not fire if CPU utilization is less than 20% though.   Elevated Disk Activity Boot Diagnostics 30 min PhysicalDisk.ReadsPerSecond has an upper baseline deviation + an upper contextual deviation PhysicalDisk.WritesPerSecond has an upper baseline deviation + an upper contextual deviation  INFO Disk activity has been higher than expected for at least 30 minutes.   Elevated Memory Utilization Basic Metrics 15 min Memory.PercentUsedMemory has an upper baseline deviation + an upper contextual deviation   WARNING The memory utilization on the Azure Virtual Machine is higher than expected.   Elevated Network Activity Boot Diagnostics 30 min NetworkInterface.BytesReceived has an upper baseline deviation + an upper contextual deviation NetworkInterface.BytesTransmitted has an upper baseline deviation + an upper contextual deviation  INFO Network activity has been higher than expected for at least 30 minutes.   Heavy Disk Load Basic Metrics 5 min PhysicalDisk.AverageDiskQueueLength has an upper baseline deviation + an upper contextual deviation   WARNING Average disk queue length is greater than expected, which could indicate a problem with heavy disk load.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/analytics/baseline-bands/",
	"title": "Baseline Bands",
	"tags": ["#getting started", "#analytics", "#metrics"],
	"description": "",
	"content": " Baseline Bands represent the normal operating range of a metric. Metricly determines the normal operating range of a metric based on weekly patterns in the behavior of that metric.\nThe image below provides an example of Baseline bands in green surrounding the actual, current value for a CPU utilization metric in black. The green band demonstrates how Metricly learns the expected behavior of the metric based on patterns in the behavior of that metric.\nTo leverage the behavior learning capabilities of Baseline bands, use Upper or Lower Baseline Deviation condition tests in a policy. For more information about Baseline Deviation tests, see Conditions.\nBaseline Example  A policy with a Static Threshold condition of greater than 95% is applied to the CPU utilization metric for a server element. The actual value of that CPU utilization metric is often greater than 95% at 2:00 PM every Monday.  Using a Static Threshold test, the policy generates a Critical event every Monday at 2:00 PM when the value of the metric exceeds 95%. After changing the Static Threshold test to an Upper Baseline Deviation test, events are no longer generated when the CPU utilization metric exceeds 95% on Mondays at 2:00 PM. This is because Metricly uses Baseline bands to learn this pattern. So, the spike in CPU utilization that occurs on Monday afternoons is not perceived as abnormal behavior, resulting in fewer false alarms.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-metrics/azure-basic-metrics/",
	"title": "Basic Metrics",
	"tags": ["#microsoft", "#azure", "#integrations", "#metrics"],
	"description": "",
	"content": "   Fully Qualified Name (FQN) Type Units Statistic Min Max Sparse Data Strategy (SDS) BASE CORR UTIL Description     azure.virtualmachine.memory.availablememory GAUGE bytes average 0 none none yes no no The total amount of available memory in bytes.   azure.virtualmachine.memory.availableswap GAUGE bytes average 0 none none yes no no The total amount of swap space available in bytes.   azure.virtualmachine.memory.pagespersec GAUGE pages / second average 0 none none yes yes no The total number of pages read and written per second.   azure.virtualmachine.memory.pagesreadpersec GAUGE pages / second average 0 none none yes no no The number of pages read per second.   azure.virtualmachine.memory.pageswrittenpersec GAUGE pages / second average 0 none none yes no no The number of pages written per second.   azure.virtualmachine.memory.percentavailablememory GAUGE percent average 0 100 none yes no no Percentage of memory available.   azure.virtualmachine.memory.percentavailableswap GAUGE percent average 0 100 none yes no no Percentage of swap space available.   azure.virtualmachine.memory.percentusedbycache GAUGE percent average 0 100 none yes no no Percentage of memory used by cache.   azure.virtualmachine.memory.percentusedmemory GAUGE percent average 0 100 none yes yes yes Percentage of memory in use.   azure.virtualmachine.memory.percentusedswap GAUGE percent average 0 100 none yes no no Percentage of swap space in use.   azure.virtualmachine.memory.usedmemory GAUGE bytes average 0 none none yes no no The total amount of memory used in bytes.   azure.virtualmachine.memory.usedswap GAUGE bytes average 0 none none yes no no The total amount of swap space used in bytes.   azure.virtualmachine.networkinterface.bytesreceived COUNTER bytes  0 none none yes no no Bytes received over the network.   azure.virtualmachine.networkinterface.bytestotal COUNTER bytes  0 none none yes no no Total bytes received and transmitted over the network.   azure.virtualmachine.networkinterface.bytestransmitted COUNTER bytes  0 none none yes no no Bytes transmitted over the network.   azure.virtualmachine.networkinterface.packetsreceived COUNTER count  0 none none yes no no Packets received over the network.   azure.virtualmachine.networkinterface.packetstransmitted COUNTER count  0 none none yes no no Packets transmitted over the network.   azure.virtualmachine.networkinterface.totalcollisions COUNTER count  0 none none no no no Total number of packet collisions.   azure.virtualmachine.networkinterface.totalrxerrors COUNTER count  0 none none no no no Total receive errors.   azure.virtualmachine.networkinterface.totaltxerrors COUNTER count  0 none none no no no Total transmit errors.   azure.virtualmachine.physicaldisk.averagediskqueuelength GAUGE count average 0 none none yes yes no Average length of the physical disk queue.   azure.virtualmachine.physicaldisk.averagereadtime GAUGE milliseconds average 0 none none yes no no Average read time in milliseconds.   azure.virtualmachine.physicaldisk.averagetransfertime GAUGE milliseconds average 0 none none yes no no Average transfer time (reads and writes) in milliseconds.   azure.virtualmachine.physicaldisk.averagewritetime GAUGE milliseconds average 0 none none yes no no Average write time in milliseconds.   azure.virtualmachine.physicaldisk.bytespersecond GAUGE bytes / second average 0 none none yes no no Average bytes per second (read and written).   azure.virtualmachine.physicaldisk.readbytespersecond GAUGE bytes / second average 0 none none yes no no Average bytes read per second.   azure.virtualmachine.physicaldisk.readspersecond GAUGE iops average 0 none none yes no no Average number of read operations per second.   azure.virtualmachine.physicaldisk.transferspersecond GAUGE iops average 0 none none yes no no Average number of read and write operations per second (IOPS).   azure.virtualmachine.physicaldisk.writebytespersecond GAUGE bytes / second average 0 none none yes no no Average bytes written per second.   azure.virtualmachine.physicaldisk.writespersecond GAUGE iops average 0 none none yes no no Average number of write operations per second.   azure.virtualmachine.processor.percentdpctime GAUGE percent average 0 100 none no no no Percentage of time spent on deferred procedure calls (DPCs), also known as soft interrupts.   azure.virtualmachine.processor.percentidletime GAUGE percent average 0 100 none yes no no Percentage of time the CPU was idle.   azure.virtualmachine.processor.percentinterrupttime GAUGE percent average 0 100 none no no no Percentage of time spent on hardware interrupts.   azure.virtualmachine.processor.percentiowaittime GAUGE percent average 0 100 none no no no Percentage of time spent waiting for IO to complete.   azure.virtualmachine.processor.percentnicetime GAUGE percent average 0 100 none no no no Percentage of time spent on low priority (“nice”) processes.   azure.virtualmachine.processor.percentprivilegedtime GAUGE percent average 0 100 none yes no no Percentage of time spent on OS processes.   azure.virtualmachine.processor.percentprocessortime GAUGE percent average 0 100 none yes no no Percentage of time the processor was not idle.   azure.virtualmachine.processor.percentusertime GAUGE percent average 0 100 none yes no no Percentage of time spent on user processes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-metrics/azure-boot-diagnostics/",
	"title": "Boot Diagnostics",
	"tags": ["#microsoft", "#azure", "#integrations", "#metrics"],
	"description": "",
	"content": "   Fully Qualified Name (FQN) Type Units Statistic Min Max Sparse Data Strategy (SDS) BASE CORR UTIL Description     azure.virtualmachine.networkin GAUGE bytes average 0 none none yes yes no Bytes received over the network. Note that this metric is the same as the Basic Metric azure.virtualmachine.networkinterface.bytesreceived   azure.virtualmachine.networkout GAUGE bytes average 0 none none yes yes no Bytes transmitted over the network. Note that this metric is the same as the Basic Metric azure.virtualmachine.networkinterface.bytestransmitted   azure.virtualmachine.diskreadbytes GAUGE bytes average 0 none none yes no no Average bytes read from the physical disks.   azure.virtualmachine.diskreadoperationssec GAUGE iops average 0 none none yes no no Average number of read operations per second. Note that this metric is the same as the Basic Metric azure.virtualmachine.physicaldisk.readspersecond. Not available on classic VMs.   azure.virtualmachine.diskwritebytes GAUGE bytes / second average 0 none none yes no no Average bytes written to the physical disks.   azure.virtualmachine.diskwriteoperationssec GAUGE iops average 0 none none yes no no Average number of write operations per second. Note that this metric is the same as the Basic Metric azure.virtualmachine.physicaldisk.writespersecond. Not available on classic VMs.   azure.virtualmachine.percentagecpu GAUGE percent average 0 100 none yes yes yes Percentage of time the processor was not idle. Note that this metric is the same as the Basic Metric azure.virtualmachine.processor.percentprocessortime    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/diamond-agent-cpu-metrics/",
	"title": "CPU Metrics",
	"tags": ["#diamond", "#integrations", "#agents", "#cpu"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     cpu.total.guest Percentage of CPU spent running virtual CPUs for guest operatingsystems. average percent 0 none none yes no no   cpu.total.guest_nice Percentage of CPU spent running low-priority virtual CPUs for guestoperating systems. average percent 0 none none yes no no   cpu.total.idle Percentage of CPU not doing any work. average percent 0 none none yes no no   cpu.total.iowait Percentage of CPU time spent waiting for I/O to complete. average percent 0 none none yes no no   cpu.total.irq Percentage of CPU time spent processing hardware interrupts. average percent 0 none none yes no no   cpu.total.nice Percentage of CPU spent running user processes at low priority. average percent 0 none none yes no no   cpu.total.softirq Percentage of CPU time spent processing software interrupts. average percent 0 none none yes no no   cpu.total.steal Percentage of CPU time spent in other operating systems when running ina virtualized environment. average percent 0 none none yes no no   cpu.total.system Percentage of CPU spent running system processes. average percent 0 none none yes no no   cpu.total.user Percentage of CPU spent running user processes. average percent 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Units Min Max BASE CORR UTIL     metriclyicly.linux.cpu.total.utilization.percent The overall average CPU Utilization across all CPUs. This is anormalized metric. Computation: (data[‘cpu.total.idle’] != null \u0026amp;\u0026amp; data[‘cpu.total.idle’].actual!= null) ? ((data.sum(‘cpu.total.*’) – data[‘cpu.total.idle’].actual) /data.sum(‘cpu.total.*’)) * 100 : data[‘cpu.cpu0.idle’] != null ?((data.sum(‘cpu[.].’) – data.sum(‘cpu[.]..idle’)) /data.sum(‘cpu[.].*’)) * 100 : null percent 0 100 yes yes yes   metriclyicly.linux.cpu.total.normalized.user Percentage of CPU spent running user processes. This is a normalizedmetric. Computation: attribute[‘cpus’] == null ? null : data[‘cpu.total.user’] /attribute[‘cpus’].value percent 0 100 yes yes no   metriclyicly.linux.cpu.total.normalized.system Percentage of CPU spent running system processes. This is a normalizedmetric. Computation: attribute[‘cpus’] == null ? null : data[‘cpu.total.system’] /attribute[‘cpus’].value percent 0 100 yes yes no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-cpu-metrics/",
	"title": "CPU Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#cpu", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     cpu-#.cpu-idle.value Number of jiffies the CPU spent idle. average jiffies 0 none none yes no no   cpu-#.cpu-interrupt.value Number of jiffies the CPU spent processing hardware interrupts. average jiffies 0 none none yes no no   cpu-#.cpu-nice.value Number of jiffies the CPU spent processing low priority user threads. average jiffies 0 none none yes no no   cpu-#.cpu-softirq.value Number of jiffies the CPU spent processing software interrupts. average jiffies 0 none none yes no no   cpu-#.cpu-steal.value Number of jiffies “stolen” for other tasks in a virtualized environment. average jiffies 0 none none yes no no   cpu-#.cpu-system.value Number of jiffies the CPU spent processing system threads. average jiffies 0 none none yes no no   cpu-#.cpu-user.value Number of jiffies the CPU spent processing user threads. average jiffies 0 none none yes no no   cpu-#.cpu-wait.value Number of jiffies the CPU spent waiting for IO to complete. average jiffies 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Statistic Units Min Max BASE CORR UTIL     cpu-avg.cpu-idle Computation: data.avg(‘cpu-.*.cpu-idle.value’) average jiffies 0 none no no no   cpu-avg.cpu-interrupt Computation: data.avg(‘cpu-.*.cpu-interrupt.value’) average jiffies 0 none no no no   cpu-avg.cpu-nice Computation: data.avg(‘cpu-.*.cpu-nice.value’) average jiffies 0 none no no no   cpu-avg.cpu-softirq Computation: data.avg(‘cpu-.*.cpu-softirq.value’) average jiffies 0 none no no no   cpu-avg.cpu-steal Computation: data.avg(‘cpu-.*.cpu-steal.value’) average jiffies 0 none no no no   cpu-avg.cpu-system Computation: data.avg(‘cpu-.*.cpu-system.value’) average jiffies 0 none no no no   cpu-avg.cpu-user Computation: data.avg(‘cpu-.*.cpu-user.value’) average jiffies 0 none no no no   cpu-avg.cpu-wait Computation: data.avg(‘cpu-.*.cpu-wait.value’) average jiffies 0 none no no no   cpu-avg.total-jiffies Represents the total number of jiffies in the last cycle. Computation: cpu-avg.cpu-idle + cpu-avg.cpu-interrupt + cpu-avg.cpu-nice +cpu-avg.cpu-softirq + cpu-avg.cpu-steal + cpu-avg.cpu-system +cpu-avg.cpu-user + cpu-avg.cpu-wait average jiffies 0 none no no no   cpu-avg.cpu-idle.percent Computation: (cpu-avg.cpu-idle / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-interrupt.percent Computation: (cpu-avg.cpu-interrupt / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-nice.percent Computation: (cpu-avg.cpu-nice / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-softirq.percent Computation: (cpu-avg.cpu-softirq / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-steal.percent Computation: (cpu-avg.cpu-steal / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-system.percent Computation: (cpu-avg.cpu-system / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-user.percent Computation: (cpu-avg.cpu-user / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes yes   cpu-avg.cpu-wait.percent Computation: (cpu-avg.cpu-wait / cpu-avg.total-jiffies) * 100 average percent 0 100 yes yes no   cpu-avg.cpu-total-utilization.percent Computation: 100 – cpu-avg.cpu-idle.percent average percent 0 100 yes yes yes   Utilization If Diamond metrics are also available on the sameelement (either from Diamond directly or from the Metricly Agent), theDiamond CPU Utilization will take precedence over the CollectdUtilization. Computation :cpu-avg.cpu-total-utilization.percent average percent 0 100 yes no yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/docker/docker-metrics/docker-cpu-metrics/",
	"title": "CPU Metrics",
	"tags": ["#docker", "#integrations", "#metrics", "#cpu"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Type Units Statistic* BASE CORR Description     cpu.cpu_usage.percpu_usage* COUNTER nanoseconds  yes no Each CPU has a separate metric which tracks the number of nanoseconds that that specific CPU has been used since the container was started.   cpu.cpu_usage.total_usage COUNTER nanoseconds  yes no This metric is the sum of all of the per-CPU usage metrics. Thus, it represents the total number of nanoseconds that all CPUs have been in use since the container was started. It is important to bear in mind that there could be overlap. In other words, if this metric shows 10 seconds of CPU usage, it could be that both CPUs were busy for the same 5 seconds of time.   cpu.cpu_usage.usage_in_kernelmode COUNTER nanoseconds  yes no This is the number of nanoseconds of total_usage that was spent on kernel (OS) level threads.   cpu.cpu_usage.usage_in_usermode COUNTER nanoseconds  yes no This is the number of nanoseconds of total_usage that was spent on user threads.   cpu.system_cpu_usage COUNTER nanoseconds  yes no This metric is a little confusing, as it is the number of nanseconds used by the host since the host started; however, it is the sum of all CPU metrics, including idle, so it should be increasing at a constant rate. Put another way, when doing the deltas between intervals, the value should always be equal to the interval length times the number of CPUs. In practice, the number is always a bit less than this and experiences variations, possibly due to measurement error.   cpu.throttling_data.periods COUNTER count  yes no The number of “periods” during which the CPU for the container could have been thottled. If throttling is not enabled for the container, this value will always be 0.   cpu.throttling_data.throttled_periods COUNTER count  no no The number of “periods” during which the CPU for the container actuallywas thottled. If throttling is not enabled for the container, this value will always be 0. In all cases, this value will be less than or equal to the periods metric.   cpu.throttling_data.throttled_time COUNTER count  no no \u0026ldquo;The amount of time in nanoseconds taht the container has spent being throttled.\u0026rdquo;    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/cassandra/",
	"title": "Cassandra",
	"tags": ["#cassandra", "#integrations"],
	"description": "",
	"content": " Cassandra is an open source distributed database management system. We use the Jolokia agent to monitor Cassandra’s performance as Cassandra exposes its metrics via JMX. Jolokia connects to a given mbean server and then exposes the server via a REST-like interface, acting as a bridge between JMX and HTTP/JSON.\nConfiguration  Download the Jolokia JVM JAR file.  Move the downloaded file to the /opt/netuitive-agent/ directory. Add the following line to the very end of the cassandra-env.sh file (typically located in /etc/cassandra/conf or /opt/cassandra/conf):   JVM_OPTS=\u0026quot;$JVM_OPTS -javaagent:/opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar\u0026quot;  If you’re running Cassandra in a container, you’ll need to add –javaagent:/opt/agent.jar=port=8778,host=0.0.0.0 to the end of the line above.\n\r2. Restart Cassandra, and confirm Jolokia is running by accessing http://localhost:8778/jolokia/ 3. Navigate to the collectors folder. The default location is /opt/netuitive-agent/conf/collectors. 4. Open the CassandraJolokiaCollector.conf file. 5. Change the enabled setting to True, save the file, and restart the Linux agent.\nThis integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\nCollector options    Option Default Description     enabled FALSE Enable collecting Cassandra metrics.   host localhost Hostname to collect from.   port 8778 Port to collect from.   path cassandra The metric prefix, e.g., how you want the metrics to show up in Metricly.   jolokia_path jolokia Part of the URL path that points to where your application serves metrics. Typically jmx or jolokia.   mbeans org.apache.cassandra.metrics Pipe (   metrics_blacklist see below Regex list to match metrics to block. Mutually exclusive with metrics_whitelistoption.   byte_unit  Default numeric output(s).   histogram_regex  Filter to only process attributes that match the specified regex.   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.   password  Password used for authentication.   percentiles  Comma separated list of statistical percentiles to collect.   regex  Enables the mbeans option to match with regex.   rewrite  Config sub-section that contains pairs of from-to regex rewrites. See below for example.   username  Username used for authentication.    Metrics Blacklist .*Histogram.*|.*Percentile$|.*\\.Min$|.*\\.Max$|.*\\.Mean$|.*\\.Count$|.*\\.StdDev$|.*\\. MeanRate$|.*\\.FiveMinuteRate$|.*\\.FifteenMinuteRate$|.*DroppedMessage.*|.*Last GcInfo.*|Keyspace._Keyspaces.system.*|Keyspace._Keyspaces.*_Tables.*  Rewrite mbeans = \u0026quot;...\u0026quot; [rewrite] java = coffee \u0026quot;-v\\d+\\.\\d+\\.\\d+\u0026quot; = \u0026quot;-AllVersions\u0026quot; \u0026quot;.*Gets2Activities.*\u0026quot; = \u0026quot;...  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/cassandra-policies/",
	"title": "Cassandra Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#cassandra"],
	"description": "",
	"content": "   Policy name Duration Conditions Category Description     Depressed Key Cache Hit Rate 30 min cassandra.Cache.KeyCache.HitRate has an lower baseline deviation + a static threshold ≤ 0.85 WARNING The hit rate for the key cache is lower than expected and is less than 85%. This condition has been persisting for at least the past 30 minutes.   Elevated Node Read Latency 30 min cassandra.Keyspace.ReadLatency.OneMinuteRate has an upper baseline deviation WARNING The overall keyspace read latency on this Cassandra node has been higher than expected for at least 30 minutes.   Elevated Node Write Latency 30 min cassandra.Keyspace.WriteLatency.OneMinuteRate has an upper baseline deviation WARNING The overall keyspace write latency on this Cassandra node has been higher than expected for at least 30 minutes.   Elevated Number of Pending Compaction Tasks 15 min cassandra.Compaction.PendingTasks has an upper baseline deviation WARNING The number of pending compaction tasks has been higher than expected for at least the past 15 minutes. This could indicate that the node is falling behind on compaction tasks.   Elevated Number of Pending Thread Pool Tasks 15 min cassandra.ThreadPools.*.PendingTasks has an upper baseline deviation WARNING For at least the past 15 minutes, the number of pending tasks for one or more thread pools has been higher than expected. This could indicate that the pools are falling behind on their tasks.   Unavailable Exceptions Greater Than Zero 5 min cassandra.*Unavailables.OneMinuteRate has a static threshold ≤1 CRITICAL The required number of nodes were unavailable for one or more requests.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/metrics/metric-charts/",
	"title": "Chart Features",
	"tags": ["#getting started", "#metrics", "#charts"],
	"description": "",
	"content": " Metric Charts Metric charts on the Metrics page allow you to view time-series data collected on elements in your environment. The range of data shown in metric charts corresponds to the range of data shown in the Events graph. This allows you to compare event data to the metric behavior that caused it.\nMetric Metadata Click the metric name to open the metric metadata panel.    Metadata Description     Avg The average value recorded in the last cycle.   Baselined If the Baseline Band analysis is enabled or disabled for the metric.   Correlated If the Contextual Band analysis is enabled or disabled for the metric.   Count The amount of values recorded in the last cycle.   Created When the metric was created.   Element Detail Opens that element’s Element Detail panel in the Inventory Explorer.   FQN The fully qualified name (FQN) of the metric.   Historical Max Historically, the highest value the metric has experienced.   Historical Min Historically, the lowest value the metric has experienced.   ID The full ID of the metric.   Max. The maximum value recorded in the last cycle.   Min. The minimum value recorded in the last cycle.   Sparse Mode Defines the strategy for replacing missing data. Either missing data is replaced with a zero (ReplaceWithZero) or no strategy is taken at all (None).   Sum The sum of values recorded in the last cycle.   Type The type of metric; currently, the only two values are “collected” or “computed.”   Units The type of measurement the metric is collected in.   Updated The time the last five-minute cycle occurred in which the data was updated.   Valid Max If set, the valid maximum value the metric can have.   Valid Min If set, the valid minimum value the metric can have.   Value Used The type of aggregation used in the analysis cycle    Metric Submenu  Metric Unit: Change the displayed unit (UI only; does not affect default unit metadata). Aggregation(s): Select which aggregate values you want to display on the metric chart. Avg is the default. Each aggregation corresponds to a different color. Computed metrics do not have aggregations available. Download Buttons: Download the current chart for this metric to a .png, .jpg, or .svg file. Add to Dashboard: Add any metric chart to the desired dashboard as a single metric time series widget (see below). Other Elements with this Metric: View other elements with the same metric and open the respective elements’ metric chart (see below).  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-check-version/",
	"title": "Check Version",
	"tags": ["#windows", "#integrations"],
	"description": "",
	"content": "You may need the verify the version of the Windows agent you’re currently using.\n Open the [Element Detail panel][1] for a WINSRV element. Navigate to Attributes (squared in green). Verify that the agent (squared in blue) contains the correct version number.  [1] :/data-visualization/inventory\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/checks/",
	"title": "Checks",
	"tags": ["#alerts", "#notifications", "#checks"],
	"description": "",
	"content": " Checks are used to determine the state or health of infrastructure resources, services, or applications.\nDynamic and customizable, Checks allow you to define a time duration and then notify you when that state change occurs. Checks can be completely custom built by you or leverage our OOTB checks.\nPrerequisites You must have already installed and configured a Windows and/or Linux agent to set up checks.\nWe recommend you update your agents to their latest version before using this document.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/chef/",
	"title": "Chef",
	"tags": ["#chef", "#integrations"],
	"description": "",
	"content": " Chef is a configuration automation management software that allows you setup multiple servers using a few commands from a Chef server and workstation. The Metricly Agent cookbook will help you get the Metricly Linux Agent up and running on all of your nodes quickly.\nConfiguration If you’ve managed to set up your Chef workstation, server, and nodes, check out our open source Chef cookbook on Github, which will get you started on installing the Metricly Agent on all of your nodes.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/choose-duration/",
	"title": "Choose Duration",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#duration"],
	"description": "",
	"content": " Duration is the consecutive length of time for which all the conditions in a policy must be met before an event or other optional notification is created. The default setting for metric condition duration is 5 minutes; the default (and only) setting for external event condition duration is real-time. Because Metricly aggregates data on five-minute cycles, the duration for metric conditions must be at least 5 minutes.\nBy setting the duration of ExamplePolicy X to 10 minutes, an event will not be created in Metricly until all the conditions in ExamplePolicy X have been met for the same period of 10 consecutive minutes.\n\rSet a Duration On Policy Editor, under the 2. Conditions section:\n Metric Conditions: Select between 5 minutes and 6 hours. External Event Conditions: Real-time is the only available option.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/events/cloudwatch-events/",
	"title": "CloudWatch Events",
	"tags": ["#alerts", "#notifications", "#events", "#cloudwatch"],
	"description": "",
	"content": " Through a combination of SNS Notifications, Metricly’s Webhook integration, and an external event conditions policy filter, you can push event logs from your AWS services to Metricly and act on them in the UI. This works across several AWS services. Once set up, these logs can be divided further on the policy level (through matching value strings in the log message and categorized by severity). Policies for your event logs can also be set up with various notifications through email, slack, and others. The below instructions use Lambda as an example.\nConfiguration 1. Create \u0026amp; Subscribe to SNS Topic You must have AWS SNS setup to complete this section. Read our SNS Guide to complete setup. If you have already set up Amazon’s SNS, continue on.\n Open your AWS console and navigate to the SNS Dashboard. Click Topics \u0026gt; Create new topic. Name and describe the new topic. Click Create topic. Select your created topic and click Actions \u0026gt; Subscribe to topic. For the next step, you need to obtain a Metricly API endpoint and paste it as the URL.\n\r In a separate tab, log into Metricly and navigate to Integrations \u0026gt; Webhooks.  Copy the POST URL. Paste the URL in the Endpoint field on your AWS tab and click Create Subscription.  AWS sends a validation URL to Metricly, which you then have to locate as an Event item in the UI. Log into Metricly and go to Events. In the Type filter, you can select WEBHOOK to narrow your search. Click on the event to read its details. \u0026quot;SubscriberURL\u0026quot;: is the link you are looking for.  Copy this URL, return to the AWS console. Navigate to AWS SNS \u0026gt; Topics and select the topic you have created. Click Actions \u0026gt; Confirm a subscription.  Input the URL you pasted from Metricly into the field and click Confirm subscription. Note that you can unsubscribe by using the \u0026quot;UnsubscribeURL\u0026quot;: provided in the same messages.  2. Create IAM Role To write logs for Lambda to CloudWatch Logs, you must create a custom IAM Role with the appropriate policies/permissions.\n Log in to your AWS Identity \u0026amp; Access Management (IAM) Console. Once in the IAM dashboard, navigate to the Roles section. Click Create New Role. Select AWS Service \u0026gt; Lambda.  Click Next: Permissions. Click Create Policy. This action opens a new tab. Select the JSON tab and input the following code in the text field:   { \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;logs:CreateLogGroup\u0026quot;, \u0026quot;logs:CreateLogStream\u0026quot;, \u0026quot;logs:PutLogEvents\u0026quot;, \u0026quot;logs:DescribeLogStreams\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:logs:*:*:*\u0026quot; ] }] }  8. Name the policy CloudWatchLogs and click Create Policy.\n9. In your previous tab with the new Lamba role, look up the newly created policy CloudWatchLogs and select it.\n10. Click Next: Review.\n11. Provide a name, such as CloudWatchMetricly, and a description for the role.\n12. Click Create Role.\n3. Create Log Group Filter  Open your AWS console and Navigate to Services \u0026gt; Management Tools \u0026gt; CloudWatch. Click Logs on the navigation. Click Create log group and name your group. Select your log group and click Create Metric Filter.  Input any string you wish this filter to act upon that appears in the log. Timed Out and Error are common examples. In this case, we used START in the Filter Pattern. This grabs all Lambda functions in particular. To break events down into more specific actionable items, see the final section in this guide, Create Metricly Policies. Click Assign Metric. Name the metric. In this case, we call it CloudWatchEvent. This name displays in the Metricly UI. Click Create Filter.  4. Create Alert Now that you have created a log group and a filter for that group, let’s make an alarm.\n Open your AWS console and Navigate to Services \u0026gt; Management Tools \u0026gt; CloudWatch. Click Logs on the navigation. Click the 1 Filter link you created earlier.  Click Create Alarm. A modal Appears. Fill out the Alarm Threshold, Additional Settings, and Actions sections.  Name and Description (#1 and #2) can be named anything. Is: (#3) must be \u0026gt;= 1; For: (#4) must be 1 out of 1. Treat missing data as (#5) must be set to good (not breaching threshold). Whenever this alarm (#6) must be State is ALARM; Send notification to (#7) must be the SNS topic you’ve subscribed to in the first section of configuration, Create \u0026amp; Subscribe to SNS Topic. Click Create Alarm to save it.  5. Create Metricly Policies This is the most dynamic step. When creating Metricly policies, you can filter for strings within the log message body. If you only want one policy for all logs, for example, you can keep the match criteria generic. If you want multiple policies per certain codes, simply filter for those codes on your policy setup. Remember that you can also create notifications on these policies.\n Log into Metricly and navigate to Alerts \u0026gt; Add New Policy. Name your policy and select its Category (Info, Warning, or Critical). If you want to limit the scope to match the Webhook element, you may do so on the first tab. Click on the Conditions tab. Click Add Condition \u0026gt; Add External Event Condition. Populate the Message field to match the messages you want captured in this policy.  Click Save to activate the policy. Repeat 1-7 for as many policies as you’d like, each with different criteria in the Message filter field.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/",
	"title": "Collectd",
	"tags": ["#collectd", "#integrations", "#collectors"],
	"description": "",
	"content": " Collectd’s Write HTTP plugin can be used to configure collectd to send data to Metricly. If you need additional information about setting up Collectd, view their wiki.\nConfiguration 1. Copy API Key in Metricly  From the top navigation menu, click Integrations. Click the collectd card. Data collection should already be enabled, and a unique API key for your account has already been generated. Copy the API key.  2. Install \u0026amp; Configure Collectd Installation steps for collectd may vary widely between systems, so you’ll want to install collectd based on recommended steps for your distro and the version of collectd you downloaded. You can download the latest version of collectd here.\n After installing collectd, open your collectd.conf file. It can usually be found in /etc/collectd.conf. Set the Interval to 60. Setting the Interval to 60 will allow metrics to be collected and sent to Metricly every 60 seconds. Enable the following plugins by uncommenting them:  LoadPlugin cpu LoadPlugin disk LoadPlugin interface LoadPlugin load LoadPlugin memory LoadPlugin network LoadPlugin processes LoadPlugin write_http  4. In the \u0026lt;Plugin write_http\u0026gt; configuration section, replace API_KEY with the unique API key generated for your account that you copied in step 1.\n\u0026lt;Plugin \u0026quot;write_http\u0026quot;\u0026gt; \u0026lt;Node \u0026quot;example\u0026quot;\u0026gt; URL \u0026quot;https://api.app.metricly.com/ingest/collectd/API_KEY\u0026quot;; User \u0026quot;collectd\u0026quot; Password \u0026quot;weCh3ik0\u0026quot; Format JSON StoreRates true \u0026lt;/Node\u0026gt; \u0026lt;/Plugin\u0026gt;  5. Save the collectd.conf file.\n6. Restart collectd.\n7. Verify that collectd can determine its fully qualified hostname by checking the element name in your Inventory Explorer. The hostname should be unique. If collectd cannot correctly determine the hostname, set a unique hostname by replacing unique_fqn_of_your_host in the Hostname setting:\nHostname \u0026quot;unique_fqn_of_your_host\u0026quot;  This integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/collectd-policies/",
	"title": "Collectd Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#collectd"],
	"description": "",
	"content": "   Policy name Duration Conditions Category Description     Elevated Memory Usage (Collectd) 30 min metricly.collectd.memory.utilizationpercent has an upper baseline deviation INFO Indicates an increase in memory usage above what is considered to be normal.   Elevated Process Count 30 min metricly.collectd.processes.total has an upper baseline deviation INFO Indicates that the total number of processes has increased above what is considered to be normal.   Elevated Percentage of Blocked Processes 30 min metricly.collectd.processes.blockedpercent has an upper baseline deviation WARNING Indicates a higher-than-normal percentage of blocked processes.   Elevated Percentage of Zombie Processes 30 min metricly.collectd.processes.zombiepercent has an upper baseline deviation WARNING Indicates a higher-than-normal percentage of zombie processes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-metrics/java-agent-collected-metrics/",
	"title": "Collected Metrics",
	"tags": ["#java", "#integrations", "#metrics", "#agents"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Description Statistic Units Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     *.calls The number of calls made to the method. sum count 0 none none yes no no   *.errors The number of method calls that resulted in errors. sum count 0 none none yes no no   *.time The amount of time spent executing the method totaled across all calls. sum milliseconds 0 none none yes no no   *.avg_time The amount of time spent executing the method, averaged across allcalls. average milliseconds 0 none none yes no no   cpu.used.percent The percentage of CPU used by the JVM. average percent 0 100 none yes yes yes   gc.psmarksweep.collectiontime The amount of time the JVM spent doing “PS MarkSweep” garbagecollection. average milliseconds 0 300000 none yes no no   gc.psscavenge.collectiontime The amount of time the JVM spent doing “PS Scavenge” garbage collection. average milliseconds 0 300000 none yes no no   gc.concurrentmarksweep.collectiontime The amount of time the JVM spent doing “Concurrent MarkSweep” garbagecollection. average milliseconds 0 300000 none yes no no   gc.parnew.collectiontime The amount of time the JVM spent doing “ParNew MarkSweep” garbagecollection. average milliseconds 0 300000 none yes no no   gc.g1oldgeneration.collectiontime The amount of time the JVM spent doing “G1 Old Generation” garbagecollection. average milliseconds 0 300000 none yes no no   gc.g1newgeneration.collectiontime The amount of time the JVM spent doing “G1 Old Generation” garbagecollection. average milliseconds 0 300000 none yes no no   heap.committed The total amount of memory available for the heap. average bytes 0 none none yes no no   heap.used The total amount of memroy currently being used by the heap. average bytes 0 none none yes no no   mempool.codecache.committed The amount of memory currently allocated to the code cache. average bytes 0 none none yes no no   mempool.codecache.max The maximum amount of memory that could be allocated to the code cache. average bytes 0 none none yes no no   mempool.codecache.used The amount of committed memory currently used by the code cache. average bytes 0 none none yes no no   mempool.compressedclassspace.committed The amount of memory currently allocated to the compressed class space. average bytes 0 none none yes no no   mempool.compressedclassspace.max The maximum amount of memory that could be allocated to the compressedclass space. average bytes 0 none none yes no no   mempool.compressedclassspace.used The amount of committed memory currently used by the compressed class space. average bytes 0 none none yes no no   mempool.metaspace.committed The amount of memory currently allocated to the metaspace. average bytes 0 none none yes no no   mempool.metaspace.max The maximum amount of memory that could be allocated to the metaspace. average bytes 0 none none yes no no   mempool.metaspace.used The amount of committed memory currently used by the metaspace. average bytes 0 none none yes no no   mempool.psedenspace.committed The amount of memory currently allocated to the eden space. average bytes 0 none none yes no no   mempool.psedenspace.max The maximum amount of memory that could be allocated to the eden space. average bytes 0 none none yes no no   mempool.psedenspace.used The amount of committed memory currently used by the eden space. average bytes 0 none none yes no no   mempool.psoldgen.committed The amount of memory currently allocated to the old generation. average bytes 0 none none yes no no   mempool.psoldgen.max The maximum amount of memory that could be allocated to the oldgeneration. average bytes 0 none none yes no no   mempool.psoldgen.used The amount of committed memory currently used by the old generaion. average bytes 0 none none yes no no   mempool.pspermgen.committed The amount of memory currently allocated to the permanent generation. average bytes 0 none none yes no no   mempool.pspermgen.max The maximum amount of memory that could be allocated to the permanent generation. average bytes 0 none none yes no no   mempool.pspermgen.used The amount of committed memory currently used by the permanent generation. average bytes 0 none none yes no no   mempool.pssurvivorspace.committed The amount of memory currently allocated to the survivor space. average bytes 0 none none yes no no   mempool.pssurvivorspace.max The maximum amount of memory that could be allocated to the survivor space. average bytes 0 none none yes no no   mempool.pssurvivorspace.used The amount of committed memory currently used by the survivor space. average bytes 0 none none yes no no   system.LoadedClasses The number of classes loaded by the JVM. average count 0 none none yes yes no   system.threads The number of currently running threads. average count 0 none none yes yes no   system.UnloadedClasses The number of classes unloaded by the JVM. average count 0 none none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/categories/collector/",
	"title": "Collector",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/",
	"title": "Collectors",
	"tags": ["#agents", "#directory page", "#collectors"],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-metrics/java-agent-computed-metrics/",
	"title": "Computed Metrics",
	"tags": ["#java", "#integrations", "#metrics", "#agents"],
	"description": "",
	"content": " Computed    Fully Qualified Name (FQN) Description Statistic Units Min Max BASE CORR UTIL     netuitive.jvm.heap.utilizationpercent Percentage of the allocated heap memory that is currently in use.Computation:(Heap Used / Heap Committed) * 100 average percent 0 100 yes yes yes   netuitive.jvm.non-heap.utilizationpercent Percentage of the allocated non-heap memory that is currently in use.Computation:(Metaspace or PermGen Used + CodeCache Used / Metaspace or PermGen Committed + CodeCache Committed) * 100 average percent 0 100 yes yes yes   netuitive.jvm.total.utilizationpercent Percentage of the total allocated memory that is currently in use.Computation:(Heap Used + Metaspace or PermGen Used + CodeCache Used / Heap Committed + Metaspace or PermGen Committed + CodeCache Committed) * 100 average percent 0 100 yes yes yes   netuitive.method.*.errorpercent The percentage of method calls that resulted in errors.Computation:(Method Calls == 0) ? 0 : (Method Errors / Method Calls) * 100 average percent 0 100 yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/docker/docker-metrics/docker-network-metrics/",
	"title": "Computed Metrics",
	"tags": ["#docker", "#integrations", "#metrics"],
	"description": "",
	"content": " Computed    Name FQN Computation Units Min Max BASE CORR Description     Container CPU Percent netuitive.docker.cpu.container_cpu_percent data[‘cpu.system_cpu_usage’].actual == 0 ? 0 :(data[‘cpu.cpu_usage.total_usage’].actual /data[‘cpu.system_cpu_usage’].actual) * 100 percent 0 100 yes yes The percentage of total CPU being used by the container.   Container Memory Percent netuitive.docker.cpu.container_memory_percent (data[‘memory.usage’].actual / data[‘memory.limit’].actual) * 100 percent 0 100 yes yes The amount of memory in use by the container, expressed as a percentage of the memory available to it.   Container Throttling Percent netuitive.docker.cpu.container_throttling_percent data[‘cpu.throttling_data.periods’].actual == 0 ? 0 :(data[‘cpu.throttling_data.throttled_periods’].actual /data[‘cpu.throttling_data.periods’].actual) * 100 percent 0 100 yes yes The percentage of periods that the container spent having its CPU usage throttled.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/consul/",
	"title": "Consul",
	"tags": ["#consul", "#integrations"],
	"description": "",
	"content": " Each node (and service per node) has a set of checks.\n A node or service is marked critical if any check is marked critical for the node or service. A node or service is marked warning if any check is marked, so long as there are no criticals. A node or service is marked passing if no checks are marked.  Configuration These steps assume you have already set up Consul service. If you have not yet set up Consul, view their GitHub to get started.\n1. Linux Agent The Linux Agent must be installed in order to collect Consul metrics.\n2. ConsulCollector.conf To enable metric collection, update the /opt/netuitive-agent/conf/collectors/ConsulCollector.conf file:\nenabled = True url = http://localhost:8500  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/analytics/contextual-bands/",
	"title": "Contextual Bands",
	"tags": ["#getting started", "#analytics", "#metrics"],
	"description": "",
	"content": " Contextual Bands represent the range of current expected values for a metric based on other correlated metrics in the learned model. In contrast to Baseline bands which look for patterns in a metric in isolation, Contextual bands take into account how the value of one metric may impact another.\nThe image below provides an example of a Contextual band in purple surrounding the actual, current value for a metric called Bytes In Per Second. The purple band demonstrates how Metricly is able to use other correlated metrics to learn the expected value of the Bytes In Per Sec metric.\nContextual Deviation conditions allow you to use Contextual bands to monitor the elements in your environment. For more information about creating policies using Contextual Deviation conditions, see Conditions.\nContextual Example  A policy with a Static Threshold condition of greater than 90% is applied to the CPU utilization metric for a server element. Often, when network activity increases for this element, so does CPU Utilization. However, each time network activity spikes and CPU utilization exceeds 90%, a Critical event is generated.  By changing the Static Threshold condition to an Upper Contextual Deviation condition, these false alarms can be avoided. If Metricly learns that a CPU utilization metric and a network activity metric belonging to the same server element are positively correlated, then it is able to determine the expected value for CPU utilization at any time, given the value of network activity. So, if the value of CPU utilization suddenly spikes to 96%, but the value of network activity shows a similar increase, Metricly would conclude that the rise in CPU utilization is not cause for an event, since it is not uncommon to see a rise in CPU utilization when there is also a rise in network activity.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/copy-dashboard/",
	"title": "Copy a Dashboard",
	"tags": ["#getting started", "#metrics", "#elements", "#dashboards"],
	"description": "",
	"content": " Copy a Dashboard A quick and easy way to create a customized dashboard is to copy a defaulted one and edit it.\n Navigate to Dashboards \u0026gt; Select Dashboard Name. Click on \r\u0026gt; Copy.  Rename the Dashboard. Edit the widgets by clicking … \u0026gt; Settings or Delete.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/cost-explorer-widget/",
	"title": "Cost Explorer Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "Options for this widget type include: period comparison, service total, and doughnut.\nThe Period Comparison option enables you to select a current timeframe (day, month, 6 months, etc) and compare its previous timeframe interval. For example, the below screenshot shows a current 6 month period comparison of May 16, 2018 – November 15, 2018 and a previous 6 month interval of November 16, 2017 – May 15, 2018.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-cost/",
	"title": "Cost Reports",
	"tags": ["#reports", "#s3", "#ec2", "#rds"],
	"description": "",
	"content": " Cost reports enable you to easily identify expensive instances and compare them against utilization, type, elements, and tags. These multi-dimensional reports also break down information like total versus individual instance costs and even how much each instance state (Reserved, On-Demand) costs. Custom tagging is another easy way to group your instances.\nCost Reports are generated once per week. It may take up to 7 days before your first report is available.\nReport Versions Estimated Cost (AWS Integration Only) If you just have an AWS integration in Metricly, the Estimated Cost report is available. Instance costs are estimated based on current list prices and simple assumptions to fill in missing information. For a more accurate view including reservations, data transfer costs, iops guarantees and other account specific charges, you can add an AWS Cost integration that allows Metricly to use your actual billing files from AWS.\nEstimated Cost reports use 7 days of metric results and the current list prices to estimate element instance costs for all instances monitored by Metricly. Estimated Reports do not include data transfer costs and assumes all instances are on-demand.\nFull Cost (AWS+AWS Cost Integration) If you have both an AWS and AWS Cost integration, the Full Cost report is available and based on your billing files. The Full Cost report reads 7 days of billing data associated with the instances monitored by Metricly.\nCosts are aggregated, simplified, and reduced to the following categories element:\n   Type Cost Description     Hourly Instance Fees On-Demand Instance Hourly fee for an on-demand instance   Hourly Instance Fees Spot Instance Hourly fee for a spot instance   Hourly Instance Fees Reserved Instance Hourly fees for partial upfront or no-upfront reserved instances   Hourly Instance Fees Amortized Upfront Reservation Fee Amortized upfront fees for partial upfront or all-upfront instances **   Hourly Instance Fees Dedicated Instance Hourly fee for a dedicated instance   Hourly Instance Fees Instance EBS Optimized Charge Hourly incremental fee for EBS optimized instances (applies to certain instance types)   Hourly Instance Fees Instance Dedicated Charge Hourly incremental fee for dedicated host   Data Transfer Costs* Data In – InterZone Costs for data transfer to/from another AWS service in another availability zone or peered VPC in the same region   Data Transfer Costs* Data In – InterRegion Costs for data transfer to/from another AWS service in another region   Data Transfer Costs* Data In – PublicIP Costs for data transfer to/from another AWS service via a public or elastic IP address   Data Transfer Costs* Data In – Internet Costs for data transfer to/from the instance from/to the internet   Data Transfer Costs* Data In – CloudFront Costs for data transfer to/from the instance via CloudFront   Data Transfer Costs* Other Other data transfer costs (e.g., Direct Connect)    5-7 days of analysis is required before you can view your initial report. A splash screen greets you in place of the report until Metricly is done generating it.\n\rReport Views This section outlines all of the available report views.\nTotal Cost Pareto This graph shows the total costs incurred for all the instances monitored by Metricly (or the subset if a filter has been applied). The line is plotted against the right-hand axis and shows a cumulative percent contribution of each of the bars. Use this view to see the total cost of your environment and total contributions by category.\nAll cost categories are shown in this chart even if you have incurred no costs of a particular type. For the Estimated Cost report, you may see just one bar. Cost by Element This graph breaks down how much each element is costing by category. The line is plotted against the right-hand axis and shows the utilization of each element. With this view, you can compare the relative cost of elements versus their level of utilization. This chart only shows the cost categories that you have actually incurred. Cost by Instance Type This graph breaks down how much each instance size is costing by instance type. The line is plotted against the right-hand axis and shows the maximum of the utilizations of all elements per instance type. This chart only shows the cost categories that you have actually incurred. Cost vs. Utilization Scatter This graph displays a scatter plot of the cost versus utilization for your instances. Hover over a point on the graph to view the instance name, utilization, instance type, tag, and cost. You can zoom into an area of the chart by clicking and dragging the mouse.\nThis view lets you compare the relative cost and utilization of your instances amongst their peers: elements to the bottom-right have relatively high utilization and lower cost compared with elements in the top-left corner which have lower utilization and higher costs. Elements are given different markers based on their tag. To use this view you need to have tags on your instance elements; these can be source tags (set in AWS) or tags you have created in Metricly.\nIf combinations of your instances represent different applications, you could create a tag called “application” in each instance and set the value accordingly. In this view, you could select the “application” tag to mark the elements according to the grouping you have specified. This is useful for identifying outliers where you expect elements of the same tag to have similar cost/utilization positions on the chart.\n\rCost by Tag This graph lets you group the costs by any custom tag. To use this view you need to have tags on your instance elements. These can be source tags (set in AWS) or tags you have created in Metricly. For example, if combinations of your instances represent different applications you could create a tag called “application” in each instances and set the value accordingly. In this view, you could select the “application” tag to aggregate the costs according to the grouping you have specified. Other examples could include grouping by department or by environment. This chart only shows the cost categories that you have actually incurred.\nYou can zoom into the chart by clicking and dragging your mouse across a set of elements. If you hover the mouse over a bar, you will see a tooltip showing the instance type, total cost, and the cost breakdown.\n\rEC2 vs. RDS vs. S3 Cost Reports across instances have largely the same experience, but this section covers the main differences between cost reporting for each.\nUtilization Metrics EC2  Active Hours CPU Utilization % Memory Utilization Disk I/O % Disk Space Used % Network I/O %  Additional Considerations:  EC2 elements without a Metricly agent / Windows agent display only two utilization measures: Active Hours and CPU Utilization %. EC2 elements with a Metricly agent installed have the following additional utilization metrics available: Memory Utilization %, Disk I/O %, and Disk Space Used %. EC2 elements with a Windows agent installed have the Network I/O % metric available.  If you have a mix of elements with and without a Metricly agent, you will see gaps in the utilization figures where values are not available.\nRDS  Active Hours CPU Utilization Disk Space Used % IOPS Utilization %  S3  Put Requests Get Requests Number of Objects Bucket Size (bytes)  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/create-new-dashboard/",
	"title": "Create New Dashboard",
	"tags": ["#getting started", "#metrics", "#elements", "#dashboards"],
	"description": "",
	"content": " Create a New Dashboard  Navigate to Dashboards on the main navigation menu. Click New Dashboard. Type a name for the dashboard. Click Save. You’ll be taken to the Widget Library, where you can add a widget.   "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/checks/custom-checks/",
	"title": "Custom Checks",
	"tags": ["#alerts", "#notifications", "#checks", "#custom checks"],
	"description": "",
	"content": " Our platform is flexible to support any custom checks, but you will need a mechanism to schedule the scripts to run. Linux cron jobs or Window task scheduler will typically work for most cases. If you are running on the Linux platform our agent can also schedule the running of your scripts via the Users Scripts Integration. This option will allow you to schedule a script that may post to our REST API as output either a system check, or a time-series metric value, or even a text-based data. And it will remove the need for a separate scheduler or a loop function. The agent will execute the script on the small cycle as the data collection (ex. 60 seconds).\nThe 4 parameters required to send custom checks  apiId: This is the API key that can be found by clicking on the corresponding integration (ex. Windows or Linux) on the integration page of our product once you are logged in. We suggest using the apiId associated with the element type (ex. Linux) checkName: This is any name you want to give the check. It is the name that will show up in the user interface which you would also use to create an alerting policy. elementFqn: This is the name of the element (ex. Linux hostname) that you want to associate with the system check. For example if you are checking if an application is running on Server123, you would set the elementFqn to Server123. If the element does not exist in the system, we will check an element with the type check and add it to the system. It is best practice to always associate a check with some monitored element. TTL: The value is in seconds. It is the amount of time you would expect to see a response back from your check. This time can exactly match the time you are running the scheduled job, so for example the check could run every 60 seconds and have a 60 TTL. But we suggest putting in a buffer to deal with any small latency (ex. network or DNS delay) and prevent any “check flapping\u0026rdquo;. A better example would be to set the check on a 60 second cycle and set the TTL for 90 seconds.  Endpoint URL Format https://api.app.metricly.com/check/{apiId}/{checkName}/{elementFqn}/{ttl}  CURL Example If you had a daily backup running on host db1234, you could run the following at the end of your backup script:\ncurl -X POST https://api.app.metricly.com/check/00000000000000000000000000000000/dailybackup/db1234/90000  25 hours (90000 seconds) is used as the check TTL to provide a one hour buffer in case backup times fluctuate a bit, reducing false alarms.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-custom-mbeans/",
	"title": "Custom MBeans",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " The Java agent can collect metrics from custom mbeans. We have provided a sample spring boot application that creates 2 custom mbeans with test attributes here.\nMultiple Custom MBean Diagram For a Single Custom MBean  Navigate to the zorka.properties file in your Java agent directory. Near the bottom of the file, set the attribute netuitive.api.custom.stats.mbean to the custom mbean you defined in your application  #custom mbean to collect metrics from netuitive.api.custom.stats.mbean = com.netuitive.mbean:type=Test,name=CustomTestMBean   Save the file.  For Multiple MBeans We’ve provided a sample .bsh script that creates getter objects for each of the mbeans in the sample multiple mbean spring boot application file.\n Create a .bsh script that contains getter objects for each of your custom mbean values. In the same script, create a rollup mbean and add the getter objects you created in step 1 as attributes of the rollup mbean. Navigate to the zorka.properties file in your Java agent directory. Add the script you created in step 1 to the scripts setting.  #Default collection of jvm metrics scripts = jvm.bsh, custom-mbean.bsh   Near the bottom of the file, set the attribute netuitive.api.custom.stats.mbean to the new rollup mbean you created in step 2.  #custom mbean to collect metrics from netuitive.api.custom.stats.mbean = com.netuitive.mbean:type=Test,name=RollupTestMBean  Save the file.  Leave the netuitive.api.custom.stats.mbean.attr.includeattribute blank to include all metrics.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-custom-metrics/",
	"title": "Custom Metrics",
	"tags": ["#windows", "#integrations", "#custom metrics", "#metrics"],
	"description": "",
	"content": " You can create additional Windows performance counters to add custom metrics monitored by Metricly.\nAdd Custom Metrics 1. Open the Add Counters window  Open perfmon (Performance Monitor) on your computer. Click Performance Monitor in the Monitoring Tools folder. A graph generates. Click Add above the graph. An “Add Counters” window opens. Leave the window open.  2. Prepare a new Counter  Navigate to the ReadWindowsPerfCounters file (C:\\Program Files\\CollectdWin\\config) and open it. Optionally, at the top of the file but below the  tag, place a comment to section off your new custom category of counters.  \u0026lt;!-- CustomCategoryName --\u0026gt;  3. Add a blank Counter tag template:\n\u0026lt;Counter Category=\u0026quot;\u0026quot; Name=\u0026quot;\u0026quot; Instance=\u0026quot;\u0026quot; CollectdPlugin=\u0026quot;\u0026quot; CollectdType=\u0026quot;\u0026quot; CollectdTypeInstance=\u0026quot;\u0026quot; /\u0026gt;  3. Fill in Counter information  Follow the diagram below to fill out the Category, Name, and Instance fields (case sensitive) in the blank counter template you added in step 2.3. The picture outlines the expanded Processor counter category.  2. Navigate to the types.db file (C:\\Program Files\\CollectdWin) and open it.\n3. Use your best judgment to match a type in types.db to the category you selected in step 3.1. Input the type (case sensitive) you wish to use into the CollectdType field. 4. Create a metric category for the CollectdPlugin field. This category displays in the Metrics tree and search field (squared in green). 5. Create a metric name using the** CollectdTypeInstance** field. This field is used as the metric’s name in Metricly, but be sure to make it entirely unique. 6. Save the ReadWindowsPerfCounters file.\nAbout Categories Not all categories have instances available. In the above example, the instances correlate to the processor’s cores, where _Total would calculate the metric selected for all four cores. Options you can use for the Instance field:\n “” for no specific instances. _Total for an aggregate of all instances. .* to make a branch for each instance. {specific_instance_name} for only a specific instance.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/customize-notification-payloads/",
	"title": "Customize Notification Payloads",
	"tags": ["#alerts", "#notifications"],
	"description": "",
	"content": " Custom JSON payloads in Metricly support FreeMarker writeup. This page contains a list of examples for you to reference when creating your own notification payloads for emails, SNS, and webhooks.\nJSON Variables Available in Metricly    Variable Description     ${event.data.results} The description of the event as a policy violation.   ${event.id} The ID of the event   ${eventCategory.name} The event category ( (Info), (Warning), or (Critical)).   ${elementFqn} The Fully Qualified Name (FQN) of the element.   ${elementId} The type of element (e.g., SERVER, ELB, EC2, RDS, etc.).   ${elementType} The type of element (e.g, SERVER, ELB, RUBY, etc.)   ${elementLocation} The location of the element.   ${elementName} The friendly name for the element.   ${policyId} The policy identification number.   ${policyName} The name of the policy.   ${eventTimestamp} The time (in UTC) the event occurred.   ${policyDescription} The description of the policy that generated the event.    Escaping JSON With Freemarker Use the official FreeMarker documentation on escaping for an in-depth look on various escaping rules. Note that escaping does not work for ', only \u0026quot; and \u0026gt;. If you do not properly escape your FreeMarker, you may not receive notifications. Remember to test any custom payloads that you create.\nExample\n{ \u0026quot;icon\u0026quot;: \u0026quot;https://www.metricly.com/wp-content/uploads/2017/06/METRICLY_LOGO_M_only.png\u0026quot;, \u0026quot;activity\u0026quot;: \u0026quot;Metricly Alerts\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;${policyName}\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;Category: ${eventCategory.name}\\nElement: ${elementName}\\nDescription: ${policyDescription?json_string}\\nEventData: \u0026lt;#if event.data??\u0026gt;\u0026lt;#if event.data.results??\u0026gt;\u0026lt;#assign results = event.data.results?eval\u0026gt;\u0026lt;#if results.conditions??\u0026gt;\u0026lt;#list results.conditions as condition\u0026gt;\u0026lt;#if condition?counter \u0026lt;= 5\u0026gt;${condition.expression}\u0026lt;/#if\u0026gt;\u0026lt;/#list\u0026gt;\u0026lt;/#if\u0026gt;\u0026lt;/#if\u0026gt;\u0026lt;/#if\u0026gt;\u0026quot; }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-df-metrics/",
	"title": "DF Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#df", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     df-\u0026lt;mount\u0026gt;.df_complex-free.value Free disk space in bytes. average bytes 0 none none yes no no   df-\u0026lt;mount\u0026gt;.df_complex-reserved.value Disk space reserved for root user in bytes. average bytes 0 none none yes no no   df-\u0026lt;mount\u0026gt;.df_complex-used.value Used disk space in bytes. average bytes 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Statistic Units Min Max BASE CORR UTIL     metricly.collectd.df-*.total-space Computation: df-.df_complex-free + df-.df_complex-reserved + df-*.df_complex-used average bytes 0 none no no no   metricly.collectd.df-*.used-percent Computation: (df-.df_complex-used / metricly.collectd.df-.total-space) * 100 average percent 0 100 no no yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/",
	"title": "Default Policies",
	"tags": ["#alerts", "#directory", "#policies", "#default policies"],
	"description": "",
	"content": "Default policies are created by Metricly and intended to provide recommendations for ways to monitor the behavior of the elements in your environment. Default policies can be found on the Policies page and are marked as Metricly in the Created By column. You can edit default policies as needed to suit the behavior of your environment. When new default policies are provisioned to your account, Metricly will not overwrite any changes you made to existing default policies. Furthermore, any new default policies added to your account will be disabled by default.\nBefore reading about default policies, you first should understand the concepts of scope, conditions, duration, notifications, and event categories.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/delete-dashboard/",
	"title": "Delete a Dashboard",
	"tags": ["#getting started", "#metrics", "#elements", "#dashboards"],
	"description": "",
	"content": " Via Manage Dashboards You can delete a dashboard by navigating to Dashboards \u0026gt; Manage Dashboards and clicking \r. Via Any Dashboard You can delete custom dashboards directly on their page by clicking \r\u0026gt; Delete Dashboard. "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/delete-policy/",
	"title": "Delete a Policy",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#delete"],
	"description": "",
	"content": " On the Alerts page, select the desired policy. In Policy Editor, click Delete.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/diamond-linux-policies/",
	"title": "Diamond (Linux) Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#linux", "#diamond"],
	"description": "",
	"content": "Before reading about these default policies, note that both the Elevated User CPU and Elevated System CPU policies assume that the CPU Collector is configured to collect aggregate CPU metrics, rather than per core metrics.\nIt also assumes that the metrics are being normalized. This is done by setting the percore setting set to FALSE (it is TRUE by default) and the normalize setting set to TRUE (it is FALSE by default) in your configuration file. After adjusting these settings, save the configuration file and restart the agent to apply the changes. See the Linux agent for more information.\n   Policy name Duration Condition 1 (and) Condition 2 Category Description     Linux – CPU Threshold Exceeded 15 min cpu.total.utilization.percent has a static threshold \u0026gt;95%  CRITICAL The CPU on the SERVER instance has exceeded 95% for at least 15 minutes.   Linux – Elevated System CPU 30 min metricly.linux.cpu.total.system.normalized has an upper baseline deviation + a static threshold ≥ 30%  INFO This policy will generate an Informational event when CPU usage by system processes is higher than normal, but only if the actual value is also above 30%. Customers typically don’t want to be informed of deviations in CPU behavior when the actual values are too low; you may want to tune the 30% threshold for your environment.   Linux – Elevated User CPU 30 min metricly.linux.cpu.total.user.normalized has an upper baseline deviation + a static threshold ≥ 50%  INFO This policy will generate an Informational event when CPU usage by user processes is higher than normal, but only if the actual value is also above 50%. Customers typically don’t want to be informed of deviations in CPU behavior when the actual values are too low; you may want to tune the 50% threshold for your environment.   Linux – Heavy CPU Load 15 min metricly.linux.cpu.total.user.normalized has an upper baseline deviation + an upper contextual deviation metricly.linux.loadavg.05.normalized has a static threshold \u0026gt; 2 CRITICAL This is a CRITICAL event indicating that the server’s CPU is under heavy load, based upon upper deviations on CPU utilization percent and the normalized loadavg.05 metric being greater than 2. Rule of thumb is that the run queue size (represented by the loadavg) should not be greater than 2x the number of CPUs.   Linux – Disk Utilization Threshold Exceeded 15 min metricly.linux.diskspace.*.byte_percentused has a static threshold \u0026gt;95%  CRITICAL The consumed disk space on the SERVER instance has exceeded 95% for at least 15 minutes.   Linux – Heavy Disk Load 15 min iostat.*.average_queue_length has an upper baseline deviation + an upper contextual deviation  WARNING This is a WARNING which indicates that the disk is experiencing heavy load, but performance has not yet been impacted.   Linux – Heavy Disk Load with Slow Performance 15 min iostat.*.await has an upper baseline deviation + an upper contextual deviation iostat.*.average_queue_length has an upper baseline deviation + an upper contextual deviation CRITICAL This is a CRITICAL event which indicates that the disk is not only experiencing heavy load, but performance is suffering.   Linux – Agent Appears to be Down 15 min metricly.metrics.heartbeat has a static threshold \u0026lt;1  WARNING A heartbeat has not been received for a Metricly Agent for at least the past 15 minutes; the Agent may be down.   Linux – Memory Utilization Threshold Exceeded 15 min metricly.linux.memory.utilization.percent has a static threshold \u0026gt; 95%  CRITICAL This is a CRITICAL event which is raised when memory utilization exceeds 95%.   Elevated Memory Usage 30 min metricly.linux.memory.utilizationpercent has an upper baseline deviation + a static threshold \u0026gt; 50%  INFO This policy will generate an Informational event when memory usage is higher than normal, but only if the actual value is also above 50%. Customers typically don’t want to be informed of deviations in memory usage when the actual values are too low; you may want to tune the 50% threshold for your environment.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/",
	"title": "Diamond Agent",
	"tags": ["#diamond", "#integrations", "#agents"],
	"description": "",
	"content": " Diamond’s default HTTP Post Handler can be used to send Diamond data to Metricly.\nConfiguration 1. Copy the unique API key from the Diamond integration in your account  In Metricly, navigate to Integrations. Click the Diamond card. Data collection should already be enabled, and a unique API key for your account has already been generated. Copy the API key.  2. Install \u0026amp; Configure Diamond  Download and install Diamond using the instructions found here. Open your diamond.conf file. It can usually be found in /etc/diamond/diamond.conf. Under [[HttpPostHandler]] in the [handlers], change the url setting to the following:  [[HttpPostHandler]] ### Url to post the metrics url = http://api.app.metricly.com/diamond/API_KEY  Substitute _APIKEY for your unique API key. 4. Adjust the batch size to 256 for monitoring general server metrics.\n### Metrics batch size batch = 256  5. Save the diamond.conf file and restart Diamond.\nThis integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-disk-metrics/",
	"title": "Disk Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#disk", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     disk-\u0026lt;dn\u0026gt;.disk_merged.read Number of merged reads per second. average operations/second 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_merged.write Number of merged writes per second. average operations/second 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_octets.read Bytes read per second. average bytes/second 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_octets.write Bytes written per second. average bytes/second 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_ops.read Read operations per second. average operations/second 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_ops.write Write operations per second. average operations/second 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_time.read Average time for read ops. average milliseconds 0 none none yes no no   disk-\u0026lt;dn\u0026gt;.disk_time.write Average time for write ops. average milliseconds 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Statistic Units Min Max BASE CORR UTIL     metricly.collectd.disk-*.disk_ops.total Total number of operations in the interval.Computation:(disk-.disk_ops.read + disk-.disk_ops.write) * 300 sum operations 0 none no no no   metricly.collectd.disk-*.disk_ops.readwrite Operations per second (IOPS).Computation:disk-.disk_ops.read + disk-.disk_ops.write average operations/second 0 none yes yes no   metricly.collectd.disk-*.disk_time.readwrite Average time for all operations (latency).Computation:((disk-*.disk_time.read * (disk-*.disk_ops.read * 300)) +(disk-*.disk_time.write * (disk-*.disk_ops.write * 300))) /metricly.collectd.disk-*.disk_ops.total average milliseconds 0 none yes yes no   metricly.collectd.disk-*.disk_busy.percent Percent of five-minute interval the disk is busy serving IO requests.Computation:(((data[‘disk-${1}.disk_ops.read’].actual * 300 * data[‘disk-${1}.disk_time.read’].actual)+ (data[‘disk-${1}.disk_ops.write’].actual * 300 * data[‘disk-${1}.disk_time.write’].actual))/ (300000)) * 100} average percent 0 100 yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/diamond-agent-disk-usage-metrics/",
	"title": "Disk Usage Metrics",
	"tags": ["#diamond", "#integrations", "#agents", "#diskspace"],
	"description": "",
	"content": " Computed    Fully Qualified Name(FQN) Description Units Min Max BASE CORR UTIL     metriclyicly.linux.iostat.totalreads Total reads across all disks. Computation: data.sum(‘iostat\\..*\\.reads)  0 none yes no no   metriclyicly.linux.iostat.totalwrites Total writes across all disks. Computation: data.sum(‘iostat\\..*\\.writes)  0 none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/diamond-agent-diskspace-metrics/",
	"title": "Diskspace Metrics",
	"tags": ["#diamond", "#integrations", "#agents", "#diskspace"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     diskspace..byte_percentfree Percentage of free bytes. average percent 0 100 none yes no no    Computed    Fully Qualified Name(FQN) Description Units Min Max BASE CORR UTIL     metriclyicly.linux.diskspace.*.byte_percentused Percentage of disk space used. Computation: 100 – diskspace.*.byte_percentfree percent 0 100 no no yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/docker/",
	"title": "Docker",
	"tags": ["#docker", "#integrations"],
	"description": "",
	"content": " Docker is an open way of building, shipping, and running distributed applications anywhere using containers and images. Metricly can be used to monitor the performance of your Docker host and containers.\nEach Docker container you have running will be listed as Docker Container in your Inventory Explorer. Each Docker host you have running will be listed as SERVER in your Inventory Explorer. You’ll be able to identify which of your SERVER elements are Docker hosts via the Docker Summary dashboard (if you have the Docker package installed).\nMetricly also offers a Docker container with the Linux agent configured to send Docker host and container metrics. The Linux Agent Docker container should be used only if the Linux agent cannot be installed on the host.\nConfiguration The Linux Agent must be installed before proceeding. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\n Navigate to the Linux Agent configuration file, /opt/netuitive-agent/conf/netuitive-agent.conf. Change the enabled setting to True in the [[NetuitiveDockerCollector]] section of the file. Optionally, add a metric blacklist or whitelist to reduce the number of metrics you receive. See our Regex Guide for examples.\n Save the file, and restart the Linux agent.  This integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\nCollector Options    Option Default Description     enabled False Enable collecting Docker metrics.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   memory_path  The path to the kernel’s CGroups memory file system.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/docker-policies/",
	"title": "Docker Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#docker"],
	"description": "",
	"content": "   Policy name Duration Conditions Category Description     Docker Container – CPU Throttling 15 min metricly.docker.cpu.container_throttling_percent has a static threshold \u0026gt;0 WARNING The Docker container has had its CPU usage throttled for at least the past 15 minutes.   Docker Container – Elevated CPU Utilization 30 min metricly.docker.cpu.container_cpu_percent has an upper baseline deviation + an upper contextual deviation INFO CPU usage on the Docker container has been higher than expected for 30 minutes or longer.   Docker Container – Elevated Memory Utililzation 30 min metricly.docker.cpu.container_memory_percent has an upper baseline deviation + an upper contextual deviation INFO Memory usage on the Docker container has been highter than expected for 30 minutes or longer.   Docker Container – Extensive CPU Throttling 1 hour 5 min metricly.docker.cpu.container_throttling_percent has a static threshold \u0026gt;0 CRITICAL The Docker container has had its CPU usage throttled for over an hour.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/dropwizard/",
	"title": "Dropwizard",
	"tags": ["#dropwizard", "#integrations", "#custom metrics"],
	"description": "",
	"content": " Dropwizard is part Java framework and part Java library that assists in operating web services. Dropwizard will take your web application and run it locally, recording metrics on its performance. You can integrate with Dropwizard via our custom Dropwizard Metrics Library to send these metrics to a StatsD server, which you can then forward to Metricly.\nConfiguration  Include the appropriate Ananke library dependency. You’ll also need a working StatsD (Metricly StatsD or Etsy StatsD) integration. Include the appropriate dropwizard-metrics dependency for the build manager of your choice.  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.metriclyicly\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dropwizard-metrics\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt;  3. Add the following to your Dropwizard config.yml file:\nmetrics: frequency: 1 minute reporters: - type: metriclyicly host: metriclyicly-agent port: 8125  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/duration-refresh-intervals/",
	"title": "Duration &amp; Refresh Intervals",
	"tags": ["#getting started", "#metrics", "#elements", "#dashboards"],
	"description": "",
	"content": " Adjusting the dashboard’s Duration or Refresh Interval affects the data displayed in widgets on your dashboard.\nChange Duration Edit the Duration setting for the dashboard in the sub navigation menu.\n Choose a Duration (past) value. Select an Ending value (default is Now). The data then automatically reloads to reflect your changes.   Two widgets behave differently in regards to the Duration setting:\n Metric Status Widget: Current Values in Metric Status widgets are not affected by the Time Frame setting. It always reflects the most recent five minutes of data. Group Status Widget: Clicking the refresh button in the Time Frame will refresh the data in the Group Status widget. However, the Group Status widget always displays the most recent 5 minutes of data, regardless of the Time Frame setting.  Check out the Time Frame documentation for more information.\nChange Refresh Interval  To edit the Refresh Interval for the dashboard, click Ending Now. A modal appears with a dropdown for Refresh Interval.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-dynamodb/",
	"title": "DynamoDB Metrics",
	"tags": ["#aws", "#metrics", "#dynamoDB"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) AWS Metric Statistic Units Max Sparse Data Strategy (SDS) BASE CORR     aws.dynamodb.conditionalcheckfailedrequests ConditionalCheckFailedRequests sum count none zero no no   aws.dynamodb.consumedreadcapacityunits ConsumedReadCapacityUnits sum count none zero yes no   aws.dynamodb.consumedwritecapacityunits ConsumedWriteCapacityUnits sum count none zero yes no   aws.dynamodb.onlineindexconsumedwritecapacity OnlineIndexConsumedWriteCapacity sum count none zero yes no   aws.dynamodb.onlineindexpercentageprogress OnlineIndexPercentageProgress max percent 100 none no no   aws.dynamodb.onlineindexthrottleevents OnlineIndexThrottleEvents sum count none zero no no   aws.dynamodb.provisionedreadcapacityunits ProvisionedReadCapacityUnits sum count none zero no no   aws.dynamodb.provisionedwritecapacityunits ProvisionedWriteCapacityUnits sum count none zero no no   aws.dynamodb.readthrottleevents ReadThrottleEvents sum count none zero no no   aws.dynamodb.returnedbytes ReturnedBytes average bytes none zero yes yes   aws.dynamodb.returneditemcount ReturnedItemCount average count none zero yes yes   aws.dynamodb.returnedrecordscount ReturnedRecordsCount average count none zero yes yes   aws.dynamodb.successfulrequestlatency SuccessfulRequestLatency average ms none zero yes yes   aws.dynamodb.systemerrors SystemErrors sum count none zero no no   aws.dynamodb.throttledrequests ThrottledRequests sum count none zero no no   aws.dynamodb.usererrors UserErrors sum count none zero no no   aws.dynamodb.writethrottleevents WriteThrottleEvents sum count none zero no no    Computed    Fully Qualified Name (FQN) Description Units Max BASE CORR UTIL Related Global Policies     netuitive.aws.dynamodb.readcapacityutilization This metric represents the percentage of the provisioned read capacity being used.Computation:((aws.dynamodb.consumedreadcapacityunits / 300) / aws.dynamodb.provisionedreadcapacityunits) * 100 percent 100 yes yes yes AWS DynamoDB – Elevated Read Capacity Utilization   netuitive.aws.dynamodb.writecapacityutilization This metric represents the percentage of the provisioned write capacity being used.Computation: ((aws.dynamodb.consumedwritecapacityunits / 300) / aws.dynamodb.provisionedwritecapacityunits) * 100 percent 100 yes yes yes AWS DynamoDB – Elevated Write Capacity Utilization    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-ebs/",
	"title": "EBS Metrics",
	"tags": ["#aws", "#metrics", "#ebs"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Description Units BASE CORR UTIL Related Global Policies     netuitive.aws.ebs.totalops This metric expresses the total number of read and write operations against this EBS instance. This metric is useful for monitoring EBS I/Oactivity.Computation: Read Ops + Write Ops operations yes no no    netuitive.aws.ebs.totalbytes This metric expresses the total number of bytes read and written from/to this EBS instance. This metric is useful for monitoring EBS I/Oactivity. Computation: Read Bytes + Write Bytes bytes yes no no    netuitive.aws.ebs.averagelatency This metric expresses the average latency per operation for this EBSinstance. This metric is useful for monitoring EBS performance andquality of service.Computation:(Total Read Time + Total Write Time) / (Read Ops +Write Ops) seconds yes yes no Elevated Queue Length Differential with Elevated Latency   netuitive.aws.ebs.readbytespersec This metric expresses the bytes read per second from this EBS instance.This metric is useful for monitoring EBS read activity.Computation: Read Bytes / 300 bytes/second yes no no    netuitive.aws.ebs.writebytespersec This metric expresses the bytes written per second to this EBS instance.This metric is useful for monitoring EBS write activity.Computation: Write Bytes / 300 bytes/second yes no no    netuitive.aws.ebs.totalbytespersec This metric expresses the total number of bytes either read from orwritten to this EBS instance. This metric is useful for monitoringoverall EBS I/O activity.Computation: Read Bytes Per Second + Write Bytes Per Second bytes/second yes yes no    netuitive.aws.ebs.averagereadlatency This metric expresses the average latency per read operation for thisEBS instance. This metric is useful for monitoring EBS performance andquality of service.Computation: Total Read Time / Read Ops seconds yes no no    netuitive.aws.ebs.averagewritelatency This metric expresses the average latency per write operation for thisEBS instance. This metric is useful for monitoring EBS performance andquality of service.Computation: Total Write Time / Write Ops seconds yes no no    netuitive.aws.ebs.readopspersec This metric expresses the number of read operations per second for thisEBS instance. This metric is useful for monitoring EBS read activity.Computation: Read Ops / 300 operations/second yes no no    netuitive.aws.ebs.writeopspersec This metric expresses the number of write operations per second for thisEBS instance. This metric is useful for monitoring EBS write activity.Computation: Write Ops / 300 operations/second yes no no    netuitive.aws.ebs.iops This metric expresses the total number of either read or writeoperations per second for this EBS instance. This metric is useful formonitoring EBS I/O activity.Computation: Total Ops / 300 operations/second yes yes no    netuitive.aws.ebs.busytimeiops This metric expresses the number of operations per second measured only over the time that the disk is actually busy. This can be useful indetermining the IOPS being achieved during bursts.Computation: Total Ops / (300 – floor(Idle Time)) operations/second yes no no    netuitive.aws.ebs.busytimebytespersecond This metric expresses the number of bytes per second read and written,measured only over the time that the disk is actually busy. This can beuseful in determining the maximum throughput being achieved duringbursts.Computation: Total Bytes / (300 – floor(Idle Time)) bytes/second yes no no    netuitive.aws.ebs.busypercent This metric expresses the percent of time during each 5 minute intervalthat this EBS was actually busy performing an I/O operation. This metricis useful for monitoring utilization of EBS capacity.Computation: 100 – ((Idle Time / 300) * 100) percent yes yes yes    netuitive.aws.ebs.queuelengthdifferential This metric is measuring the difference between the actual queue lengthand the “ideal” queue length. The ideal queue length is based onAmazon’s rule of thumb that for every 200 IOPS you should have a queue length of 1. In theory, a well-optimized volume should have a queue length differential that tends to hover around 0. In practice, we have seen volumes with extremely low latency (\u0026lt; 0.0001) have queue length differentials that are higher than 0; presumably this is because the latency is much lower than Amazon is assuming for their rule of thumb. Even in these cases, the differential is a pretty steady number; hence an upper deviation in the differential would tend to indicate that the disk is not keeping up.Computation: Queue Length – (IOPS / 200) difference yes no no Elevated Queue Length Differential with Elevated Latency   netuitive.aws.ebs.iopsutilization This metric compares the current IOPS to the provisioned IOPS for thevolume in order to determine how much of the provisioned capacity isbeing used.Computation:min(100, (attribute[IOPS] == NULL ? data[IOPS] / 300 : data[IOPS / attribute[IOPS]]) *100) percent yes yes yes     Computed    Fully Qualified Name (FQN) Description Units BASE CORR UTIL Related Global Policies     netuitive.aws.ebs.totalops This metric expresses the total number of read and write operations against this EBS instance. This metric is useful for monitoring EBS I/Oactivity.Computation: Read Ops + Write Ops operations yes no no    netuitive.aws.ebs.totalbytes This metric expresses the total number of bytes read and written from/to this EBS instance. This metric is useful for monitoring EBS I/Oactivity. Computation: Read Bytes + Write Bytes bytes yes no no    netuitive.aws.ebs.averagelatency This metric expresses the average latency per operation for this EBSinstance. This metric is useful for monitoring EBS performance andquality of service.Computation:(Total Read Time + Total Write Time) / (Read Ops +Write Ops) seconds yes yes no Elevated Queue Length Differential with Elevated Latency   netuitive.aws.ebs.readbytespersec This metric expresses the bytes read per second from this EBS instance.This metric is useful for monitoring EBS read activity.Computation: Read Bytes / 300 bytes/second yes no no    netuitive.aws.ebs.writebytespersec This metric expresses the bytes written per second to this EBS instance.This metric is useful for monitoring EBS write activity.Computation: Write Bytes / 300 bytes/second yes no no    netuitive.aws.ebs.totalbytespersec This metric expresses the total number of bytes either read from orwritten to this EBS instance. This metric is useful for monitoringoverall EBS I/O activity.Computation: Read Bytes Per Second + Write Bytes Per Second bytes/second yes yes no    netuitive.aws.ebs.averagereadlatency This metric expresses the average latency per read operation for thisEBS instance. This metric is useful for monitoring EBS performance andquality of service.Computation: Total Read Time / Read Ops seconds yes no no    netuitive.aws.ebs.averagewritelatency This metric expresses the average latency per write operation for thisEBS instance. This metric is useful for monitoring EBS performance andquality of service.Computation: Total Write Time / Write Ops seconds yes no no    netuitive.aws.ebs.readopspersec This metric expresses the number of read operations per second for thisEBS instance. This metric is useful for monitoring EBS read activity.Computation: Read Ops / 300 operations/second yes no no    netuitive.aws.ebs.writeopspersec This metric expresses the number of write operations per second for thisEBS instance. This metric is useful for monitoring EBS write activity.Computation: Write Ops / 300 operations/second yes no no    netuitive.aws.ebs.iops This metric expresses the total number of either read or writeoperations per second for this EBS instance. This metric is useful formonitoring EBS I/O activity.Computation: Total Ops / 300 operations/second yes yes no    netuitive.aws.ebs.busytimeiops This metric expresses the number of operations per second measured only over the time that the disk is actually busy. This can be useful indetermining the IOPS being achieved during bursts.Computation: Total Ops / (300 – floor(Idle Time)) operations/second yes no no    netuitive.aws.ebs.busytimebytespersecond This metric expresses the number of bytes per second read and written,measured only over the time that the disk is actually busy. This can beuseful in determining the maximum throughput being achieved duringbursts.Computation: Total Bytes / (300 – floor(Idle Time)) bytes/second yes no no    netuitive.aws.ebs.busypercent This metric expresses the percent of time during each 5 minute intervalthat this EBS was actually busy performing an I/O operation. This metricis useful for monitoring utilization of EBS capacity.Computation: 100 – ((Idle Time / 300) * 100) percent yes yes no    netuitive.aws.ebs.queuelengthdifferential This metric is measuring the difference between the actual queue lengthand the “ideal” queue length. The ideal queue length is based onAmazon’s rule of thumb that for every 200 IOPS you should have a queue length of 1. In theory, a well-optimized volume should have a queue length differential that tends to hover around 0. In practice, we have seen volumes with extremely low latency (\u0026lt; 0.0001) have queue length differentials that are higher than 0; presumably this is because the latency is much lower than Amazon is assuming for their rule of thumb. Even in these cases, the differential is a pretty steady number; hence an upper deviation in the differential would tend to indicate that the disk is not keeping up.Computation: Queue Length – (IOPS / 200) difference yes no no Elevated Queue Length Differential with Elevated Latency   netuitive.aws.ebs.iopsutilization This metric compares the current IOPS to the provisioned IOPS for thevolume in order to determine how much of the provisioned capacity isbeing used.Computation:min(100, (attribute[IOPS] == NULL ? data[IOPS] / 300 : data[IOPS / attribute[IOPS]]) *100) percent yes no no     "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-ec2/",
	"title": "EC2 Metrics",
	"tags": ["#aws", "#metrics", "#ec2"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) AWS Metric Statistic Units Max BASE CORR UTIL     aws.ec2.cpucreditbalance CPUCreditBalance average  none yes no no   aws.ec2.cpucreditusage CPUCreditUsage sum  none yes no no   aws.ec2.cpuutilization CPUUtilizationPercent average percent 100 yes yes yes   aws.ec2.diskreadbytes DiskReadBytes sum bytes none no no no   aws.ec2.diskreadops DiskReadOps sum  none no no no   aws.ec2.diskwritebytes DiskWriteBytes sum bytes none no no no   aws.ec2.diskwriteops DiskWriteOps sum  none no no no   aws.ec2.networkin NetworkIn sum bytes none no no no   aws.ec2.networkout NetworkOut sum bytes none no no no   aws.ec2.statuscheckfailed StatusCheckFailed sum  5 yes no no   aws.ec2.statuscheckfailed_instance StatusCheckFailed_Instance sum  5 yes no no   aws.ec2.statuscheckfailed_system StatusCheckFailed_System sum  5 yes no no    Computed    Fully Qualified Name (FQN) Description Units BASE CORR Related Global Policies     netuitive.aws.ec2.diskreadbytespersec This metric expresses the number of bytes read per second from the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk read activity.Computation:metricly.aws.ec2.diskreadbytespersec / 300 bytes/second yes yes    netuitive.aws.ec2.diskwritebytespersec This metric expresses the number of bytes written per second to the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk write activity.Computation:metricly.aws.ec2.diskwritebytespersec / 300 bytes/second yes yes    netuitive.aws.ec2.diskreadopspersec This metric expresses the number of read operations per second from the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk read activity.Computation:metricly.aws.ec2.diskreadopspersec / 300 operations/second yes yes Elevated EC2 Ephemeral Disk Activity   netuitive.aws.ec2.diskwriteopspersec This metric expresses the number of write operations per second to the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk write activity.Computation:metricly.aws.ec2.diskwriteopspersec / 300 operations/second yes yes Elevated EC2 Ephemeral Disk Activity   netuitive.aws.ec2.disktotalops This metric expresses the total number of read and write operations against the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk I/O activity.Computation:metricly.aws.ec2.diskreadops + metricly.aws.ec2.diskwriteops operations yes no    netuitive.aws.ec2.diskiops This metric expresses the total IOPS performed against the ephemeral disk of an EC2 instance. This metric is useful for monitoring ephemeral disk I/O activity.Computation:(metricly.aws.ec2.disktotalops) / 300 operations/second no no    netuitive.aws.ec2.bytesinpersec This metric expresses the number of network bytes received per second by an EC2 instance. This metric is useful for monitoring network receive activity.Computation: aws.ec2.networkin / 300 bytes/second yes yes Elevated EC2 CPU Activity (Normal Network Activity) Elevated EC2 Network Activity   netuitive.aws.ec2.bytesoutpersec This metric expresses the number of network bytes written per second by an EC2 instance. This metric is useful for monitoring network transmit activity.Computation: aws.ec2.networkout / 300 bytes/second yes yes Elevated EC2 CPU Activity (Normal Network Activity) Elevated EC2 Network Activity    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-ec2-recommendations/",
	"title": "EC2 Recommendations",
	"tags": ["#reports", "#ec2"],
	"description": "",
	"content": " The EC2 Recommendation report is designed to help you reduce EC2 instance running costs by suggesting alternative instance types that may provide a similar level of service at a lower cost. The report presents details on the current EC2 instance types and their respective memory, VCPUs, and hourly instance running costs. Using these characteristics and the utilization observed during the reporting period, it estimates the memory and number of VCPUs that are actually needed, subject to optional constraints such as CPU utilization not exceeding a particular level, etc.\nThe report defaults to showing the top 10 savings opportunities, but this can be adjusted in combination with element filters to find and highlight additional savings.\nReport Features Refer to the image above when reading these sections.\n(1) Graph The graph displays two markers (connected by a dotted line) for each instance in the summary table below it. The solid marker represents the current state of the element: aggregated CPU utilization for the instance vs. estimated weekly instance cost. The empty marker shows the projected state of the instance for the same period it had been of the proposed type. The length of the dotted line connecting the two markers can be a useful indicator: a longer line represents significant changes. Conversely if the two markers coincide exactly, then the proposed type is the same as the current type. The direction of the line us useful too: a vertical line indicates a change in price without an expected change in utilization whereas a horizontal line suggests a change in utilization without a change in prices.The graph can be adjusted to show CPU vs. Cost, Memory vs. Cost, or CPU vs. Memory, or it can be also be hidden to make room for a larger table.\n(2) Summary Table This table shows information about the current and proposed instance types.\n(3) View Options These options let you tune the recommendations generated in the chart and graph.\nShow: Allows you to choose the number of elements to display on the graph and in the table. The Estimated Weekly Instance Savings value only includes savings for the filtered element set.\nChart View: Changes the axes on the graph to help you visualize the impact of changing instance types on cost, CPU utilization, and memory utilization.\n Cost vs. CPU Utilization Cost vs. Memory Utilization CPU vs. Memory Utilization None (hides the graph)  Metric Statistic: Changes the aggregated CPU and/or Memory statistic used to determine the peak observed load during the reporting period.\n Maximum: This is the most conservative; at no time during the report period did the CPU or memory exceed this value. 95th Percentile: This is slightly more aggressive: 95% of the time the CPU and memory utilization were at or below this level. 75th Percentile Mean Median 5th Percentile Minimum  Family Constraint: Determines which instance types are considered possible alternatives to the current instance type.\n Any Family: There are no constraints on the instance types other than they must have the calculated minimum VCPUs and Memory. Same Family: The proposed instance type must be in the same family as the current type. For example, if the current type is in the Compute Optimized family, then the proposed must be as well. Same Family and Generation: In addition to being in the same family, the new type must also be of the same generation. For example, an m4.2xlarge can be switched to an m4.xlarge but not an m3.xlarge.  Maximum CPU Utilization: The maximum CPU Utilization percent allowed in calculating for projections. Note that 100% is the most aggressive setting and results in instances with fewer VCPUs (normally cheaper). Instance types with enough VCPUs to keep the projected CPU utilization below 100% are OK. Also note that 50% is the most conservative setting and results in instances with more VCPUs.\nMaximum Memory Utilization: The maximum Memory Utilization percent allowed in calculating for projections. Note that 100% is the most aggressive setting and results in instances with lower memory (normally cheaper). Instance types with enough memory to keep the projected memory utilization below 100% are OK. Also note that 50% is the most conservative setting and results in instances with more memory.\nAssumed Memory: The amount of Memory Utilization percent to assume when no agent (Linux / Windows) is installed on the EC2 and hence Metricly does not have memory utilization data. Below is some contextual information included with a few of the options available in the drop-down menu to help you make an informed choice:\n Use CPU Utilization — In this case, the report takes the observed CPU utilization for the period and uses this figure for the memory also. 100% — This is the most conservative setting; we assume that at some point during the reporting period the memory utilization reached 100% and use this as the measure to determine the required memory. 50% — This is the most aggressive setting; we assume that the highest memory utilization reached during the reporting period was 50% and use this as the measure to determine the required memory.  (4) Filters Contains several filters where you can search for element names, element types, tags, attributes, collectors, and more. Expand the More filter to see additional filters; select a filter to add it to the list of active filters.\n(5) Estimated Weekly Savings The estimated potential savings calculated by the report based on switching to the proposed instance types. A negative number indicates that the report is suggesting more expensive instance types. This can occur if you set utilization targets that are lower than the current level of utilization.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-ecs/",
	"title": "ECS Metrics",
	"tags": ["#aws", "#metrics", "#ecs"],
	"description": "",
	"content": " Collected    Cluster Service Fully Qualified Name (FQN) AWS Metric Statistic Units Max BASE UTIL     yes no aws.ecs.cpureservation CPUReservation average percent 100 yes    yes no aws.ecs.memoryreservation MemoryReservation average percent 100 yes    yes yes aws.ecs.cpuutilization CPUUtilization average percent 100 yes yes   yes yes aws.ecs.memoryutilization MemoryUtilization average percent 100 yes yes   yes no aws.ecs.activeservicecount Active Service Count average  none yes    yes no aws.ecs.pendingtaskcount Pending Task Count average  none yes    yes no aws.ecs.registeredcontainerinstancecount Registered Containers Instance Count average  none yes    yes no aws.ecs.runningtaskcount Running Task Count average  none yes     "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-efs/",
	"title": "EFS Metrics",
	"tags": ["#aws", "#metrics", "#efs"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Description Statistic Units Min Max BASE CORR UTIL     aws.efs.burstcreditbalance The number of burst credits that a file system has. avg bytes   no yes no   aws.efs.clientconnections The number of client connections to a file system. sum bytes   no yes no   aws.efs.datawriteiobytes The number of bytes for each file write operation. sum bytes   no yes no   aws.efs.metadataiobytes The number of bytes for each metadata operation. sum bytes   no yes no   aws.efs.percentiolimit Shows how close a file system is to reaching the I/O limit of the General Purpose performance mode. percent percent   no no yes   aws.efs.permittedthroughput The maximum amount of throughput a file system is allowed. avg bytes per second   no yes no   aws.efs.totaliobytes The number of bytes for each file system operation, including data read, data write, and metadata operations. sum bytes   no yes no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-elb/",
	"title": "ELB Metrics",
	"tags": ["#aws", "#metrics", "#elb"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) AWS Metric Statistic Units Max Sparse Data Strategy (SDS) BASE CORR     Healthy Host Count aws.elb.healthyhostcount HealthyHostCount average  none last no no   Unhealthy Host Count aws.elb.unhealthyhostcount UnHealthyHostCount average  none last no no   Request Count aws.elb.requestcount RequestCount sum  none zero yes yes   Average Latency aws.elb.latency Latency average s none zero yes yes   HTTPCode ELB 4XX Response Count aws.elb.httpcode_elb_4xx HTTPCode_ELB_4XX sum  none zero no no   HTTPCode ELB 5XX Response Count aws.elb.httpcode_elb_5xx HTTPCode_ELB_5XX sum  none zero no no   HTTPCode Backend 2XX Response Count aws.elb.httpcode_backend_2xx HTTPCode_Backend_2XX sum  none zero no no   HTTPCode Backend 3XX Response Count aws.elb.httpcode_backend_3xx HTTPCode_Backend_3XX sum  none zero no no   HTTPCode Backend 4XX Response Count aws.elb.httpcode_backend_4xx HTTPCode_Backend_4XX sum  none zero no no   HTTPCode Backend 5XX Response Count aws.elb.httpcode_backend_5xx HTTPCode_Backend_5XX sum  none zero no no   Backend Connection Errors aws.elb.backendconnectionerrors BackendConnectionErrors sum  none zero no no   Average Surge Queue Length aws.elb.surgequeuelength SurgeQueueLength average  1024 zero no no   Spillover Count aws.elb.spillovercount SpilloverCount sum  none zero no no    Computed    Fully Qualified Name (FQN) Description Units Max BASE CORR UTIL Related Global Policies     netuitive.aws.elb.unhealthyhostpercent the percent of hosts for which an ELB is balancing load that are not healthy. When an ELB determines that an EC2 is “unhealthy”, it will stop directing requests to it, thereby effectively decreasing the configuration’s capacity to service requests. This metric is useful for monitoring actual delivered service capacity of an ELB and its associated EC2s.Computation: (Unhealthy Host Count + Healthy Host Count) == 0 ? 0 : ((Unhealthy Host Count)/(Unhealthy Host Count + Healthy Host Count)) * 100 percent 100 no no no    netuitive.aws.elb.backendconnectionerrorpercent the percent of all requests for which a connection was not successfully established between the load balancer and the registered instances. Because the load balancer retries the connection when there are errors, this count can exceed the request rate; so, consequently this percentage can exceed 100. Any value of this metric that is over 100% indicates significant retries and serious connectivity issues.Computation: (Request Count == 0 ? 0 : (Backend Connection Errors / Request Count) * 100 percent 100 yes yes no    netuitive.aws.elb.totalelbhttperrors the total number of HTTP 4XX and 5XX errors that were generated by the ELB. This metric is useful for detecting connection faults between clients and the services associated with the ELB.Computation: HTTPCode ELB 4XX Response Count + HTTPCode ELB 5XX Response Count count none yes no no    netuitive.aws.elb.httpcodeelberrorpercent the percentage of all requests for which HTTP 4XX and 5XX errors were generated by the ELB. This metric is useful for detecting connection faults between clients and the services associated with the ELB.Computation: (Total ELB HTTP Errors / Request Count) * 100 percent 100 yes yes no    netuitive.aws.elb.httpcodelb4xxerrorpercent the percentage of all requests for which HTTP 4xx errors were generated by the ELB.Computation: (HTTPCode ELB 4xx Response Count / Request Count) * 100 percent 100 yes no no    netuitive.aws.elb.httpcodelb5xxerrorpercent the percentage of all requests for which HTTP 5xx errors were generated by the ELB.Computation: (HTTPCode ELB 5xx Response Count / Request Count) * 100 percent 100 yes no no    netuitive.aws.elb.totalbackendhttperrors the total number of HTTP 4XX and 5XX errors that were generated by hosts for which the ELB is balancing load. This metric is useful for detecting potential service faults.Computation: HTTPCode Backend 4XX Response Count + HTTPCode Backend 5XX Response Count count none yes no no    netuitive.aws.elb.httpcodebackenderrorpercent the percentage of all requests for which HTTP 4XX and 5XX errors were generated by hosts for which the ELB is balancing load. This metric is useful for detecting potential service faults.Computation: (Total Backend HTTP Errors / Request Count) * 100 percent 100 yes yes no Elevated Backend Error Rate (Low Volume) Elevated Backend Error Rate (High Volume, Low Error Rate) Elevated Backend Error Rate (High Volume, High Error Rate)   netuitive.aws.elb.httpcodebackend4xxerrorpercent the percentage of all requests for which HTTP 4xx errors were generated by hosts for which the ELB is balancing load.Computation: (HTTPCode Backend 4xx Response Count / Request Count) * 100 percent 100 yes no no    netuitive.aws.elb.httpcodebackend5xxerrorpercent the percentage of all requests for which HTTP 5xx errors were generated by hosts for which the ELB is balancing load.Computation: (HTTPCode Backend 5xx Response Count / Request Count) * 100 percent 100 yes no no    netuitive.aws.elb.concurrency the level of concurrency that an ELB and its associated EC2 is currently delivering. Concurrency is given by Little’s Law which is an indicator of the degree of parallelism supported by the ELB configuration. When the capacity of the system to process requests in parallel is consistently exceeded, queues grow, latency increases and the system will begin to reject requests. This metric may be valuable for off-line analytics to determine system capacity.Computation: (Request Count * Average Latency ) / 300 requests none yes yes no    netuitive.aws.elb.surgequeueutilization the percent of surge queue capacity (1024 requests) that are currently consumed by waiting requests. This metric can be a leading indicator for latency issues as well as increases in spill over (rejected requests due to high demand). This metric can be used to characterize one aspect of an ELB’s overall utilization.Computation: (Max Surge Queue Length/1024) * 100 percent 100 yes no yes Surge Queue Utilization Above 5% Surge Queue Utilization Above 50%   netuitive.aws.elb.requestspersecond This metric reports the number of requests per second being handled by the ELB.Computation: Request Count / 300 requests/second none yes no no     "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-emr/",
	"title": "EMR Metrics",
	"tags": ["#aws", "#metrics", "#nlb"],
	"description": "",
	"content": " AWS groups EMR metrics into different categories (cluster status, node status, IO, etc.), but this has no impact on how Metricly monitors EMR.\nCollected    Friendly Name Fully Qualified Name (FQN) AWS Metric Statistic Units Max BASE CORR UTIL     Cluster Status aws.elasticmapreduce.appscompleted AppsCompleted average count none no no no   Cluster Status aws.elasticmapreduce.appsfailed AppsFailed average count none no no no   Cluster Status aws.elasticmapreduce.appskilled AppsKilled average count none no no no   Cluster Status aws.elasticmapreduce.appspending AppsPending average count none no no no   Cluster Status aws.elasticmapreduce.appsrunning AppsRunning average count none no no no   Cluster Status aws.elasticmapreduce.appssubmitted AppsSubmitted average count none no no no   Cluster Status aws.elasticmapreduce.containerallocated ContainerAllocated ave average count none no no no   Cluster Status aws.elasticmapreduce.containerreserved ContainerReserved average count none no no no   Cluster Status aws.elasticmapreduce.containerpending ContainerPending average count none no no no   Cluster Status aws.elasticmapreduce.isidle IsIdle average count 1 no no no   Node Status aws.elasticmapreduce.corenodesrunning CoreNodesRunning average count none no no no   Node Status aws.elasticmapreduce.corenodespending CoreNodesPending average count none no no no   Node Status aws.elasticmapreduce.livedatanodes LiveDataNodes average percent 100 no no no   Node Status aws.elasticmapreduce.mrtotalnodes MRTotalNodes average count none no no no   Node Status aws.elasticmapreduce.mractivenodes MRActiveNodes average count none no no no   Node Status aws.elasticmapreduce.mrlostnodes MRLostNodes average count none no no no   Node Status aws.elasticmapreduce.mrunhealthynodes MRUnhealthyNodes average count none no no no   Node Status aws.elasticmapreduce.mrdecommissionednodes MRDecommissionedNodes average count none no no no   Node Status aws.elasticmapreduce.mrrebootednodes MRRebootedNodes average count none no no no   IO aws.elasticmapreduce.s3byteswritten S3BytesWritten sum bytes none yes yes no   IO aws.elasticmapreduce.s3bytesread S3BytesRead sum bytes none yes yes yes   IO aws.elasticmapreduce.hdfsutilization HDFSUtilization average percent 100 yes yes no   IO aws.elasticmapreduce.hdfsbytesRead HDFSBytesRead sum bytes none yes yes no   IO aws.elasticmapreduce.hdfsbytesWritten HDFSBytesWritten sum bytes none yes yes no   IO aws.elasticmapreduce.missingblocks MissingBlocks average count none no no no   IO aws.elasticmapreduce.corruptblocks CorruptBlocks average count none no no no   IO aws.elasticmapreduce.totalload TotalLoad average count none yes yes no   IO aws.elasticmapreduce.memorytotalmb MemoryTotalMB average megabytes none no no no   IO aws.elasticmapreduce.memoryreservedmb MemoryReservedMB average megabytes none no no no   IO aws.elasticmapreduce.memoryavailablemb MemoryAvailableMB average megabytes none no no no   IO aws.elasticmapreduce.memoryallocatedmb MemoryAllocatedMB average megabytes none no no no   IO aws.elasticmapreduce.pendingdeletionblocks PendingDeletionBlocks average count none no no no   IO aws.elasticmapreduce.underreplicatedblocks UnderReplicatedBlocks average count none no no no   IO aws.elasticmapreduce.dfspendingreplicationblocks DfsPendingReplicationBlocks average count none no no no   IO aws.elasticmapreduce.capacityremaininggb CapacityRemainingGB average gigabytes none no no no   HBase aws.elasticmapreduce.hbasebackupfailed HbaseBackupFailed average count 1 no no no   HBase aws.elasticmapreduce.mostrecentbackupduration MostRecentBackupDuration average count none yes no no   HBase aws.elasticmapreduce.timesincelastsuccessfulbackup TimeSinceLastSuccessfulBackup average count none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-elasticache/",
	"title": "Elasticache Metrics",
	"tags": ["#aws", "#metrics", "#elasticache"],
	"description": "",
	"content": " Elasticache instances can come in a few “flavors”, which means metrics are unique to each “flavor” of Elasticache.\n Host-level metrics are present on both Memcached as well as Redis clusters Memcached metrics are available only on Memcached clusters, Memcached 1.4.14 metrics are only available on Memcached clusters using at least version 1.4.14 Redis metrics are present only on Redis clusters.  Collected    Metric Type Fully Qualified Name (FQN) AWS Metric Statistic Units Max BASE CORR UTIL     Host-level aws.elasticache.cpuutilization CPUUtilization average percent 100 yes yes yes   Host-level aws.elasticache.freeablememory FreeableMemory average bytes none yes no no   Host-level aws.elasticache.networkbytesin NetworkBytesIn average bytes none yes yes no   Host-level aws.elasticache.networkbytesout NetworkBytesOut average bytes none yes yes no   Host-level aws.elasticache.swapusage SwapUsage average bytes none yes no no   Memcached aws.elasticache.bytesreadintomemcached BytesReadIntoMemcached average bytes none yes no no   Memcached aws.elasticache.bytesusedforacheitems BytesUsedForCacheItems average bytes none yes no no   Memcached aws.elasticache.byteswrittenoutfrommemcached BytesWrittenOutFromMemcached average bytes none yes no no   Memcached aws.elasticache.casbadval CasBadVal sum count none yes no no   Memcached aws.elasticache.cashits CasHits sum count none yes no no   Memcached aws.elasticache.casmisses CasMisses sum count none yes no no   Memcached aws.elasticache.cmdflush CmdFlush sum count none yes no no   Memcached aws.elasticache.cmdget CmdGet sum count none yes no no   Memcached aws.elasticache.cmdset CmdSet sum count none yes no no   Memcached aws.elasticache.currconnections CurrConnections sum count none yes yes no   Memcached aws.elasticache.curritems CurrItems sum count none yes no no   Memcached aws.elasticache.decrhits DecrHits sum count none yes no no   Memcached aws.elasticache.decrmisses DecrMisses sum count none yes no no   Memcached aws.elasticache.deletehits DeleteHits sum count none yes no no   Memcached aws.elasticache.deletemisses DeleteMisses sum count none yes no no   Memcached aws.elasticache.evictions Evictions sum count none yes yes no   Memcached aws.elasticache.gethits GetHits sum count none yes no no   Memcached aws.elasticache.getmisses GetMisses sum count none yes no no   Memcached aws.elasticache.incrhits IncrHits sum count none yes no no   Memcached aws.elasticache.incrmisses IncrMisses sum count none yes no no   Memcached aws.elasticache.reclaimed Reclaimed sum count none yes no no   Memcached 1.4.14 aws.elasticache.bytesusedforhash BytesUsedForHash average bytes none yes no no   Memcached 1.4.14 aws.elasticache.cmdconfigget CmdConfigGet sum count none yes no no   Memcached 1.4.14 aws.elasticache.cmgconfigset CmdConfigSet sum count none yes no no   Memcached 1.4.14 aws.elasticache.cmdtouch CmdTouch sum count none yes no no   Memcached 1.4.14 aws.elasticache.currconfig CurrConfig average count none yes no no   Memcached 1.4.14 aws.elasticache.evictedunfetched EvictedUnfetched sum count none yes no no   Memcached 1.4.14 aws.elasticache.expiredunfetched ExpiredUnfetched sum count none yes no no   Memcached 1.4.14 aws.elasticache.slabsmoved SlabsMoved sum count none yes no no   Memcached 1.4.14 aws.elasticache.touchhits TouchHits sum count none yes no no   Memcached 1.4.14 aws.elasticache.touchmisses TouchMisses sum count none yes no no   Redis aws.elasticache.bytesusedforcache BytesUsedForCache average bytes none yes no no   Redis aws.elasticache.cachehits CacheHits sum count none yes yes no   Redis aws.elasticache.cachemisses CacheMisses sum count none yes yes no   Redis aws.elasticache.currconnections CurrConnections sum count none yes yes no   Redis aws.elasticache.evictions Evictions sum count none yes yes no   Redis aws.elasticache.hyperloglogbasedcmds HyperLogLogBasedCmds sum count none yes no no   Redis aws.elasticache.ismaster IsMaster sum count none yes no no   Redis aws.elasticache.newconnections NewConnections sum count none yes no no   Redis aws.elasticache.reclaimed Reclaimed sum count none yes no no   Redis aws.elasticache.replicationbytes ReplicationBytes average bytes none yes no no   Redis aws.elasticache.replicationlag ReplicationLag average seconds none yes no no   Redis aws.elasticache.saveinprogress SaveInProgress max count 1 yes no no   Redis aws.elasticache.curritems CurrItems sum count none yes no no   Redis aws.elasticache.gettypecmds GetTypeCmds sum count none yes no no   Redis aws.elasticache.hashbasedcmds HashBasedCmds sum count none yes no no   Redis aws.elasticache.keybasedcmds KeyBasedCmds sum count none yes no no   Redis aws.elasticache.listbasedcmds ListBasedCmds sum count none yes no no   Redis aws.elasticache.setbasedcmds SetBasedCmds sum count none yes no no   Redis aws.elasticache.settypecmds SetTypeCmds sum count none yes no no   Redis aws.elasticache.sortedsetbasedcmds SortedSetBasedCmds sum count none yes no no   Redis aws.elasticache.stringbasedcmds StringBasedCmds sum count none yes no no    Computed    Friendly Name Fully Qualified Name (FQN) Description Units Max BASE CORR Related Global Policies     Cache Hit Rate netuitive.aws.elasticache.cachehitrate This metric provides the percentage of hits against the cacheComputation:(data[‘aws.elasticache.cachehits’].actual + data[‘aws.elasticache.cachemisses’].actual) == 0 ? 0 : 100 *(data[‘aws.elasticache.cachehits’].actual / (data[‘aws.elasticache.cachehits’].actual + data[‘aws.elasticache.cachemisses’].actual)) percent 100 yes yes AWS Elasticache Redis – Low Cache Hit Rate   Memory Utilization netuitive.aws.elasticache.memoryutilization Computation:100 * ((data[‘aws.elasticache.bytesusedforcache’].actual != undefined ? data[‘aws.elasticache.bytesusedforcache’].actual : data[‘aws.elasticache.bytesusedforcacheitems’].actual) / ((data[‘aws.elasticache.bytesusedforcache’].actual != undefined ? data[‘aws.elasticache.bytesusedforcache’].actual : data[‘aws.elasticache.bytesusedforcacheitems’].actual) + data[‘aws.elasticache.freeablememory’].actual)) percent 100 yes yes AWS Elasticache – Cache Memory Utilization    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/elastic-search-policies/",
	"title": "Elasticsearch Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#elasticsearch"],
	"description": "",
	"content": "   Policy name Duration Conditions Category Description     Cluster Health Degraded to Red 15 min elasticsearch.cluster_health.status has a static threshold \u0026lt; 1 CRITICAL The cluster health status is red which means that one or more primary shard(s) and its replica(s) is missing.   Cluster Health Degraded to Yellow 15 min elasticsearch.cluster_health.status is between 1 and 1.8 WARNING The cluster health status is yellow which means that one or more shard replica(s) is missing.   Elevated JVM Heap Usage 15 min elasticsearch.jvm.mem.heap_used_percent has an upper baseline deviation WARNING This policy will generate a warning event when the Elastic Search JVM’s heap usage is above 80%.   Disk space is more than 75% used on data node  netuitive.linux.diskspace.avg_byte_percentused has a static threshold \u0026gt;75 WARNING The average utilization across your Elastic Search data node storage devices are more than 75%.   Elevated Fetch Time 30 min netuitive.linux.elasticsearch.indices._all.search.fetch_avg_time_in_millis has an upper baseline deviation WARNING This policy generates a warning event if the elasticsearch.indices._all.search.fetch_time_in_millis metric deviates above the baseline for 15 minutes or more.   Elevated Flush Time 30 min netuitive.linux.elasticsearch.indices._all.flush.avg_time_in_millis has an upper baseline deviation WARNING This policy generates a warning event if the elasticsearch.indices._all.flush.total_time_in_millis metric deviates above the baseline for 15 minutes or more.   Elevated Indexing Time 30 min netuitive.linux.elasticsearch.indices._all.indexing.index_avg_time_in_millis has an upper baseline deviation WARNING This policy generates a warning event if the elasticsearch.indices._all.indexing.index_time_in_millis metric deviates above the baseline for 15 minutes or more.   Reject Count Greater Than Zero 5 min elasticsearch.thread_pool.*.rejected has a static threshold \u0026gt;0 WARNING \u0026ldquo;This policy generates a warning if any of the Elastic Search thread pools has a “rejected” count greater than 0.\u0026rdquo;    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/elastisearch/",
	"title": "Elastisearch",
	"tags": ["#elastisearch", "#integrations"],
	"description": "",
	"content": " Elasticsearch is a distributed, scalable search server that enables you to search through all kinds of documents. Metricly can be used to monitor the performance of your Elasticsearch server. Additional configuration options are available below the instructions.\nConfiguration The Linux Agent must be installed before proceeding. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\n Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the ElasticSearchCollector.conf file. Change the enabled setting to True. You can adjust the default settings as necessary depending on your environment, but note:  If you aren’t using a cluster or do not wish to collect several additional cluster metrics, you can change the cluster value to false. logstash_mode should be set to True only if you are using logstash-formatted index names.  Optionally, tweak the metrics blacklist or add a whitelist to reduce the number of metrics you receive. See our Regex Guide for examples. Save the file, and restart the Linux agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting Elasticsearch metrics.   logstash_mode TRUE If indices stats are gathered, remove the YYYY.MM.DD suffix from the index name (e.g., logstash-adm-syslog-2014.01.03) and use that as a bucket for all ‘day’ index stats.   cluster TRUE If this node is part of a cluster, the collector will collect metrics on the cluster health.   metrics_blacklist ^indices.(?!_all$ datastore.   byte_unit  Default numeric output(s).   host  Hostname to collect from.   instances  List of instances. When set, this overrides the “host” and “port” options. Instance format: instance [@][:]   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   port  Port to collect from.   scheme  http (default) or https.   user  Username for Basic/Shield auth.   password  Password for Basic/Shield auth.   stats  Tells the collector which of the stats to collect. stats=jvm” would collect JVM metrics. ”stats=jvm,thread_pool” would collect JVM and thread pool metrics. ”stats=jvm,thread_pool,indices” would collect JVM, thread pool, and index metrics. You can have any combination of those 3 options. If you have a large number of indices (greater than 10), you should either change the “stats” setting to NOT collect indices or use the “metric_whitelist” or “metric_blacklist” options to filter the indices down to a smaller number.   ssl_verify_mode N/A Tells the collector whether or not an SSL certificate is required or should be verified. Examples: ssl_verify_mode = CERT_REQUIRED – required and validated ssl_verify_mode = CERT_NONE – not required ssl_verify_mode = CERT_OPTIONAL – not required, but validated if provided   ssl_check_hostname  Tells the collector whether or not to match the peer certificate hostname with the host hostname. The ssl-verify_modeoption must be set to CERT_OPTIONAL or CERT_REQUIRED. Examples: ssl_check_hostname = True ssl_check_hostname = False    Cluster Health Status This feature is a GET API callout that retrieves a high-level status of your cluster’s health. GET _cluster/health will return a JSON response that provides key information about the shards and nodes it contains.\nFor a full breakdown and troubleshooting, see elastic’s Cluster Health guide.\nAvailable Statuses  Green: 2; Completely operational Yellow: 1; Replicas are missing Red: 0; Searches and indexing are affected by missing data  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/inventory/inventory-element-detail/",
	"title": "Element Detail Panel",
	"tags": ["#getting started", "#metrics", "#elements", "#inventory page"],
	"description": "",
	"content": " The Element Detail panel displays tabs for the metric summary, policies, and relationships associated with the selected element.\nSummary Tab The Summary tab displays a dashboard full of select widgets to highlight the most important details of the selected element.\nPolicies Tab The Policies tab offers the same functionality as the Policies Page except the Policies tab only displays policies that include the selected element in the policy’s scope. Below is a picture of an EC2’s policies tab.\nRelationships Tab The Relationships tab offers the same functionality as the Elements Relationships widget: it displays the other elements associated with the selected element. Click any of the elements on the tree to open the selected widget’s element detail panel.\nAbout Tags A tag is a key-value pair assigned to a single element. Tags can be used to group elements and as search filters in Inventory Explorer, Event Explorer, Report Explorer, and Policy Editor. You can tag elements via the Inventory Explorer.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/ruby-agent-element-tags/",
	"title": "Element Tags",
	"tags": ["#ruby", "#integrations", "#agents", "#elements", "#tags"],
	"description": "",
	"content": " Send Element tags To send element tags, update the agent.yml found in the netuitived gem by uncommenting the elementTags line. This file is located at netuitived/config/agent.yml.\nKey/Value pairs should be added in the following format: name1:value1, name2:value2.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-emails/",
	"title": "Email Notifications",
	"tags": ["#alerts", "#notifications", "#email"],
	"description": "",
	"content": " You can create email templates with custom messaging that are re-usable across multiple policies, or simply choose Metricly’s default email notifications. Read below for configuration steps.\nConfiguration  Click your Username \u0026gt; Notifications. Click Add Notification. Select Email for Notification Type. The following modal appears:  Choose your frequency via the Re-notify every field. Check Notify on clear if you want to be notified when the alert has ended. Click New Email to create a new email template. The following modal appears:  Provide a Name for the template. A list of these show up in the Email dropdown. Provide an Email Address to send this notification to. Choose a Default or Custom Template.  Default: Sends a Metricly pre-formatted message. Custom: Allows you to customize the Subject and Body of the email.  Click Test and Save. Select your template from the Email dropdown.  Click Save.  Customization Variables You can use the following variables to make your notification more dynamic.\n   Variable Description     ${elementFqn} The Fully Qualified Name (FQN) of the element.   ${elementId} The type of element (e.g., SERVER, ELB, EC2, RDS, etc.).   ${elementLocation} The location of the element.   ${elementName} The friendly name for the element.   ${elementType} The type of element (e.g, SERVER, ELB, RUBY, etc.)   ${event.data.results} The description of the event as a policy violation.   ${event.id} The ID of the event   ${eventCategory.name} The event category ( (Info), (Warning), or (Critical)).   ${eventTimestamp} The time (in UTC) the event occurred.   ${policyDescription} The description of the policy that generated the event.   ${policyId} The policy identification number.   ${policyName} The name of the policy.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/email/",
	"title": "Email Notifications",
	"tags": ["#email", "#integrations"],
	"description": "",
	"content": " You can create email templates with custom messaging that are re-usable across multiple policies, or simply choose Metricly’s default email notifications. Read below for configuration steps.\nConfiguration  Click your Username \u0026gt; Notifications. Click Add Notification. Select Email for Notification Type. The following modal appears:  Choose your frequency via the Re-notify every field. Check Notify on clear if you want to be notified when the alert has ended. Click New Email to create a new email template. The following modal appears:  Provide a Name for the template. A list of these show up in the Email dropdown. Provide an Email Address to send this notification to. Choose a Default or Custom Template.  Default: Sends a Metricly pre-formatted message. Custom: Allows you to customize the Subject and Body of the email.  Click Test and Save. Select your template from the Email dropdown.  Click Save.  Regex Variables Use our Regex Guide to create custom payloads.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/customize-notification-payloads/freemarker-email-payloads/",
	"title": "Email Payloads",
	"tags": ["#alerts", "#notifications"],
	"description": "",
	"content": "There are two event payload types that can be leveraged with email notification payloads: event and event_cleared. An event is generated when a policy is violating. An event_cleared is generated when a once-violating policy is no longer violating. Your custom event payloads can be setup to notify you on either type with unique messaging and details about the event.\nTo create a custom event payload:\n Navigate to your Account \u0026gt; Notifications \u0026gt; Email. Click + Add Email. Choose Custom in the Template dropdown. Add a subject and input your JSON + FreeMarker writeup in the body of the email. Click Test \u0026amp; Save. Open a policy in the policy editor. Go to Notifications \u0026gt; Add Notification \u0026gt; Email. In the Email dropdown, select your newly created template. Save.  Alternatively, you can create your new custom email payload in the policy editor on the new notification itself by clicking + New Email.\nExample 1\nThis example provides the policy name related to the event in the subject of the email and then provides the event category name of the event firing in the body. When the event clears, it sends another email with CLEAR as the body text.\nMetricly Event [${policyName}]  \u0026lt;#if payloadType == \u0026quot;event\u0026quot;\u0026gt; ${eventCategory.name} \u0026lt;/#if\u0026gt; \u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt; CLEAR \u0026lt;/#if\u0026gt;  Example 2\nThis example sends an email with UP or DOWN as the subject line, with all of the event details in the email body.\n\u0026lt;#if payloadType == \u0026quot;event\u0026quot;\u0026gt;DOWN\u0026lt;/#if\u0026gt;\u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;UP\u0026lt;/#if\u0026gt;  Time: ${eventTimestamp} Event Category: ${eventCategory.name} Policy Name: ${policyName} Policy Description: ${policyDescription} Event ID: ${event.id} Element: ${elementName} Violation: ${event.data.results}  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-email/",
	"title": "Email Reports",
	"tags": ["#reports", "#email"],
	"description": "",
	"content": " Email Reports are generated and sent after business hours (EST) and can be enabled from your user account profile. Email Reports provide a quick look into your environment from the last 24 hours. Clicking any of the links within the email opens Metricly to the appropriate section.\nAvailable Reports There are three main email reports available: the Weekly Recommendation Report, the Daily Top Violator Report, and the Daily AWS Cost Report.\nWeekly Recommendation Report To save a recommendation report:\n Navigate to Reports \u0026gt; under Recommendations, click EC2 or ASG. Set up the report with your desired filters and criteria. Click Save Report. The Saved Reports modal appears. Input a Name for the report. Toggle Email to active.  You can remove a saved report from your daily report email by following the previous steps and toggling a report to inactive.\n\rDaily Top Violator Report (per Account) You can enable the Top Violator Report through your account settings.\n Navigate to Account Profile. Toggle Daily Report Email to active.  Daily AWS Cost Report Your Account must have the AWS Cost report activated before being able to send an email.\n Navigate to your Username \u0026gt; Beta \u0026gt; AWS Cost Report. Choose your desired View and Comparison Period. Click Save Report. The Saved Reports modal appears.  Input a Name for the report. Toggle Email to active.  Select what email receives this daily report by clicking the expansion icon on the email input box. You can also add a new email to the list at this point by typing it out and hitting enter.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-enable-guest-os-diagnostic/",
	"title": "Enable Guest OS Diagnostic Metrics",
	"tags": ["#microsoft", "#azure", "#integrations", "#optional config"],
	"description": "",
	"content": " Azure Virtual Machines will share boot diagnostic metrics by default, which are a small subset of core metrics. To enable Guest OS diagnostic (basic) metrics that provide more information about your machine, you’ll need to follow these steps (depending on your situation):\nEnable Basic Metrics on Existing VM  In Azure, navigate to Virtual machines. Select a virtual machine. Another window with options will open. Select Diagnostic settings. Under Configure required settings, select the checkbox next to Basic metrics. Metricly will now receive the basic VM metrics.  Enabling basic metrics on a new VM  In Azure, navigate to Virtual machines. At the top of the Virtual machines window, click Add. Select the type and create the instance. Complete Steps 1 and 2 filling out the information as desired. In Step 3, under Monitoring, enable Guest OS diagnostics. Finish creating the VM. The basic metrics are now available in Metricly.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-enable-proxy/",
	"title": "Enable Proxy",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " Enable a Proxy  Navigate to the zorka.properties file. Find the proxy section:\n  netuitive.api.proxy = no netuitive.api.proxy.address = http://\u0026lt;proxy host\u0026gt;:\u0026lt;proxy port\u0026gt;  3. Change the netuitive.api.proxy line to yes.\n4. Add the correct proxy host and port to the netuitive.api.proxy.address line.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/enable-disable-policy/",
	"title": "Enable or Disable a Policy",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#delete"],
	"description": "",
	"content": " On the Alerts page, select the desired policy. In Policy Editor, select or deselect the Enable Policy checkbox.  You can also enable or disable policies directly from the List and Card Policy view options.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/etsy-statsd/",
	"title": "Etsy StatsD",
	"tags": ["#statsd", "#integrations"],
	"description": "",
	"content": " Etsy StatsD is one of the most popular StatsD libraries available. Metricly offers a backend plugin for the Etsy StatsD library that allows you to send your StatsD metric data to Metricly. We recommend using our Etsy StatsD integration if you currently have an Etsy StatsD server running and want to send your instrumented data to Metricly. For more information about Etsy StatsD, see the following documentation.\nConfiguration 1. Copy API key  From the top navigation menu, click Integrations. Click the Etsy | StatsD card. Data collection should already be enabled, and a unique API key for your account has already been generated. Copy the API key  2. Update Your StatsD Backends Directory  Clone the Metricly StatsD Backend project to the desired location. Copy the metricly.js file and the entire metricly directory to your StatsD backend directory. For more information about cloning existing repositories in Stash with Git, see the following documentation.  3. Edit StatsD Config File  Open your local StatsD configuration file. In your configuration file, add ./backends/metricly to the backends section.  { backends:[ \u0026quot;./backends/metricly\u0026quot; ] }  3. Add the following lines below the backends section:\n{ backends:[ \u0026quot;./backends/metricly\u0026quot; ], metricly: { apiKey: \u0026quot;YOUR_API_KEY\u0026quot;, apiHost: \u0026quot;api.app.metricly.com\u0026quot;, apiPort: 443, } }  4. In order to associate StatsD metrics with an element in Metricly, ensure that there is at least one mapping for Metricly defined in the mappings section of your StatsD configuration file.\nEach mapping uses a pattern with a regular expression (regex) that corresponds with a set of keys in StatsD. The regex value can convert these keys to metrics that belong to an element in Metricly. If the element or metric name is in the StatsD key, it can be represented by$(regex-captured-group-number), demonstrated in the code below.\n\r{ backends:[\u0026quot;./backends/metricly\u0026quot;], metricly: { apiKey: \u0026quot;YOUR_API_KEY\u0026quot;, apiHost: \u0026quot;YOUR_METRICLY_API_HOST\u0026quot;, apiPort: 443, mappings: [ { pattern: \u0026quot;(.*?app.*?)\\\\.(.*?\\\\.mean)\\\\.gauge\u0026quot;, element: { type: \u0026quot;APP Server\u0026quot;, name: \u0026quot;$1\u0026quot;, metric: { name: \u0026quot;$2\u0026quot; } } }, { pattern: \u0026quot;(.*?app.*?)\\\\.(service.utilization)\\\\.gauge\u0026quot;, element: { type: \u0026quot;APP Server\u0026quot;, name: \u0026quot;$1\u0026quot;, metric: { name: \u0026quot;$2\u0026quot;, tags: [ {\u0026quot;name\u0026quot;: \u0026quot;utilization\u0026quot;, \u0026quot;value\u0026quot;:\u0026quot;true\u0026quot;} ] } } }, { pattern: \u0026quot;\\^(statsd\\\\..*)\u0026quot;, element: { type: \u0026quot;StatsD\u0026quot;, name: \u0026quot;StatsD\u0026quot;, metric: { name: \u0026quot;$1\u0026quot; } } }, { pattern: \u0026quot;\\^(timestamp_lag.*)\u0026quot;, element: { type: \u0026quot;StatsD\u0026quot;, name: \u0026quot;StatsD\u0026quot;, metric: { name: \u0026quot;statsd.$1\u0026quot; } } } ] } }  5. We recommend that you set the flushInterval in your StatsD configuration file to 60000 milliseconds. This will ensure that your StatsD data is collected by Metricly every 1 minute. 6. Save the configuration file and restart StatsD.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/events/",
	"title": "Events",
	"tags": ["#alerts", "#notifications", "#events"],
	"description": "",
	"content": " Events indicate that a policy has been violated, meaning all of the policy conditions have been met for the set duration. In other words, events indicate that Metricly has detected anomalous behavior in one or more of the elements in your environment.\nFor example, if you create a policy for all EC2 elements with the condition CPU Utilization greater than 90% and a duration of 10 minutes, an event will be generated when an EC2 element’s CPU Utilization metric exceeds 90% for 10 consecutive minutes.\n\rEvent Categories Event categories are user-assigned via the Policy Editor and associated with the severity of the event. Each event can be assigned one category. There are three color-coded categories that indicate the severity of the event.\n   Category Color Description     Info Blue The Info category indicates that a policy has been violated, but the anomalous behavior is not critical.   Warning Yellow The Warning category indicates that a policy has been violated, and there will likely be a more critical event in the future.   Critical Red The Critical category indicates that a policy has been violated, and the cause of the event should be addressed quickly.    Assigning an Event Category  Open Policy Editor. Underneath the Policy’s name, in the Category drop-down menu, select Info, Warning, or Critical. After completing the remaining fields in Policy Editor, click Save.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/events-widget/",
	"title": "Events Metric Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "Options for this widget type include: heatmap and ticker.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/favorite-dashboard/",
	"title": "Favorites",
	"tags": ["#getting started", "#metrics", "#elements", "#dashboards"],
	"description": "",
	"content": " Favorited dashboards display as a drop-down list under Dashboards in the main top navigation menu.\nFavorite a Dashboard  Navigate to the Dashboard menu (or Dashboard \u0026gt; Manage Dashboards). A list of all the dashboards available in your tenant appears. Click \rnext to a dashboard to favorite it.  Unfavorite a Dashboard Repeat the above process and click \rto unfavorite the dashboard. This removes the dashboard from your quick drop-down list in the top navigation menu.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/azure-filter-elements/",
	"title": "Filter Elements",
	"tags": ["#microsoft", "#azure", "#integrations", "#optional config"],
	"description": "",
	"content": " You can filter what Azure elements are included in Metricly’s monitoring by using regex to match key-value pairs. Metricly offers opt-in (include) or opt-out (exclude) element filtering.\nUsing opt-in filtering  In your Azure portal, create or choose an existing tag (key-value pair). Then, assign the tag to the Azure elements you do not want Metricly to monitor. In Metricly, navigate to your Azure integration card. Expand the element types you want to filter. Key-value pair fields display.  Select the Filtering checkbox. Select Include. Type the proper Regex to match the tag(s) you created in your Azure portal for each element type you want to filter. Click Save.  Using opt-out filtering  In your Azure portal, create or choose an existing tag (key-value pair). Then, assign the tag to the Azure elements you do not want Metricly to monitor. In Metricly, navigate to your Azure integration card. Expand the element types you want to filter. Key-value pair fields display.  Select the Filtering checkbox. Select Exclude. Type the proper Regex to match the tag(s) you created in your Azure portal for each element type you want to filter. Click Save.  Using Regex Check out our Regex Guide for some examples.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/flume/",
	"title": "Flume",
	"tags": ["#flume", "#integrations", "#collectors"],
	"description": "",
	"content": " Flume collects and aggregates all of your log files distributed across your environment. Metricly can be used to monitor the performance of your Flume service.\nConfiguration  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the FlumeCollector.conf file. Change the enabled setting to True. Update the req_host, req_port, and/or req_path settings as necessary. Save the configuration file and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting Flume metrics.   req_host localhost Hostname to collect from.   req_port 41414 Port to collect from.   req_path /metrics File path to your Flume service.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/ruby-agent-garbage-collection/",
	"title": "Garbage Collection",
	"tags": ["#ruby", "#integrations", "#agents"],
	"description": "",
	"content": " The garbage collector attempts to return memory consumed by objects no longer in use by your application. Metricly can be used to collect metrics on how much time is spent in garbage collection for your Ruby applications. You should have Matz’s Ruby Interpreter (MRI) version 1.9.2 or greater or Ruby Enterprise Edition installed before enabling garbage collection metrics.\nConfigure  Navigate to your application’s initialization file. Add the following call (depending on your Ruby version) to the file:  For MRI v1.9.2 or greater: GC::Profiler.enable For Ruby Enterprise Edition: GC.enable_stats  Save the file and restart your application.  If you have a Rails application, you can add one of the calls above to an initializer in config/initializers or directly to your config/application.rb.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/categories/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/http-code-collector/",
	"title": "HTTP Code Collector",
	"tags": ["#http code", "#integrations", "#collectors"],
	"description": "",
	"content": " HTTP status codes are useful diagnostic tools for a website to help determine if all content on a website is being delivered properly. Enabling the HTTP code collector for your preferred website will log every status code returned by the website. The first time a status code is returned, our Linux agent will create a metric for that code in Metricly; each subsequent time the status code is returned, another metric will begin to count how many times the code has been returned. Thanks to this unique collector and its metrics, you can create a policy to monitor the status codes that are returned from your website, which can act as a basic check for website status.\nPrerequisites The Linux Agent is required before proceeding with the setup of the HTTP Code Collector. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\nUpdate the Configuration File  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the HttpCodeCollector.conf file. Change the enabled setting to True. Change the req_url setting to contain the web page you want to collect statistics on. Save the file, and restart the Linux Agent.  Collector Options    Option Default Description     enabled False Enable collecting HTTP metrics.   req_url http://example.com/ Comma-separated array of the full URLs to collect statistics on. For applications running on ports other than 80 or 443, users can include the port in the URL (http://example.com:8080/).   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   req_vhost  A host header variable (if necessary) that will be added to each request.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/http-collector/",
	"title": "HTTP Collector",
	"tags": ["#http", "#integrations", "#collectors"],
	"description": "",
	"content": " The HTTP Collector gathers statistics from an HTTP or HTTPS connection.\nPrerequisites The Linux Agent is required before proceeding with the setup of the HTTP Collector. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\nUpdate the Configuration File  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the HttpCollector.conf file. Change the enabled setting to True. For each HTTP(s) you’d like to monitor, update the req_url list:  enabled = True ttl_multiplier = 2 path_suffix = \u0026quot;\u0026quot; measure_collector_time = False byte_unit = byte req_url = https://www.my_server.com/, https://www.my_server.com/assets/jquery.js  5. Save the configuration file and restart the Linux Agent.\nCollector Options    Setting Default Description Type     byte_unit byte Default numeric output(s) str   enabled FALSE Enable collecting these metrics bool   measure_collector_time FALSE Collect the collector run time in ms bool   metrics_blacklist None Regex to match metrics to block. Mutually exclusive with metrics_whitelist NoneType   metrics_whitelist None Regex to match metrics to transmit. Mutually exclusive with metrics_blacklist NoneType   req_url http://localhost/, An array of full URL to get. For applications running on ports other than 80 or 443, users can include the port in the URL (http://localhost:8080/). list   req_vhost  Host header variable if needed. Will be added to every request str    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/httpd/",
	"title": "HTTPD",
	"tags": ["#httpd", "#integrations", "#collectors"],
	"description": "",
	"content": " The HTTP Collector gathers statistics from an HTTP or HTTPS connection.\nPrerequisites The Linux Agent is required before proceeding with the setup of HTTPD. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\nUpdate the Configuration File  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the HttpCollector.conf file. Change the enabled setting to True. For each HTTP(s) you’d like to monitor, update the req_url list:  Collector Options    Option Default Description     enabled FALSE Enable collecting HTTPD metrics.   urls localhost http://localhost:8080/server-status?auto URLs to server-status in auto format, separated by commas.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-hipchat/",
	"title": "HipChat Notifications",
	"tags": ["#alerts", "#notifications", "#hipchat"],
	"description": "",
	"content": " Send a notification to a HipChat room when an event occurs on your Metricly Policies. HipChat notifications are re-usable across multiple policies. Read below for configuration steps.\nConfiguration 1. Generate a room token  Log in to your Hipchat account. Navigate to the Rooms section. Under My Rooms, select or create the desired room. On the left panel, select Tokens. Type a Label for the room and select Send Notification from the scopes list. Click Create to generate a token.  2. Link the room with Metricly  Navigate to a Policy \u0026gt; Notifications. Click Add Notification and choose HipChat.  After clicking Add Hipchat, ensure the Enabled checkbox is selected. Paste the Room Name and Room Token to the corresponding fields. Click Test and Save.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/idle-resources/",
	"title": "Idle Resources",
	"tags": ["#reports", "#idle resources", "#cost"],
	"description": "",
	"content": " Keep track of all of your unused resources with our EBS \u0026amp; ELB Idle Resource reports. Each report supports daily email notifications to keep you informed of changes.\nTo Use Unattached EBS or ELB Reports  Navigate to Reports \u0026gt; Idle Resources. Select Unattached EBS (or ELB).  Available View Sorting Unattached Resource reports can be sorted by each column:\n Name Location Size VolumeId IOPS Type Monthly Cost Simply click on the column header to sort using that preferred column.  Subscribe to Your Report  Navigate to the Reports main page. Scroll down to the Unattached EBS (or ELB) Report card.  Click the Enable Daily Email Toggle.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-asg-recommendations/item_second/inside_first_item/",
	"title": "Inside First Item",
	"tags": ["#lorem", "#elit", "#voluptatibus"],
	"description": "",
	"content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Voluptatibus ratione, animi maxime expedita vitae maiores cum mollitia. Consequuntur cum laudantium doloremque repellendus, numquam in alias ex amet, a fugiat libero!Lorem ipsum dolor sit amet consectetur adipisicing elit. Voluptatibus ratione, animi maxime expedita vitae maiores cum mollitia. Consequuntur cum laudantium doloremque repellendus, numquam in alias ex amet, a fugiat libero!Lorem ipsum dolor sit amet consectetur adipisicing elit. Voluptatibus ratione, animi maxime expedita vitae maiores cum mollitia. Consequuntur cum laudantium doloremque repellendus, numquam in alias ex amet, a fugiat libero!\nLorem ipsum dolor sit amet consectetur adipisicing elit. Voluptatibus ratione, animi maxime expedita vitae maiores cum mollitia. Consequuntur cum laudantium Jerky turkey bacon ham hock, meatloaf buffalo tongue tri-tip sirloin bresaola frankfurter pork chop ham strip steak fatback. Burgdoggen venison brisket jowl hamburger ribeye meatloaf chicken biltong alcatra andouille jerky ham ball tip. Andouille short loin pastrami pancetta. Short ribs frankfurter short loin spare ribs shoulder capicola pork landjaeger. Short loin frankfurter meatball leberkas chicken pork tongue ball tip filet mignon pork chop bacon. Pork chop short loin drumstick chicken, meatball pork cow kielbasa ball tip. Leberkas shoulder kevin, capicola boudin short loin pork loin.\nShort ribs tongue swine, ribeye cow shank andouille pork belly fatback frankfurter spare ribs shankle. Short ribs t-bone shoulder tri-tip pork belly bresaola beef salami corned beef. Jowl bacon boudin, drumstick bresaola tri-tip jerky rump pork belly ribeye. Pork belly spare ribs buffalo prosciutto. Salami meatloaf picanha, beef cow sausage pancetta. Cow t-bone strip steak, ham hock meatball chuck ribeye short ribs pig boudin biltong ground round flank chicken rump.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-asg-recommendations/item_second/inside_second_item/",
	"title": "Inside Second Item",
	"tags": ["#bacon", "#beef"],
	"description": "",
	"content": "Bacon ipsum dolor amet ball tip picanha kevin meatloaf strip steak leberkas. Prosciutto venison kevin shank ground round sirloin capicola drumstick meatball filet mignon andouille shoulder. Chuck porchetta capicola, sirloin prosciutto rump bacon buffalo cow picanha corned beef t-bone ham spare ribs. Leberkas short loin spare ribs beef burgdoggen ribeye filet mignon biltong.\nGround round alcatra shoulder, ham spare ribs flank pastrami ribeye meatball prosciutto turducken fatback strip steak bresaola cupim. Swine corned beef pork chop porchetta sirloin pancetta turducken doner bacon alcatra frankfurter. Cupim alcatra pig prosciutto picanha strip steak shank frankfurter ham hock shankle turducken. Filet mignon spare ribs burgdoggen buffalo tongue.\nAlcatra doner corned beef, prosciutto fatback swine picanha meatball burgdoggen. Jowl pork drumstick tongue, pork belly cupim alcatra spare ribs. Tri-tip jerky ham shankle chuck jowl spare ribs pastrami salami prosciutto cupim. Spare ribs beef ribs kevin, andouille venison flank pancetta corned beef cow porchetta hamburger rump turducken. Pork belly drumstick capicola, meatloaf spare ribs prosciutto beef jowl turkey bacon shoulder alcatra jerky. Ham hock shank chuck jerky pastrami chicken turkey beef ribs ball tip filet mignon drumstick.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/categories/integration/",
	"title": "Integration",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-interface-metrics/",
	"title": "Interface Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#interface", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     interface-\u0026lt;int\u0026gt;.if_errors.rx Errors per second received. average errors/second 0 none none yes no no   interface-\u0026lt;int\u0026gt;.if_errors.tx Errors per second sent. average errors/second 0 none none yes no no   interface-\u0026lt;int\u0026gt;.if_octets.rx Bytes per second received. average bytes/second 0 none none yes no no   interface-\u0026lt;int\u0026gt;.if_octets.tx Bytes per second sent. average bytes/second 0 none none yes no no   interface-\u0026lt;int\u0026gt;.if_packets.rx Packets per second received. average packets/second 0 none none yes no no   interface-\u0026lt;int\u0026gt;.if_packets.tx Packets per second sent. average packets/second 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Statistic Units Min Max BASE CORR UTIL     metricly.collectd.interface-*.if_errors.total Errors per second received.Computation:interface-.if_errors.tx + interface-.if_errors.rx average errors/second 0 none yes no no   metricly.collectd.interface-*.if_octets.total Bytes per second received.Computation:interface-.if_octets.tx + interface-.if_octets.rx average bytes/second 0 none yes no no   metricly.collectd.interface-*.if_packets.total Packets per second received.Computation:interface-.if_packets.tx + interface-.if_packets.rx average packets/second 0 none yes yes no   metricly.collectd.interface-*.if_errors.percent Percentage of packet errors.Computation:(metricly.collectd.interface-.if_errors.total /metricly.collectd.interface-.if_packets.total) * 100 average percent 0 100 yes yes no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/ruby-agent-interpret-exceptions/",
	"title": "Interpret Exceptions",
	"tags": ["#ruby", "#integrations", "#agents"],
	"description": "",
	"content": "IF sendErrorEvents is enabled in the netuitive_rails_agent config/agent.yaml file AND actionErrorsEnabled and/or sidekiqEnabled = true, exceptions are sent to Metricly as external events.\nAn Exception External event has the following tags to help you dissect the exception:\n   Tag Description     Action The action the error originated from.   Controller The name of the controller that the exception came from.   Exception The type of exception.   Sidekiq If true, this exception comes from sidekiq. If false, this exception comes from elsewhere.   URI The resource identifier that names the resource the exception came from.    Because these tags are located within the message body, you can create a policy matching against the body of the message.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/iris/",
	"title": "Iris",
	"tags": ["#iris", "#integrations", "#java"],
	"description": "",
	"content": " Iris is a Java library that allows your Java applications to communicate with Metricly’s REST API. You can use Iris to send metrics from your applications to Metricly, create dashboards, tags, elements, and much more.\nConfiguration  Include the proper dependency from Maven for the appropriate build manager. Invoke the REST API client interface in a central location that your various Java classes can access while ensuring you replace username and password with the appropriate values.  MetriclyElementClient elementClient = new MetriclyElementRestClient (\u0026quot;username\u0026quot;, \u0026quot;password\u0026quot;);  3. You may now send requests to the Metricly REST API. To read more about our API, find links to explore our API, and test some requests, see the API help section. Links to each client.java file follow where you can find the types of requests you can make and what parameters you can pass in:\n Elements:  Element client (request types) / Element REST client (params)\n  Events:  Event client / Event REST client Ingest Event client / Ingest Event REST client\n  Metrics:  Ingest Metric client / Ingest Metric REST client Metric client / Metric REST client Notification client / Notification REST client Policy client / Policy REST client   Example Requests Element elementClient.listElements(new ListElementsRequest() .withStartDate([date]) .withEndDate([date]));  Event eventClient.getEvents(new GetEventsRequest() .withIsExternal(true) .withCategory(\u0026quot;CRITICAL\u0026quot;));  Metric metricClient.getMetricStatistics(new GetMetricStatisticsRequest() .withRollup(\u0026quot;5M\u0026quot;) .withFqn(\u0026quot;aws.ec2.cpuutilization\u0026quot;));  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-asg-recommendations/item_first/",
	"title": "Item First",
	"tags": ["#reports", "#asg"],
	"description": "",
	"content": "Bacon ipsum dolor amet ball tip picanha kevin meatloaf strip steak leberkas. Prosciutto venison kevin shank ground round sirloin capicola drumstick meatball filet mignon andouille shoulder. Chuck porchetta capicola, sirloin prosciutto rump bacon buffalo cow picanha corned beef t-bone ham spare ribs. Leberkas short loin spare ribs beef burgdoggen ribeye filet mignon biltong.\nGround round alcatra shoulder, ham spare ribs flank pastrami ribeye meatball prosciutto turducken fatback strip steak bresaola cupim. Swine corned beef pork chop porchetta sirloin pancetta turducken doner bacon alcatra frankfurter. Cupim alcatra pig prosciutto picanha strip steak shank frankfurter ham hock shankle turducken. Filet mignon spare ribs burgdoggen buffalo tongue.\nAlcatra doner corned beef, prosciutto fatback swine picanha meatball burgdoggen. Jowl pork drumstick tongue, pork belly cupim alcatra spare ribs. Tri-tip jerky ham shankle chuck jowl spare ribs pastrami salami prosciutto cupim. Spare ribs beef ribs kevin, andouille venison flank pancetta corned beef cow porchetta hamburger rump turducken. Pork belly drumstick capicola, meatloaf spare ribs prosciutto beef jowl turkey bacon shoulder alcatra jerky. Ham hock shank chuck jerky pastrami chicken turkey beef ribs ball tip filet mignon drumstick.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-asg-recommendations/item_second/",
	"title": "Item Second",
	"tags": ["#reports", "#asg", "#directory page"],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-asg-recommendations/item_third/",
	"title": "Item Third",
	"tags": ["#reports", "#asg"],
	"description": "",
	"content": "Bacon ipsum dolor amet ball tip picanha kevin meatloaf strip steak leberkas. Prosciutto venison kevin shank ground round sirloin capicola drumstick meatball filet mignon andouille shoulder. Chuck porchetta capicola, sirloin prosciutto rump bacon buffalo cow picanha corned beef t-bone ham spare ribs. Leberkas short loin spare ribs beef burgdoggen ribeye filet mignon biltong.\nGround round alcatra shoulder, ham spare ribs flank pastrami ribeye meatball prosciutto turducken fatback strip steak bresaola cupim. Swine corned beef pork chop porchetta sirloin pancetta turducken doner bacon alcatra frankfurter. Cupim alcatra pig prosciutto picanha strip steak shank frankfurter ham hock shankle turducken. Filet mignon spare ribs burgdoggen buffalo tongue.\nAlcatra doner corned beef, prosciutto fatback swine picanha meatball burgdoggen. Jowl pork drumstick tongue, pork belly cupim alcatra spare ribs. Tri-tip jerky ham shankle chuck jowl spare ribs pastrami salami prosciutto cupim. Spare ribs beef ribs kevin, andouille venison flank pancetta corned beef cow porchetta hamburger rump turducken. Pork belly drumstick capicola, meatloaf spare ribs prosciutto beef jowl turkey bacon shoulder alcatra jerky. Ham hock shank chuck jerky pastrami chicken turkey beef ribs ball tip filet mignon drumstick.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/jmx/",
	"title": "JMX",
	"tags": ["#flume", "#integrations", "#collectors"],
	"description": "",
	"content": " Prerequisites The Linux Agent is required before proceeding with the setup of HTTPD. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\nConfiguration  Download the Jolokia JVM JAR file. Move the downloaded file to the /opt/netuitive-agent/ directory. Pass the Java agent parameter into your application:  -javaagent:/opt/agent.jar=port=8778,host=0.0.0.0  4. Navigate to the collectors folder. 5. Open the JolokiaCollector.conf file. 6. Change the enabled setting to True. 7. Save the configuration file and restart the Linux Agent.\nConfiguration Options    Option Default Description     enabled FALSE Enable collecting Jolokia metrics.   host localhost Hostname to collect from.   port 8778 Port to collect from.   path jmx The metric prefix, e.g., how you want the metrics to show up in Metricly.   jolokia_path jolokia Part of the URL path that points to where your application serves metrics. Typically jmx or jolokia.   mbeans java.* Pipe (   regex TRUE Enables the mbeans option to match with regex.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelistoption.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.   password  Password used for authentication.   rewrite  Config sub-section that contains pairs of from-to regex rewrites.   username  Username used for authentication.    Rewrite Example mbeans = \u0026quot;...\u0026quot; [rewrite] java = coffee \u0026quot;-v\\d+\\.\\d+\\.\\d+\u0026quot; = \u0026quot;-AllVersions\u0026quot; \u0026quot;.*Gets2Activities.*\u0026quot; = \u0026quot;\u0026quot;...  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/",
	"title": "Java Agent",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " Metricly’s Java agent is a java monitoring agent with a programmable bytecode instrumentation engine that’s enabled by adding a JVM integration in Metricly. The Metricly Java integration allows Metricly to collect JVM runtime system metrics like CPU, Memory, GC, Threads and Classes Count, and application components method performance statistics, such as number of calls and execution time.\nPrerequisites Must have Java 6 Or greater.\nConfiguration 1. Copy API key  From the top navigation menu, select Integrations. Select the Java card. The name should be already populated, and Data Collection should be enabled. A unique API key for your account has already been generated. Copy the API key.  2. Download the Netuitive Java agent  Download the Netuitive Java agent. Unzip the netuitive-zorka.zip file to the desired location. We recommend that you unzip the netuitive-zorka.zip file near the app it is monitoring.  You can also use the following command to obtain the most recent version of the Java Agent:\ncurl -s https://api.github.com/repos/Netuitive/zorka/releases/latest | jq -r \u0026quot;.assets[] | .browser_download_url\u0026quot;\n\rEdit Config File  Navigate to the zorka.properties file that was included in the netuitive-zorka-{version}.zip. Enable the jvm.bsh script and any other scripts as necessary at the top of the file. Change zorka.hostname and zorka.application to the correct value. zorka.hostname should be the fully qualified domain name of the host and zorka.application should be the name of your Java application. Optionally, if you’re setting up the Java agent on JBoss, you should change the zorka.mbs.autoregister setting to no. Optionally, if you’d like the Zorka Log to be managed by the default syslog, change the zorka.syslog setting to yes. Read more about the zorka.syslog setting here. Optionally, if you want Zorka to monitor clusters:  Uncomment zorka.clusters in the zorka.properties file and include the name of each element. The default setting (cluster 1, cluster 2) would create a JVM () element and two CLUSTER () elements with the names cluster1 and cluster2. zorka.clusters = cluster1, cluster2 If you want to specify the element type of the clusters, uncomment zorka.clusters.type and change the setting to the desired element type. If the type is not specified, the default is CLUSTER. zorka.clusters.type = CLUSTER  Change the netuitive.api.key value to the unique API key generated for your account that you copied in step 1. Ensure the netuitive.api value is set to yes to enable data push to Metricly. Modify the netuitive.api.interval value to the desired data push interval (in seconds). The agent will collect data at the desired interval but aggregate the values each minute and send a single set of values to the API. Data is sent as statistics (min, max, sum, avg, and count) instead of raw values. Data in the Metrics pagefor your JVM metrics is displayed using gauges instead of a counter to capture any delta between data points. Restart your app server with the following argument passed to the JVM (where the default path to the Netuitive Java agent unzipped directory is /opt/netuitive-zorka/):   -javaagent:[path-to-netuitive-zorka-unzipped-dir]/netuitive.jar=[path-to-netuitive-zorka-unzipped-dir]  This integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\nExamples We want to run the java application zorka-core-test.jar with our Java agent specified in the -javaagent JVM option.\n java -javaagent:/opt/netuitive-zorka/netuitive.jar=/opt/netuitive-zorka -jar zorka-core-test.jar  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/java-policies/",
	"title": "Java Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#java"],
	"description": "",
	"content": "   Policy name Duration Conditions Category Description     Elevated JVM CPU Activity 15 min cpu.used.percent has an upper baseline deviation + an upper contextual deviation + a static threshold \u0026gt; 50% WARNING This policy will generate a WARNING event when the JVM’s CPU activity is higher than expected. Additionally, the CPU usage is above 50%.   Elevated JVM Heap Usage 15 min metricly.jvm.heap.utilizationpercent has an upper baseline deviation + an upper contextual deviation WARNING This policy will generate a WARNING event when the JVM’s heap usage is higher than expected.   Elevated JVM System Threads 15 min system.threads has an upper baseline deviation + an upper contextual deviation WARNING This policy will generate a WARNING event when the number of system threads used by the JVM is higher than expected.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/kafka/",
	"title": "Kafka",
	"tags": ["#kafka", "#integrations", "#collectors"],
	"description": "",
	"content": " Kafka is a publish-subscribe message queuing system that’s designed like a distributed commit log. Metricly can help monitor the performance and throughput of your Kafka server using our Kafka collector for the Linux agent. Kafka, Kafka Consumer Lag, and Zookeeper metrics are all collected using this collector.\nPrerequisites The [Linux Agent][1] is required before proceeding with the setup of HTTPD. If you need to disable the Linux integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Infrastructure under the Integration column.\nConfiguration  Download the Jolokia JVM JAR file. Move the downloaded file to the /opt/netuitive-agent/ directory. Run the following at the command line to set an environment variable:  export KAFKA_OPTS=\u0026quot;$KAFKA_OPTS -javaagent:/opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar\u0026quot;  Restart Kafka, and confirm Jolokia is running by accessing http://localhost:8778/jolokia/ Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the KafkaJolokiaCollector.conf file. Change the enabled setting to True. Update version to be the version of Kafka running on your machine and uncomment the line.  Optionally, update host and port to the correct settings.  Save the file, and restart the Linux Agent.  This integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\nCollector Options The path and jolokia_path settings should not be changed without consulting Metricly support first.\n   Option Default Description     enabled FALSE Enable collecting Kafka metrics.   path kafka The metric prefix, e.g., how you want the metrics to show up in Metricly.   jolokia_path jolokia Part of the URL path that points to where your application serves metrics. Typically jmx or jolokia.   metrics_blacklist .*Percentile$ .FifteenMinuteRate.   host localhost Hostname/IP address by which the Kafka instance can be reached by the Linux agent.   port 8778 The port that the Jolokia JAR file is listening on.   version 0.8 Specifies the Kafka major release being used on the host. Currently, Metricly supports 0.8, 0.9, and 0.10.   zookeeper localhost:2181 The hostname / IP address as well as the port by which the Zookeeper instance can be reached by the Linux agent.   bin /opt/kafka/bin/kafka-run-class.sh The location of the kafka-run-class.sh file. Certain metrics must be retrieved via command line calls, thus the location of kafka-run-class.sh is a necessity. The exception to this being if you’re running Kafka in a Docker container; see the argssetting below for more information.   args exec {kafka-container-id} {kafka-run-class.sh} The argument passed to Kafka running in a docker container. If you are running Kafka in a docker container, you’ll need to set the bin setting to the location of the docker binary. Then, you’ll need to replace {kafka-container-id} with the ID of your Kafka container and {kafka-run-class.sh} with the location of the kafka-run-class.sh file within the container.   consumer_groups Group1, Group2, Group3 For Kafka 8 or earlier: This setting specifies a list of consumer groups that you want to receive consumer lag metrics. If you do not specify this, no consumer lag metrics will be collected. For Kafka 9 or later: This setting is ignored as consumer groups can be auto-discovered.   topics Topic1, Topic2, Topic3 For Kafka 8 or earlier: This setting specifies a list of topics associated with the consumer groups. If you do not specify this, all topics are considered. For Kafka 9 or later: this setting is ignored.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/kafka/kafka-metrics/",
	"title": "Kafka Metrics",
	"tags": ["#kafka", "#integrations", "#collectors", "#metrics"],
	"description": "",
	"content": " Due to the sheer volume of Kafka metrics, the individual metrics won’t be documented here. Instead, this page outlines general properties for the groups of metrics.\nProperties All Metrics Share:  Statistic: average Min: 0 CORR: no UTIL: no BASE:  On for most metrics Off for metrics matching the following regexes: ^kafka.cluster.* ^kafka\\.utils\\..* ^kafka\\.log\\..*(LogEndOffset|LogStartOffset)$ ^kafka\\.controller\\.((?!broker-\\d).).* ^kafka\\.consumer_group\\.((?!consumer_lag$).)*$   Metrics That End With Percent:  Unit: percent Max: 1  Metrics With Bytes.*PerSec or byte-rate:  Unit: Bps (bytes per second) SDS: ReplaceWithZero  Metrics For Units of Time:  Unit  If the metric name ends with Ms.Mean, time-avg, or time-max then the units are ms (milliseconds) If the metric name contains time-ns, then the units are ns(nanoseconds) If the metric name contains time-secs, then the units are seconds  SDS: ReplaceWithZero  Other Metrics  For metrics matching kafka\\.(server|network)\\..*Metrics\\..*\\.Count orkafka.zookeeper.zk_packets.*:\n Type: COUNTER  The Zookeeper has_owner metric:\n Max: 1  All Zookeeper latency metrics (zk_.*latency):\n Unit: ms (milliseconds)  All Zookeeper data size metrics (zk_.*data_size):\n Unit: bytes   "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/kafka-policies/",
	"title": "Kafka Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#kafka"],
	"description": "",
	"content": "Policy names are prefixed with Kakfa –\n\r   Policy name Duration Condition 1 (and) Condition 2 Category Description     Depressed Number of Zookeeper Connections 30 min kafka.zookeeper.zk_num_alive_connections has a lower baseline deviation  WARNING The number of active connections to Zookeeper has been lower than expected for at least the past 30 minutes.   Elevated Consumer Lag 15 min kafka.zookeeper.consumer_groups.*.comsuler_lag has an upper baseline deviation  WARNING Consumer lag has been higher than expected for at least 15 minutes.   Elevated Consumer Purgatory Size 15 min kafka.server.DelayedOperationPurgatory.Fetch.PurgatorySize hasan upper baseline deviation  WARNING The purgatory size for consumer fetch requests is higher than expected. This may be causing increases in consumer request latency.   Elevated Consumer Servicing Time 15 min kafka.network.RequestMetrics.FetchConsumer.TotalTimeMs.Meanhasan upper baseline deviation  WARNING The broker is taking longer than usual to service consumer requests.   Elevated Number of Outstanding Zookeeper Requests 15 min kafka.zookeeper.zk_outstanding_requests has an upper baseline deviation  WARNING The number of outstanding Zookeeper requests has been higher than expected for at least the past 15 minutes. This could be resulting in performance issues.   Elevated Producer Purgatory Size 15 min kafka.server.DelayedOperationPurgatory.Produce.PurgatorySizehasan upper baseline deviation  WARNING The purgatory size for producer requests is higher than expected. This may be causing increases in producer request latency.   Elevated Producer Servicing Time 15 min kafka.network.RequestMetrics.Produce.TotalTimeMs.Mean has an upper baseline deviation  WARNING The broker is taking longer than usual to service producer requests.   Elevated Topic Activity 30 min iBrokerTopicMetrics._all.BytesInPerSec.Count has an upper baseline deviation BrokerTopicMetrics._all.BytesOutPerSec.Count has an upper baseline deviation WARNING Topic activity has been higher than expected for at least the past 30 minutes.   Elevated Zookeeper Latency 15 min kafka.zookeeper.zk_avg_latency has an upper baseline deviation  WARNING The average latency for Zookeeper requests has been higher than expected for at least the past 15 minutes.   Extended Period of Consumer Lag 1 hour and 15 min kafka.zookeeper.consumer_groups.*.consumer_lag has an upper baseline deviation  CRITICAL Consumer lag has been higher than expected for over an hour.   No Active Controllers 5 min kafka.controller.ActiveControllerCount has a static threshold \u0026lt; 1  CRITICAL There are no active controllers in the Kafka cluster.   Unclean Leader Election Rate Greater Than 0 5 min kafka.controller.UncleanLeaderElectionsPerSec.Count has a static threshold \u0026gt; 0  CRITICAL An out-of-sync replica was chosen as leader because none of the available replicas were in sync. Some data loss has occurred as a result.   Under Replicated Partition Count Greater Than 0 30 min kafka.server.ReplicaManager.UnderReplicatedPartitions has a static threshold \u0026gt; 0  CRITICAL The number of partitions which are under-replicated has been greater than 0 for at least 30 minutes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/kafka/kafka-in-docker/",
	"title": "Kafka in Docker",
	"tags": ["#kafka", "#integrations", "#collectors", "#docker"],
	"description": "",
	"content": " Getting the Jolokia agent running in a Kafka container requires three additional modifications to the docker run command. To illustrate the modifications needed, we’re going to assume that your docker run command looks like this initially:\ndocker run -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=`docker-machine ip\\`docker-machine active\\`` --env ADVERTISED_PORT=9092 spotify/kafka  Update Docker Run Command  Make the Jolokia JAR file available to the container by passing it in as a mounted volume.  -v /opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar:/opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar  2. Pass in the KAFKA_OPTS environment variable to Kafka so it starts with the Jolokia agent included.\n-e KAFKA_OPTS=-javaagent:/opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar=port=8778,host=0.0.0.0  3. Expose the Jolokia port.\n-p 8778:8778  Here’s what the full command looks like with the three additional portions added:\ndocker run -p 2181:2181 -p 9092:9092 -p 8778:8778 -e ADVERTISED_HOST=`docker-machine ip \\`docker-machine active\\`` -e ADVERTISED_PORT=9092 -e KAFKA_OPTS=-javaagent:/opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar=port=8778,host=0.0.0.0 -v /opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar:/opt/netuitive-agent/jolokia-jvm-1.3.4-agent.jar spotify/kafka  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-knesis/",
	"title": "Knesis Metrics",
	"tags": ["#aws", "#metrics", "#knesis"],
	"description": "",
	"content": " Currently, Metricly only supports Kinesis Streams, but additional support for Kinesis Firehose may come in the future.\nCollected    Fully Qualified Name (FQN) AWS Metric Statistic Units Sparse Data Strategy (SDS) BASE CORR     aws.kinesis.getrecords.bytes GetRecords.Bytes average bytes zero yes yes   aws.kinesis.getrecords.iteratoragemilliseconds GetRecords.IteratorAgeMilliseconds average ms zero yes no   aws.kinesis.getrecords.latency GetRecords.Latency average ms zero yes yes   aws.kinesis.getrecords.records GetRecords.Records sum ops zero yes yes   aws.kinesis.getrecords.success GetRecords.Success sum ops zero yes yes   aws.kinesis.incomingbytes IncomingBytes sum bytes zero yes yes   aws.kinesis.incomingrecords IncomingRecords sum ops zero yes yes   aws.kinesis.putrecord.bytes PutRecord.Bytes sum bytes zero yes yes   aws.kinesis.putrecord.latency PutRecord.Latency average ms zero yes yes   aws.kinesis.putrecord.success PutRecord.Success sum ops zero yes yes   aws.kinesis.putrecords.bytes PutRecords.Bytes sum bytes zero yes yes   aws.kinesis.putrecords.latency PutRecords.Latency average ms zero yes yes   aws.kinesis.putrecords.records PutRecords.Records sum ops zero yes yes   aws.kinesis.putrecords.success PutRecords.Success sum ops zero yes yes   aws.kinesis.readprovisionedthroughputexceeded ReadProvisionedThroughputExceeded sum ops zero no no   aws.kinesis.writeprovisionedthroughputexceeded WriteProvisionedThroughputExceeded sum ops zero no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/kubernetes/",
	"title": "Kubernetes",
	"tags": ["#kubernetes", "#integrations"],
	"description": "",
	"content": " This integration allows you to monitor the data and elements from your Kubernetes environments. Setup is quick, with data appearing in your account as soon as 5 minutes after installation.\nPrerequisites These steps assume you have already spun up a Kubernetes cluster and can interact with it using the kubectl command. If you have not yet set up Kubernetes, see their GitHub documentation.\nUsing RBAC? If you are implementing Kubernetes with Role-based Access Control (RBAC Authorization), you must include ClusterRoleBinding instructions to the Metricly deployment YAML file found in step 1.1. These instructions allow metrics to be collected. Simply add the following to your YAML file and complete the setup instructions as written.\nkind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: heapster roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:heapster subjects: - kind: ServiceAccount name: heapster namespace: kube-system  1. Download Heapster YAML File  Download this file. Open terminal and locate your YAML file. Name the file config.yaml. Replace the {apiKey} value in the YAML file with the one found in Metricly under Integrations \u0026gt; Kubernetes.   apiVersion: v1 kind: ServiceAccount metadata: name: heapster namespace: kube-system --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: heapster namespace: kube-system spec: replicas: 1 template: metadata: labels: task: monitoring k8s-app: heapster spec: serviceAccountName: heapster containers: - name: heapster image: index.docker.io/metricly/heapster:0.0.5 imagePullPolicy: IfNotPresent command: - /heapster - --source=kubernetes:https://kubernetes.default - --sink=metricly:https://api.app.metricly.com/ingest/kubernetes?apiKey={apiKey} --- apiVersion: v1 kind: Service metadata: labels: task: monitoring # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons) # If you are using this as an addon, you should uncomment this line. # kubernetes.io/cluster-service: 'true' # kubernetes.io/name: Heapster name: heapster namespace: kube-system spec: ports: - port: 80 targetPort: 8082 selector: k8s-app: heapster  5. Save and close the file.\n2. Run Setup Command  Run the following command in terminal. Make sure that you use the correct path to your config file.  kubectl create -f path/to/heapster/config.yaml  2. Verify that your heapster pod is running with the below command. It should state READY 1/1 and STATUS Running next to a heapster pod.\nkubectl get pods --namespace-kube-system  3. View Your Data Once setup is complete, it takes approximately 5 minutes for data to display in Metricly. All metrics can be found on the metrics page, and your Kubernetes elements can be found in the inventory page.\nIf you do not wish to use the packaged policies and dashboards that Metricly provides, navigate to Integrations \u0026gt; Kubernetes and disable the PACKAGES toggle.\nKubernetes Types Once you have installed this package, the Inventory tab updates to include the following filterable element types:\n Cluster Namespace Node Pod Pod Container Sys Container  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-lambda/",
	"title": "Lambda Metrics",
	"tags": ["#aws", "#metrics", "#lambda"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) AWS Metric Statistic Units Sparse Data Strategy (SDS) BASE CORR     aws.lambda.duration GAUGE average milliseconds zero yes yes   aws.lambda.errors GAUGE sum count zero no no   aws.lambda.invocations GAUGE sum count zero yes yes   aws.lambda.throttles GAUGE sum count zero no no    Computed    Friendly Name FQN Computation Units Min Max Description     Error Percent netuitive.aws.lambda.errorpercent (data[‘aws.lambda.invocations’] == null data[‘aws.lambda.invocations’].actual == 0) ? 0 : (data[‘aws.lambda.errors’].actual / data[‘aws.lambda.invocations’].actual) * 100 percent 0 0   Throttle Percent netuitive.aws.lambda.throttlepercent (data[‘aws.lambda.invocations’] == null data[‘aws.lambda.invocations’].actual == 0) ? 0 : (data[‘aws.lambda.throttles’].actual / (data[‘aws.lambda.invocations’].actual + data[‘aws.lambda.throttles’].actual)) * 100 percent 100 100    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/linux-agent/",
	"title": "Linux Agent",
	"tags": ["#agents", "#linux"],
	"description": "",
	"content": "Using the Linux Agent, you can quickly deploy and collect metrics with a rich set of metadata.\nThe agent discovers and collects KPI metrics, integrates with CloudWatch, and can leverage other agent metrics. Using various plugins, the Linux Agent can also pull metrics from many different products running on a Linux operating system (in addition to pulling metrics from the host Linux OS).\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/checks/linux-checks/",
	"title": "Linux Checks",
	"tags": ["#alerts", "#notifications", "#checks", "#linux"],
	"description": "",
	"content": " Enable Linux Checks Currently, Metricly comes with three pre-built checks; Heartbeat, Processes, and Ports. These are turnkey checks that do not require any scripting or coding, just simple configuration setting in the respective configuration files.\n Make sure the Linux agent is installed. Metricly checks can be enabled via the configuration files included with the agent. All checks configuration files for the Linux agent can be found in /opt/netuitive-agent/conf/collectors Some of the checks are enabled by default, while you would need to enable other checks.  Heartbeat Check This check is enabled by default. For additional configuration, you can modify the following in the HeartbeatCollector.conf file where TTL represents Time To Live of the check and is expressed in seconds:\nenabled = True ttl = 120  Port Checks This check is not enabled by default. To enable Port Checks, update the PortCheckCollector.conf file. Make sure to follow the structure indicated in the file for [port] and [port_app_name].\n# To enable the collector, set to True. # Configure the ports that need to be monitored. # [port] is the parent and [[port_app_name]] are the child entries. # Child entries must be listed below the parent as shown below. enabled = False ttl = 150 [port] [[port_app_name]] number = 8888  Process Checks This check is not enabled by default. Users need to update ProcessCheckCollector.conf to enable the collector and configure the processes that need to be monitored. There are three options for matching a process: process name, process executable or process command line.\nexe and name are both lists of comma-separated regexps.\n\rMatch by Name [[nginx]] name=^nginx  Match by Executable [[postgres]] exe=^/usr/lib/postgresql/+d.+d/bin/postgres$  Match by Command Line [[elasticsearch]] cmdline=java.*Elasticsearch  DNS Checks The DNS check is not enabled by default. Users need to update the DNSLookupCheckCollector.conf file to enable this collector. URLs added to this list must be in the following format: www.google.com. Note that the dnsAddressList requires a comma even when only one URL is provided. If the comma is not added, the collector returns with a ‘cannot resolve hostname‘ error.\nenabled = true ttl = 150 #Replace www.google.com and www.yahoo.com with the DNS names you want to check dnsAddressList = www.google.com, www.yahoo.com  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/diamond-agent-load-average-metrics/",
	"title": "Load Average Metrics",
	"tags": ["#diamond", "#integrations", "#agents", "#load average"],
	"description": "",
	"content": " Computed    Fully Qualified Name(FQN) Description Units Min Max BASE CORR UTIL     metriclyicly.linux.loadavg.01.normalized The is the average run queue size over the past minute, normalizedacross CPUs. Computation: attribute[‘cpus’] == null ? null : (data[‘loadavg.01’].actual /attribute[‘cpus’].value)  0 none yes no no   metriclyicly.linux.loadavg.05.normalized The is the average run queue size over the past 5 minutes, normalizedacross CPUs. Computation: attribute[‘cpus’] == null ? null : (data[‘loadavg.05’].actual /attribute[‘cpus’].value)  0 none yes yes no   metriclyicly.linux.loadavg.15.normalized The is the average run queue size over the past 15 minutes, normalizedacross CPUs. Computation: attribute[‘cpus’] == null ? null : (data[‘loadavg.15’].actual /attribute[‘cpus’].value)  0 none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-load-metrics/",
	"title": "Load Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#load", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     load.load.longterm The is the average run queue size over the past 15 minutes. average queued processes 0 none none yes no no   load.load.midterm The is the average run queue size over the past 5 minutes. average queued processes 0 none none yes yes no   load.load.shortterm The is the average run queue size over the past minute. average queued processes 0 none none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-mq/",
	"title": "MQ Metrics",
	"tags": ["#aws", "#metrics", "#mq"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) AWS Metric Statistic Units Sparse Data Strategy (SDS) BASE CORR     aws.mq.cpuutilization CpuUtilization  percent      aws.mq.heapusage HeapUsage  percent      aws.mq.networkin NetworkIn  bytes      aws.mq.networkout NetworkOut  bytes      aws.mq.totalmessagecount TotalMessageCount  count       "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/inventory/inventory-main-navigation/",
	"title": "Main Navigation",
	"tags": ["#getting started", "#metrics", "#elements", "#inventory page"],
	"description": "",
	"content": " Select Filters Contains several filters where you can search for element names, element types, tags, attributes, collectors, and more. Expand the More filter to see additional filters; select a filter to add it to the list of active filters.\nSave Filters Filters you create in the navigation panel can be saved.\n Click \rSAVE. Provide a filter name and click \ror hit enter. Share filter if desired via \r.  Choose Time Frame Setting a Time Frame controls the range of elements shown in the Inventory Explorer Elements table. The number of elements displayed on the Inventory Explorer is dependent upon the time frame setting (i.e., an element that was available a week ago but not available now would show on the list when 1w is selected).\nAdd/Remove Columns You can add and remove columns to the Inventory Explorer Elements table for a custom view from this sub-menu.\n Click \rin the upper right hand corner of the page. Select or deselect options from the Tags and Attributes filters to show or hide columns in the Elements table. Some attributes may be available for AWS elements only.  To return to the default columns in Inventory Explorer, select Reset Defaults in the Table Columns dialog.  Click \ragain to view your changes.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/metrics/metric-charts-manipulate/",
	"title": "Manipulate Metric Charts",
	"tags": ["#getting started", "#metrics", "#charts"],
	"description": "",
	"content": " Metric charts offer functionality that allow you to merge two charts together, move charts around on the Metrics page dashboard, zoom in, and drop a marker on a data point.\nMerge Metric Charts Click on the header of one metric chart and drag it on top of another chart into the green merge region. Click to unmerge the metric charts.\nMove Metric Charts Click on the header of one metric chart and drag it into the blue move region located above a different chart. The chart will take the place of the chart to which it is dragged.\nZoom in on a Chart Click and drag across the area on a chart that you want to view.\nWhen you zoom in on one chart, Performance Explorer will automatically zoom in on all charts in the same location.\nDrop a Marker Click on a chart in an area that aligns with a data point.\nWhen you drop a marker on one chart, Performance Explorer will automatically drop markers on all charts in the same location. You can only drop a marker on a chart if you’re clicking outside of the Baseline and Contextual bands.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-manual-install/",
	"title": "Manual Install",
	"tags": ["#windows", "#integrations", "#install"],
	"description": "",
	"content": " Manually Install the Windows Agent  Download the latest Windows Agent. Ensure you download the correct version for your environment. Run the setup wizard and follow the instructions to install it. Navigate to the** WriteNetuitive.config** file (C:\\Program Files\\CollectdWin\\config or C:\\Program Files (x86)\\CollectdWin\\config depending on your environment. Open the file and locate the line \u0026lt;WriteNetuitiveURL=\u0026quot;https://api.app.metricly.com/ingest/windows/{apikey}\u0026quot; /\u0026gt;. Replace {apikey} in the URL with the API key generated in step 1. Save the file and restart the agent.  Manually Update Host Name  After downloading the Windows agent, open the CollectdWin.config file. At the top of the file, update the Hostname setting to the desired value.  \u0026lt;GeneralSettings Interval=\u0026quot;60\u0026quot; Timeout=\u0026quot;120\u0026quot; StoreRates=\u0026quot;false\u0026quot; Hostname=\u0026quot;\u0026quot; /\u0026gt;  3. Save the file. 4. Restart the CollectdWin service (if currently running).\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/diamond-agent-memory-metrics/",
	"title": "Memory Metrics",
	"tags": ["#diamond", "#integrations", "#agents", "#memory"],
	"description": "",
	"content": " Computed    Fully Qualified Name(FQN) Description Units Min Max BASE CORR UTIL     metriclyicly.linux.memory.utilizationpercent Under Linux, memory buffered and cached are part of memory which can beconsidered available. See the following explanation . Computation: 100 – (memory.Buffers + memory.Cached + memory.MemFree) /memory.MemTotal * 100 percent 0 100 yes yes yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-memory-metrics/",
	"title": "Memory Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#memory", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     memory.memory-buffered.value Memory being used by buffers; this memory is available to be freed forapplications to use, should they need it. average bytes 0 none none yes no no   memory.memory-cached.value Memory being used by caches; this memory is available to be freed forapplications to use, should they need it. average bytes 0 none none yes no no   memory.memory-free.value Memory not being used. average bytes 0 none none yes no no   memory.memory-used.value Memory being used by applications. average bytes 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Statistic Units Min Max BASE CORR UTIL     metricly.collectd.memory.total Computation: memory.memory-buffered + memory.memory-cached + memory.memory-free +memory.memory-used average bytes 0 none no no no   metricly.collectd.memory.utilizationpercent Under Linux, memory buffered and cached are part of memory which can beconsidered free. See the following explanation . Computation: 100 – ((memory.memory-buffered + memory.memory-cached +memory.memory-free / Total Memory) * 100) average percent 0 100 yes yes yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/docker/docker-metrics/docker-memory-metrics/",
	"title": "Memory Metrics",
	"tags": ["#docker", "#integrations", "#metrics", "#memory"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Type Units Statistic* BASE CORR Description     memory.failcnt GAUGE count average no no A count of the number of times that the container requested memory and failed to obtain it. This value should always be 0.   memory.limit GAUGE bytes average no no The total amount of memory available to the container.   memory.max_usage GAUGE bytes average no no The maxiumum amount of memory the container has ever used.   memory.stats.active_anon GAUGE bytes average no no    memory.stats.active_file GAUGE bytes average no no    memory.stats.cache GAUGE bytes average no no    memory.stats.hierarchical_memory_lmit GAUGE bytes average no no    memory.stats.hierarchical_memsw_limit GAUGE bytes average no no    memory.stats.inactive_anon GAUGE bytes average no no    memory,stats.inactive_file GAUGE bytes average no no    memory.stats.mapped_file GAUGE bytes average no no    memory.stats.pgpgin COUNTER bytes  yes no    memory.stats.pgpgout COUNTER bytes  yes no    memory.stats.rss GAUGE bytes average yes no    memory.stats.swap GAUGE bytes average no no    memory.stats.total_active_anon GAUGE bytes average yes no    memory.stats.total_active_file GAUGE bytes average no no    memory.stats_total_cache GAUGE bytes average no no    memory.stats.total_inactive_anon GAUGE bytes average no no    memory.stats.total_inactive_file GAUGE bytes average no no    memory.stats.total_mapped_file GAUGE bytes average no no    memory.stats.total_pgpgin COUNTER bytes  yes no    memory.stats.total_pgpgout COUNTER bytes  yes no    memory.stats.total_rss GAUGE bytes average yes no    memory.stats.total_swap GAUGE bytes average no no    memory.stats.total_unevictable GAUGE bytes average no no    memory.stats.unevictable GAUGE bytes average no no    memory.usage GAUGE bytes average yes no The amount of memory currently being used by the container.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/categories/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/metrics/",
	"title": "Metrics",
	"tags": ["#getting started", "#metrics"],
	"description": "",
	"content": " A metric is a quantifiable measurement whose values are monitored by Metricly and used to assess the performance of an element. Metrics are always associated with one or more elements.\nExamples of metrics:\n CPU Utilization Network Bytes per Second Response Time  Collected Metrics Metricly has collected metrics for every element in the application. Policies can be created using collected metrics to determine if data is missing through alerts, and further configured to fire notifications. After 15 minutes of missing data, the element suspends and the alert stops. At this point, an external event is posted to the event timeline noting that Metricly has not received data.\nExample\n   Fully Qualified Name(FQN) Description Units BASE CORR UTIL     netuitive.metrics.collected.percent % of metrics that collected data in the last interval.Computation:((# of collected metrics) / (total # of metrics) * 100) Percent yes no no    Computed Metrics Computed metrics are metrics that Metricly calculates using the data from multiple metrics collected on a integration. Computed metrics are used to compile utilization reports of your environment and to specify metric behavior in default policies. A metric can be identified as a computed metric if its name begins with “netuitive.”\nExample\n   FULLY QUALIFIED NAME (FQN) DESCRIPTION UNITS BASE     netuitive.aws.alb.totaltargethttperrors Total Target HTTP Errors count yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/",
	"title": "Metrics",
	"tags": ["#aws", "#metrics"],
	"description": "",
	"content": " All of the metrics for AWS can be found in this folder.\nMetrics Available \rALB Metrics\r\r\rASG Metrics\r\r\rDynamoDB Metrics\r\r\rEBS Metrics\r\r\rEC2 Metrics\r\r\rECS Metrics\r\r\rEFS Metrics\r\r\rELB Metrics\r\r\rEMR Metrics\r\r\rElasticache Metrics\r\r\rKnesis Metrics\r\r\rLambda Metrics\r\r\rMQ Metrics\r\r\rNLB Metrics\r\r\rRedshift Metrics\r\r\rS3 Metrics\r\r\rSQS Metrics\r\r\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/",
	"title": "Metrics",
	"tags": ["#diamond", "#integrations", "#agents"],
	"description": "",
	"content": " All of the metrics for the Diamond Agent can be found in this folder.\nMetrics Available \rCPU Metrics\r\r\rDisk Usage Metrics\r\r\rDiskspace Metrics\r\r\rLoad Average Metrics\r\r\rMemory Metrics\r\r\rNetwork Metrics\r\r\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-metrics/",
	"title": "Metrics",
	"tags": ["#java", "#integrations", "#metrics", "#agents"],
	"description": "",
	"content": " Instrumenting Metric Values  First, set up the Java Agent. In the zorka/scripts/ directory, create a .bsh file for the application you want to monitor. Call zorka.require to load any extension scripts your application depends on. Define the function(s) you want Zorka to monitor using the template below. The template will establish namespace by creating a function that returns a reference to its own instance and then defines a variable that holds an instance of the function.  __myapp() { //function code //goes here returnthis; } myapp = __myapp();  5. Within the function(s) you created in the previous, complete the following:\n Define the JMX mbean that will host the method call statistics.   _mbean=\u0026quot;zorka:type=ZorkaStats,name=MyAppStats\u0026quot;;   Create a configuration section that zorka can spy on.   spy.add(spy.instrument(MyAppRequests\u0026quot;))  6. Specify which method will be instrumented.\ninclude(spy.byMethod(\u0026quot;com.netuitive.agent.myappclass\u0026quot;, \u0026quot;invoke\u0026quot;)));  7. Navigate to the zorka.properties file, and add the file you created in step 2 to the list of loaded scripts.\n8. Update the zorka.application setting to your application’s name.\n zorka.application = my-app  9. Save all edited files and restart the Java agent. You should find your JVM element in Metricly with general JVM system metrics and MyAppStats method call metrics.\nConfig Options Add an Action on Method Entry  .onEnter(spy.zorkaLog(\u0026quot;INFO\u0026quot;, \u0026quot;MyApp\u0026quot;, \u0026quot;Request occurred.\u0026quot;))  If you have multiple actions, separate them with a comma.\n .onEnter( spy.fetchArg(\u0026quot;operator\u0026quot;, 1), spy.zorkaLog(\u0026quot;INFO\u0026quot;, \u0026quot;MYAPP\u0026quot;, \u0026quot;${operator}\u0026quot;))  Declare Additional Metric Names  spy.zorkaStats(mbsName, beanName, attrName, keyExpr, timeField, actions)   mbsName is name of your mbean server (typically java or jboss). beanName is the name of the mbean used to host statistics in the file. attrName is the name of the attribute where the ZorkaStats object will be visible. keyExpr is the value used as a key in ZorkaStats. timeField indicates the field that stores method execution time (the defaults to T if not passed). actions determines what should be done when aggregating data.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/ruby-agent-metrics/",
	"title": "Metrics",
	"tags": ["#ruby", "#integrations", "#agents", "#metrics"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Statistic Units Min Max Sparse Data Strategy (SDS)     action_controller.halted_callback sum count 0 none zero   action_controller.redirect sum count 0 none zero   action_controller.total_requests sum count 0 none zero   action_controller.*.total_requests sum count 0 none zero   action_controller...request.query_time average milliseconds 0 none zero   action_controller...request.total_duration average milliseconds 0 none zero   action_controller...request.view_time average milliseconds 0 none zero   action_controller...total_requests sum count 0 none zero   action_controller.*.request.queue_time average milliseconds 0 none    action_controller.errors average count 0 none    action_view.render_partial sum count 0 none zero   action_view.render_template sum count 0 none zero   action_record.instantiation sum count 0 none zero   action_record.sql.statement sum count 0 none zero   GC.profiler.total_time        GC.stat.count        GC.stat.heap_allocatable_pages        GC.stat.heap_allocated_pages        GC.stat.heap_available_slots        GC.stat.heap_eden_pages        GC.stat.heap_final_slots        GC.stat.heap_free_slots        GC.stat.heap_live_slots        GC.stat.heap_marked_slots        GC..stat.heap_sorted_length        GC.stat.heap_swept_slots        GC.stat.heap_tomb_pages        GC.stat.major_gc_count        GC.stat.malloc_increase_bytes        GC.stat.malloc_increase_bytes_limit        GC.stat.minor_gc_count        GC.stat.old_objects        GC.stat.old_objects_limit        GC.stat.oldmalloc_increase_bytes        GC.stat.oldmalloc_increase_bytes_limit        GC.stat.remembered_wb_unprotected_objects        GC.stat.remembered_wb_unprotected_objects_limit        GC.stat.total_allocated_objects        GC.stat.total_allocated_pages        GC.stat.total_freed_objects        GC.stat.total_freed_pages        ObjectSpace.count_objects.* average count 0 none zero   sidekiq.*.job.count average count 0 none    sidekiq.default.*.job.count average count 0 none    sidekiq.default.job.count average count 0 none    sidekiq.errors average count 0 none     Computed    Fully Qualified Name (FQN) Description Statistic Units Min Max BASE CORR UTIL     netuitive.ruby.action_controller.*.total_duration The total time spent on requests to a specific controller.Computation:data.sum(‘action_controller.${1}.*.request.total_duration’) average ms 0 none yes yes no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-metrics/",
	"title": "Metrics",
	"tags": ["#windows", "#integrations", "#metrics"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) Description Statistic Units Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     Avg. Disk Queue Length logical_disk.*.avg_queue_length Average queue length for the logical disk. average count 0 none none yes no no   Free Megabytes logical_disk.*.megabytes_free Space free on the logical disk expressed in megabytes. average megabytes 0 none none yes no no   % Free Space logical_disk.*.percent_free Space free on the logical disk expressed as a percentage. average percent 0 100 none yes no no   Available Bytes memory.available_bytes Available memory in bytes. average bytes 0 none none yes no no   Cache Faults/sec memory.cache_faults_per_sec The rate at which faults occur when a page sought in the file system cache is not found and must be retrieved from elsewhere in memory or from disk. average faults/second 0 none none yes no no   Committed Bytes memory.committed_bytes The amount of committed virtual memory in bytes. Committed memory is the physical memory which has space reserved on the disk paging file(s). average bytes 0 none none yes no no   Page Faults/sec memory.page_faults_per_sec Average number of pages faulted per second. average faults/second 0 none none yes yes no   % Usage memory.page_file_percent_used Percentage of the paging file(s) in use. average percent 0 100 none yes no no   Pages Input/sec memory.pages_input_per_sec The rate at which pages are read from disk to resolve hard page faults. average pages/second 0 none none yes no no   Pages Output/sec memory.pages_output_per_sec The rate at which pages are written to disk to free up space in physical memory average pages/second 0 none none yes no no   Pages/sec memory.pages_per_sec The rate at which pages are read from or written to disk to resolve hard page faults. average pages/second 0 none none yes yes no   % Committed Bytes in Use memory.percent_committed_in_use Percentage of committed bytes in use. average percent 0 100 none yes no no   Bytes Received/sec network_interface.*.bytes_received_per_sec Network bytes received per second. average bytes/second 0 none none yes no no   Bytes Sent/sec network_interface.*.bytes_sent_per_sec Network bytes sent per second. average bytes/second 0 none none yes no no   Bytes Total/sec network_interface.*.bytes_total_per_sec Total network bytes sent and received per second. average bytes/second 0 none none yes no no   Current Bandwidth network_interface.*.current_bandwidth Bandwidth the network is currently capable of, expressed in bits per second. average bits/second 0 none none yes no no   Output Queue Length network_interface.*.output_queue_length Length of the output packet queue, in packets. average packets 0 none none yes no no   Packets Outbound Errors network_interface.*.packets_outbound_errors Outbound packet errors. sum errors 0 none none yes no no   Packets Received Errors network_interface.*.packets_received_errors Inbound packet errors. sum errors 0 none none yes no no   Packets Received/Sec network_interface.*.packets_received_per_sec Network packets received per second. average packets/second 0 none none yes no no   Packets Sent/Sec network_interface.*.packets_sent_per_sec Network packets sent per second. average packets/second 0 none none yes no no   Avg. Disk Queue Length physical_disk.*.avg_queue_length Average number of both read and write requests that were queued for the physical disk. average count 0 none none yes yes no   Avg. Disk Read Queue Length physical_disk.*.avg_read_queue_length Average number of read requests that were queued for the physical disk. average count 0 none none yes no no   Avg. Disk sec/Read physical_disk.*.avg_sec_per_read Average disk read time in seconds. average seconds 0 none none yes no no   Avg. Disk sec/Write physical_disk.*.avg_sec_per_write Average disk write time in seconds. average seconds 0 none none yes no no   Avg. Disk Write Queue Length physical_disk.*.avg_write_queue_length Average number of write requests that were queued for the physical disk. average count 0 none none yes no no   % Idle Time physical_disk.*.percent_idle_time Percentage of time the physical disk was idle. average percent 0 100 none yes no no   % Idle time processor.*.percent_idle_time Percentage of time a specific CPU was idle. average percent 0 100 none yes yes no   % Interrupt Time processor.*.percent_interrupt_time Percentage of time a specific CPU was processing interrupts. average percent 0 100 none yes no no   % Privleged Time processor.*.percent_privileged_time Percentage of time a specific CPU was processing system threads. average percent 0 100 none yes no no   % Processor Time processor.*.percent_processor_time Percentage of time a specific CPU was busy. average percent 0 100 none yes no no   % User Time processor.*.percent_user_time Percentage of time a specific CPU was processing user threads. average percent 0 100 none yes no no   Total % Idle Time processor._Total.percent_idle_time The percentage of idle time across all CPUs. average percent 0 100 none yes no no   Total % Interrupt Time processor._Total.percent_intterupt_time The percentage of time spent processing interrupts across all CPUs. average percent 0 100 none yes no no   Total % Privileged Time processor._Total.percent_privileged_time The percentage of time spent on system processes across all CPUs. This includes time spend processing interrupts, so percent_interrupt_time is a component of percent_privileged_time. average percent 0 100 none yes no no   Total % Processor time processor._Total.percent_processor_time This represents the total CPU utilization across all processors. average percent 0 100 none yes yes yes   Total % User Time processor._Total.percent_user_time The percentage of time spent on user processes across all CPUs. average percent 0 100 none yes no no   Context Switches/sec system.context_switches_per_sec The combined rate at which all processors on the computer are switched from one thread to another. average switches/second 0 none none yes yes no   Processes system.processes The number of processes currently running. average count 0 none none yes yes no   Processor Queue Length system.processor_queue_length The number of threads in the processor queue. average count 0 none none yes no no   System calls/sec system.system_calls_per_sec The combined rate of calls to operating system service routines by all processes running on the computer. average calls/second 0 none none yes no no   Get Requests/sec Web_get_requests_per_sec The number of GET requests made per second.      yes no no   Post Requests/sec Web_post_requests_per_sec The number of POST requests made per second.      yes no no   Current Connections Web_current_connections The number of connections currently established with the web service.      yes no no   Connection Attempts/sec Web_connect_attempts_per_sec The number of connection attempts per second.      yes no no   Exceptions Thrown/sec CLR_count_exceptions_thrown The number of exceptions thrown per second. This includes both .NET exceptions and unmanaged exceptions that are converted into .NET exceptions.      yes     % Time in Garbage Collection CLR_percent_time_in_GC The percentage of elapsed time spent performing garbage collection since the last garbage collection cycle.      yes     Application Restarts ASP_application_restarts The number of times an application has been restarted during the server’s lifetime.      yes     Requests Current ASP_requests_current The current number of requests, including those that are queued, currently executing, or waiting to be written to the client. Under the ASP.NET process model, when this counter exceeds requestQueueLimit defined in the processModel configuration section, ASP.NET will begin rejecting requests.      yes     Request Wait Time ASP_request_wait_time The time (in ms) that the most recent request waited in the processing queue.      yes     Requests Queued ASP_requests_queued The number of requests waiting for service from the queue.      yes     Request Execution Time ASP_request_execution_time The time it took (in ms) to execute the most recent request.      yes     Percent Processor Time sql_server.percent_processor_time The percentage of time the processor is busy.           User Connections sql_server.user_connections The number of users currently connected to the SQL Server.           Blocked Processes sql_server.processes_blocked The number of processes that are blocked.           Total Lock Waits Per Second sql_server.total_lock_waits_per_sec The number of locks per second that had to wait for resources.           Batch Requests Per Second sql_server.batch_requests_per_sec The number of batches the server is receiving per second.           SQL Compilations Per Second sql_server.sqL-compilations_per_sec The number of SQL compiles per second.           SQL Recompilations Per Second sql_server.sql_recompilations_per_sec The number of SQL recompiles per second.           Checkpoint Pages Per Second sql_server.checkpoint_pages_per_sec The number of pages written to disk per second by a checkpoint operation.           Buffer Cache hit Ratio sql_server.buffer_cache_hit_ratio The ratio of how many pages are going to memory versus the disk.           Page Life Expectancy sql_server.page_life_expectancy The number of seconds a page is in the buffer pool without references.           Page Splits Per Second sql_server.page_splits_per_sec The number of page splits occurring per second.           Windows Event Count windows_events.event_count The count of Windows events that have occurred. sum  0 none zero yes no no    Computed    Friendly Name Fully Qualified Name (FQN) Description Units Min Max BASE CORR UTIL     Total Interface Packet Errors netuitive.winsrv.network_interface.*.packets_total_errors Total network errors.Computation:network_interface..packets_outbound_errors +network_interface..packets_received_errors errors 0 none yes no no   Total Interface Packets netuitive.winsrv.network_interface.*.packets_total Total network packets.Computation:(network_interface..packets_received_per_sec +network_interface..packets_sent_per_sec) * 300 packets 0 none yes no no   Interface Packet Error Percent netuitive.winsrv.network_interface.*.packets_error_percent Percentage of packets that had errors.Computation:netuitive.winsrv.network_interface..packets_total == 0 ? 0 :(netuitive.winsrv.network_interface..packets_total_errors /netuitive.winsrv.network_interface.*.packets_total) * 100 percent 0 100 yes no no   Max Network Utilization Percent netuitive.winsrv.network_interface.maxutilizationpercent The highest utilization percentage across all network interfaces.Computation:data.max(netuitive.winsrv.network_interface.(.*).utilizationpercent) percent 0 100 yes yes no   Max Network Error Percent netuitive.winsrv.network_interface.maxerrorpercent The highest error percentage across all network interfaces.Computation:data.max(netuitive.winsrv.network_interface(.*).utilizationpercent) percent 0 100 yes no no   Memory Utilization Percent netuitive.winsrv.memory.utilizationpercent Memory utilization percent.Computation:(attribute[ram] == null  attribute[ram] == 0) ? 0 : ((attribute[ram] –memory.available_bytes) / attribute[ram]) * 100 percent 0 100 yes   Interface Utilization Percent netuitive.winsrv.network_interface.*.utilizationpercent Network utilization percent based on bytes per second compared to theavailable bandwidth.Computation:(network_interface..current_bandwith == 0) ? 0 :((network_interface..bytes_total_per_sec * 8) /network_interface.*.current_bandwidth) * 100 percent 0 100 yes no no   Memory Unavailable Bytes netuitive.winsrv.memory.unavailable_bytes Unavailable bytes of memory.Computation:(attribute[ram bytes] == null  attribute[ram bytes == 0) ?((attribute[ram] == null  attribute[ram] == 0) ? 0 : (attribute[ram] –memory.available_bytes)) : (attribute[ram_bytes] –memory.available_bytes) bytes 0   Page File Size netuitive.winsrv.memory.page_file_size Total size of the page file(s).Computation:(memory.committed_bytes / (memory.percent_committed_in_use / 100)) –((attribute[ram bytes] == null  attribute[ram bytes] == 0) ?((attribute[ram] == null  attribute[ram] == 0) ? 0 : attribute[ram]) :attribute[ram_bytes]) bytes 0   Page File Unavailable Bytes netuitive.winsrv.memory.page_file_unavailable_bytes Unavailable bytes in the page file(s).Computation:netuitive.winsrv.memory.page_file_size * (memory.page_file_percent_used/ 100) bytes 0 none yes no no   Page File Available Bytes netuitive.winsrv.memory.page_file_available_bytes Available bytes in the page file(s).Computation:netuitive.winsrv.memory.page_file_size –netuitive.winsrv.memory.page_file_unavailable_bytes bytes 0 none yes no no   Processor Queue Length Normalized netuitive.winsrv.system.processor_queue_length_normalized The average processor queue length across all CPUs.Computation:system.processor_queue_length / attribute[‘cpus’].value count 0 none yes no no   Disk Utilization Percent netuitive.winsrv.logical_disk.*.utilizationpercent Disk utilization percent based on percentage used for each logical disk.Computation:100 – logical_disk.*.percent_free percent 0 100 yes yes no   Physical Disk Total Percent Busy Time netuitive.winsrv.physical_disk._total.percent_busy_time 100 – data [‘physical_disk._Total.percent_idle_time’].actual percent 0 100 yes no yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/cassandra/cassandra-metrics/",
	"title": "Metrics",
	"tags": ["#cassandra", "#integrations", "#metrics"],
	"description": "",
	"content": " Due to the sheer volume of Cassandra metrics, the individual metrics won’t be documented here. Instead, here are some general properties of the groups of metrics:\nAll Metrics Share the Following Properties:  Type: GAUGE Statistic: average Min: 0 Sparse Data Strategy: None BASE: Yes CORR: No UTIL: No  Ending in Latency.OneMinuteRate:  Unit: ms (milliseconds)  Non-latency OneMinuteRate Metrics:  Unit = ops (operations per second)  Contains HeapSize, DataSize, DiskSpace, Memory, or RowSize:  Unit: bytes  Ending with HitRate or Ratio:  Unit: percentunit (i.e. percentage represented as a value between 0 and 1) Max: 1  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/http-code-collector/http-code-collector-metrics/",
	"title": "Metrics",
	"tags": ["#http", "#integrations", "#metrics", "#collectors"],
	"description": "",
	"content": " This collector tracks per URL which response codes are received as well as the number of times each code was received as two separate metrics. The Response Code List metric’s value is the literal response code number at the time it was received. The Response Code count increments each time a response code is received; this means that you won’t have a metric for every response code until your web site serves up that response code.\nCollected    Friendly Name Fully Qualified Name (FQN) Description Statistic Units Min Max BASE CORR UTIL     Response Code List http.*.response_code The response code sent to the user. average  0 none none yes no   Response Code Count http.*.response_code.# For each response code metric (as illustrated by the #), the number oftimes a response code was served. average  0 none none yes no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/http-collector/http-collector-metrics/",
	"title": "Metrics",
	"tags": ["#http", "#integrations", "#metrics", "#collectors"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) Description Statistic     Servers Http Time servers.[hostname].http.[url].time Time to download the page in microseconds. average   Servers Http Size servers.[hostname].http.[url].size Size of the page received in bytes. bytes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/httpd/httpd-metrics/",
	"title": "Metrics",
	"tags": ["#httpd", "#integrations", "#metrics", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Type Units Statistic Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     httpd..BusyWorkers GAUGE count average 0 none none yes no no   httpd..BytesPerReq GAUGE bytes average 0 none none yes no no   httpd..BytesPerSec GAUGE Bps average 0 none none yes no no   httpd..CleanupWorkers GAUGE count average 0 none none yes no no   httpd..ClosingWorkers GAUGE count average 0 none none yes no no   httpd..DnsWorkers GAUGE count average 0 none none yes no no   httpd..FinishingWorkers GAUGE count average 0 none none yes no no   httpd..IdleWorkers GAUGE count average 0 none none yes no no   httpd..KeepaliveWorkers GAUGE count average 0 none none yes no no   httpd..LoggingWorkers GAUGE count average 0 none none yes no no   httpd..ReadingWorkers GAUGE count average 0 none none yes no no   httpd..ReqPerSec GAUGE ops average 0 none none yes no no   httpd..TotalAccesses COUNTER count  0 none none yes no no   httpd..WritingWorkers GAUGE count average 0 none none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/rabbitmq/rabbitmq-metrics/",
	"title": "Metrics",
	"tags": ["#rabbitmq", "#integrations", "#metrics"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Type Units Statistic Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     rabbitmq.cluster.nodes GAUGE count average 0 none none no no no   rabbitmq.cluster.partitions GAUGE count average 0 none none no no no   rabbitmq.health.disk_free GAUGE bytes average 0 none none yes no no   rabbitmq.health.disk_free_limit GAUGE bytes average 0 none none no no no   rabbitmq.health.fd_total GAUGE count average 0 none none no no no   rabbitmq.health.fd_used GAUGE count average 0 none none yes no no   rabbitmq.health.mem_limit GAUGE bytes average 0 none none no no no   rabbitmq.health.mem_used GAUGE bytes average 0 none none yes no no   rabbitmq.health.proc_total GAUGE count average 0 none none no no no   rabbitmq.health.proc_used GAUGE count average 0 none none yes no no   rabbitmq.health.sockets_total GAUGE count average 0 none none no no no   rabbitmq.health.sockets_used GAUGE count average 0 none none yes no no   rabbitmq.message_stats.ack COUNTER count  0 none none yes no no   rabbitmq.message_stats.ack_details.rate GAUGE ops average none none none yes no no   rabbitmq.message_stats.deliver COUNTER count  0 none none yes no no   rabbitmq.message_stats.deliver_details.rate GAUGE ops average none none none yes no no   rabbitmq.message_stats.deliver_get COUNTER count  0 none none yes no no   rabbitmq.message_stats.deliver_get_details.rate GAUGE ops average none none none yes no no   rabbitmq.message_stats.publish COUNTER count  0 none none yes no no   rabbitmq.message_stats.publish_details.rate GAUGE ops average none none none yes no no   rabbitmq.message_stats.redeliver COUNTER count  0 none none no no no   rabbitmq.message_stats.redeliver_details.rate GAUGE ops average none none none no no no   rabbitmq.object_totals.channels GAUGE count average 0 none none no no no   rabbitmq.object_totals.connections GAUGE count average 0 none none no no no   rabbitmq.object_totals.consumers GAUGE count average 0 none none no no no   rabbitmq.object_totals.exchanges GAUGE count average 0 none none no no no   rabbitmq.object_totals.queues GAUGE count average 0 none none no no no   rabbitmq.queue_totals.messages GAUGE count average 0 none none yes no no   rabbitmq.queue_totals.messages_details.rate GAUGE ops average none none none yes no no   rabbitmq.queue_totals.messages_ready GAUGE count average 0 none none no no no   rabbitmq.queue_totals.messages_ready_details.rate GAUGE ops average none none none no no no   rabbitmq.queue_totals.messages_unacknowledged GAUGE count average 0 none none yes no no   rabbitmq.queue_totals.messages_unacknowledged_details.rate GAUGE ops average none none none yes no no   rabbitmq.health.running GAUGE none minimum none none none no no no    Computed    Fully Qualified Name (FQN) Description Units Min Max BASE CORR UTIL     metricly.linux.rabbitmq.health.fd_utilization_percent The percentage of available file descriptors in use.Computation:rabbitmq.health.fd_used / rabbitmq.health.fd_total * 100 percent 0 100 yes no yes   metricly.linux.rabbitmq.health.mem_utilization_percent The percentage of memory in use as a function of the defined memorylimit.Computation:100 – (rabbitmq.health.mem_used / rabbitmq.health.mem_limit * 100) percent 0 100 yes no yes   metricly.linux.rabbitmq.health.proc_utilization_percent The percentage of the allowed number of processes which are being run.Computation:rabbitmq.health.proc_used / rabbitmq.health.proc_total * 100 percent 0 100 yes no yes   metricly.linux.rabbitmq.health.socket_utilization_percent The percentage of the available sockets in use.Computation:rabbitmq.health.sockets_used / rabbitmq.health.sockets_total * 100 percent 0 100 yes no yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/redis/redis-metrics/",
	"title": "Metrics",
	"tags": ["#redis", "#integrations", "#metrics"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Friendly Name     clients.blocked Blocked Clients   clients.connected Connected Clients   clients.longest_output_list Client Longest Output List   cpu.parent.sys Used System CPU   cpu.children.sys Used System CPU (Children)   cpu.parent.user Used CPU User   cpu.children.user Used CPU User (Children)   hash_max_zipmap.entries Maximum Hash Zipmap Entries   hash_max_zipmap.value Maximum Hash Zipmap Value   keys.evicted Evicted Keys   keys.expired Expired Keys   keyspace.hits Keyspace Hits   keyspace.misses Keyspace Misses   last_save.changes_since Changes Since Last Save   last_save.time Last Save Time   memory.internal_view Memory Used   memory.external_view Memory Used (Resident Set Size)   memory.fragmentation_ratio Memory Fragmentation Ratio   process.commands_processed Total Commands Processed   process.connections_received Total Connections Received   process.uptime Process Uptime (in Seconds)   pubsub.channels Publish/Subscribe Channels   pubsub.patterns Publish/Subscribe Patterns   slaves.connected Connected Slaves   slaves.last_io Master Last Input/Output (Seconds Ago)    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/consul/consul-metrics/",
	"title": "Metrics",
	"tags": ["#consul", "#integrations"],
	"description": "",
	"content": "   Fully Qualified Name (FQN) Statistic Units BASE CORR Type Computed     consul.raft.commitTime.avg max  TRUE TRUE counter yes   consul.raft.commitTime.max max  TRUE TRUE counter yes   consul.proxy.web.inbound.rx_bytes avg bytes TRUE FALSE gauge no   consul.health.service.not-found.[service] avg queries TRUE FALSE gauge no   consul.health.service.query-tags.[service].[tags] avg queries TRUE FALSE gauge no   consul.health.service.query-tag.[service].[tag] avg queries TRUE FALSE gauge no   consul.health.service.query.[service] avg queries TRUE FALSE gauge no   consul.catalog.service.not-found.[service] avg queries TRUE FALSE gauge no   consul.catalog.service.query-tags.[service].[tags] avg queries TRUE FALSE gauge no   consul.catalog.service.query-tag.[service].[tag] avg queries TRUE FALSE gauge no   consul.catalog.service.query.[service] avg queries TRUE FALSE gauge no   consul.memberlist.pushPullNode avg nodes / Interval TRUE FALSE gauge no   consul.memberlist.probeNode avg nodes / Interval TRUE FALSE gauge no   consul.memberlist.msg_suspect avg nodes / Interval TRUE FALSE gauge no   consul.memberlist.msg_dead avg nodes / Interval TRUE FALSE gauge no   consul.memberlist.msg_alive avg nodes / Interval TRUE FALSE gauge no   consul.memberlist.gossip avg messages / Interval TRUE FALSE gauge no   consul.memberlist.tcp.sent avg bytes sent / interval TRUE FALSE gauge no   consul.memberlist.tcp.connect avg push/pull initiated / interval TRUE FALSE gauge no   consul.memberlist.udp.sent/received avg bytes sent or bytes received / interval TRUE FALSE gauge no   consul.memberlist.tcp.accept avg connections accepted / interval TRUE FALSE gauge no   onsul.memberlist.msg.suspect avg suspect messages received / interval TRUE FALSE gauge no   consul.memberlist.msg.dead avg messages / interval TRUE FALSE gauge no   consul.memberlist.degraded.timeout avg occurrence / interval TRUE FALSE gauge no   consul.memberlist.degraded.probe avg probes / interval TRUE FALSE gauge no   consul.rpc.cross-dc avg queries TRUE FALSE gauge no   consul.rpc.query avg queries TRUE FALSE gauge no   consul.rpc.request avg requests TRUE FALSE gauge no   consul.rpc.request_error avg errors TRUE FALSE gauge no   consul.rpc.accept_conn avg connections TRUE FALSE gauge no   consul.dns.stale_queries avg queries TRUE FALSE gauge no   consul.acl.replication_hit avg hits TRUE FALSE gauge no   consul.acl.cache_miss avg misses TRUE FALSE gauge no   consul.acl.cache_hit avg hits TRUE FALSE gauge no   consul.client.rpc.error.catalog_node_services.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_node_services.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_node_services.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.error.catalog_service_nodes.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_service_nodes.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_service_nodes.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.error.catalog_services.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_services.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_services.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.error.catalog_nodes.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_nodes.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_nodes.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.error.catalog_datacenters.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_datacenters.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_datacenters.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.error.catalog_deregister.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_deregister.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_deregister.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.error.catalog_register.[node] avg errors TRUE FALSE gauge no   consul.client.api.success.catalog_register.[node] avg requests TRUE FALSE gauge no   consul.client.api.catalog_register.[node] avg requests TRUE FALSE gauge no   consul.client.rpc.failed avg requests TRUE FALSE gauge no   consul.client.rpc.exceeded avg rejected requests TRUE FALSE gauge no   consul.client.rpc avg requests TRUE FALSE gauge no   consul.acl.blocked.(check node service).registration avg requests TRUE FALSE   consul.acl.blocked.service.registration avg requests TRUE FALSE gauge no   consul.serf.events max events / interval TRUE TRUE counter no   consul.serf.member.flap max flaps / interval TRUE TRUE counter no   consul.serf.snapshot.compact max ms TRUE TRUE timer no   consul.serf.snapshot.appendLine max ms TRUE TRUE timer no   consul.rpc.raft_handoff avg connections TRUE FALSE gauge no   consul.raft.leader.lastContact max ms TRUE TRUE timer no   consul.raft.replication.appendEntries.logs max logs appended/ interval TRUE TRUE counter no   consul.raft.replication.appendEntries.rpc max ms TRUE TRUE timer no   consul.raft.rpc.installSnapshot max ms TRUE TRUE timer no   consul.raft.rpc.requestVote max ms TRUE TRUE timer no   consul.raft.rpc.appendEntries.processLogs max ms TRUE TRUE timer no   consul.raft.rpc.appendEntries.storeLogs max ms TRUE TRUE timer no   consul.raft.rpc.appendEntries max ms TRUE TRUE timer no   consul.raft.rpc.processHeartBeat max ms TRUE TRUE timer no   consul.raft.restoreUserSnapshot max ms TRUE TRUE timer no   consul.raft.transistion.heartbeat_timeout max timeouts / interval TRUE TRUE counter no   consul.raft.state.follower max follower state entered / interval TRUE TRUE counter no   consul.raft.replication.appendEntries max ms TRUE TRUE timer no   consul.raft.leader.dispatchLog max ms TRUE TRUE timer no   consul.raft.commitTime max ms TRUE TRUE timer no   consul.raft.restore max operation invoked / interval TRUE TRUE counter no   consul.raft.verify_leader max checks / interval TRUE TRUE counter no   consul.raft.barrier max blocks / interval TRUE TRUE counter no   consul.raft.apply max Raft Transactions / Interval TRUE TRUE counter no   consul.raft.state.candidate max Election Attempts / Interval TRUE TRUE counter no   consul.raft.state.leader max Leadership Transitions / Interval TRUE TRUE counter no   consul.raft.replication.heartbeat max MS TRUE TRUE Timer no   consul.raft.snapshot.takeSnapshot max MS TRUE TRUE Timer no   consul.raft.snapshot.persist max MS TRUE TRUE Timer no   consul.raft.snapshot.create max MS TRUE TRUE Timer no   consul.raft.fsm.restore max MS TRUE TRUE Timer no   consul.raft.fsm.apply max Commit Logs / Interval TRUE TRUE counter no   consul.raft.fsm.snapshot max MS TRUE TRUE Timer no   consul.runtime.heap_objects max number of objects TRUE TRUE gauge no   consul.runtime.alloc_bytes max bytes TRUE TRUE gauge no   consul.runtime.num_goroutines max number of goroutines TRUE TRUE gauge no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/docker/docker-metrics/",
	"title": "Metrics",
	"tags": ["#docker", "#integrations", "#metrics"],
	"description": "",
	"content": " This folder contains all metrics for the Docker integration.\nMetrics Available \rCPU Metrics\r\r\rComputed Metrics\r\r\rMemory Metrics\r\r\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/kubernetes/kubernetes-metrics/",
	"title": "Metrics",
	"tags": ["#metrics", "#integrations", "#kubernetes"],
	"description": "",
	"content": "   Metric FQN Kubernetes Types Baseline Correlated Statistic     cpu.limit Cluster, Node, Namespace, Pod, Pod Container, Sys Container No No Average   cpu.node.allocatable Node No No Average   cpu.node.utilization Node Yes Yes Average   cpu.node_capacity Node No No Average   cpu.node_reservation Node No No Average   cpu.request Cluster, Node, Namespace, Pod, Pod Container, Sys Container No No Average   cpu.usage Cluster, Node, Namespace, Pod, Pod Container, Sys Container No No Average   cpu.usage_rate Cluster, Node, Namespace, Pod, Pod Container, Sys Container Yes No Average   disk.io.write_bytes:11:0 Node Yes No Average   disk.io_read_bytes:/dev/dm-0 Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   disk.io_read_bytes:/dev/dm-1 Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   disk.io_read_bytes:/dev/sda Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   disk.io_read_bytes:11:0 Cluster, Node, Sys Container Yes No Average   disk.io_read_bytes_rate:/dev/dm-0 Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   disk.io_read_bytes_rate:/dev/dm-1 Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   disk.io_read_bytes_rate:/dev/sda Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   disk.io_read_bytes_rate:11:0 Cluster, Node, Namespace, Sys Container No No Average   disk.io_write_bytes:/dev/dm-0 Cluster, Node, Namespace, Sys Container No No Average   disk.io_write_bytes:/dev/dm-1 Cluster, Namespace, Pod, Sys Container No No Average   disk.io_write_bytes:/dev/sda Cluster, Namespace, Pod, Sys Container No No Average   disk.io_write_bytes:11:0 Cluster, Namespace, Sys Container Yes No Average   disk.io_write_bytes_rate:/dev/dm-0 Cluster, Namespace, Sys Container No No Average   disk.io_write_bytes_rate:/dev/dm-1 Cluster, Namespace, Pod, Sys Container No No Average   disk.io_write_bytes_rate:/dev/sda Cluster, Namespace, Pod, Sys Container No No Average   disk.io_write_bytes_rate:11:- Node No No Average   disk.io_write_bytes_rate:11:0 Cluster, Namespace, Sys Container Yes No Average   filesystem.available:/dev/mapper/centos-root Node, Pod No No Average   filesystem.available:/dev/mapper/centos-var_lib_docker Node, Pod, Pod Container No No Average   filesystem.available:/dev/sda1 Node No No Average   filesystem.available:tmpfs Node No No Average   filesystem.inodes:/dev/mapper/centos-root Node No No Average   filesystem.inodes:/dev/mapper/centos-var_lib_docker Node No No Average   filesystem.inodes:/dev/sda1 Node No No Average   filesystem.inodes:tmpfs Node No No Average   filesystem.inodes_free:/dev/mapper/centos-root Node No No Average   filesystem.inodes_free:/dev/mapper/centos-var_lib_docker Node No No Average   filesystem.inodes_free:/dev/sda1 Node No No Average   filesystem.inodes_free:tmpfs Node No No Average   filesystem.limit:/dev/mapper/centos-root Node No No Average   filesystem.limit:/dev/mapper/centos-var_lib_docker Node, Pod, Pod Container No No Average   filesystem.limit:/dev/sda1 Node No No Average   filesystem.limit:tmpfs Node No No Average   filesystem.usage:/dev/mapper/centos-root Node, Pod No No Average   filesystem.usage:/dev/mapper/centos-var_lib_docker Node, Pod, Pod Container No No Average   filesystem.usage:/dev/sda1 Node No No Average   filesystem.usage:tmpfs Node No No Average   k8s.cluster.cpu.useage.percent Cluster      k8s.namespace.cpu.usage.percent Namespace, Pod, Pod Container, Sys Container      k8s.namespace.memory.usage.percent Namespace, Pod, Pod Container, Sys Container Yes Yes Percent (Expression Result)   memory.cache Namespace, Pod, Pod Container, Sys Container No No Average   memory.limit Cluster, Namespace, Pod, Pod Container No No Average   memory.major_page_faults Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   memory.major_page_faults_rate Cluster, Namespace, Pod, Pod Container, Sys Container Yes No Average   memory.node_allocatable Cluster, Namespace No No Average   memory.node_capacity Cluster, Namespace No No Average   memory.node_reservation Cluster, Namespace No No Average   memory.node_utilization Cluster, Namespace Yes Yes Average   memory.page_faults Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   memory.page_faults_rate Cluster, Namespace, Pod, Pod Container, Sys Container Yes No Average   memory.request Cluster, Namespace, Pod, Pod Container, Sys Container Yes Yes Average   memory.rss Cluster, Namespace, Pod, Pod Container, Sys Container No No Average   memory.usage Cluster, Namespace, Pod, Pod Container, Sys Container Yes Yes Average   memory.working_set Cluster, Namespace, Pod, Pod Container, Sys Container Yes No Average   network.rx Node, Pod, Pod Container No No Average   network.rx_errors Node, Pod, Pod Container No No Average   network.rx_errors_rate Node, Pod, Pod Container Yes No Average   network.rx_rate Node, Pod, Pod Container Yes Yes Average   network.tx Node, Pod, Pod Container No No Average   network.tx_errors Node, Pod, Pod Container No No Average   network.tx_errors_rate Node, Pod, Pod Container Yes No Average   network.tx_rate Node, Pod, Pod Container Yes Yes Average   restart_count Node, Pod, Pod Container      uptime Cluster, Node, Namespace, Pod, Pod Container, Sys Container No No Average    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-iis/microsoft-iis-metrics/",
	"title": "Metrics",
	"tags": ["#metrics", "#integrations", "#microsoft iis"],
	"description": "",
	"content": "   Friendly Name FQN Description     Get Requests/sec Web_get_requests_per_sec The number of GET requests made per second.   Post Requests/sec Web_post_requests_per_sec The number of POST requests made per second.   Current Connections Web_current_connections The number of connections currently established with the web service.   Connection Attempts/sec Web_connect_attempts_per_sec The number of connection attempts per second.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-net/microsoft-net-metrics/",
	"title": "Metrics",
	"tags": ["#metrics", "#integrations", "#microsoft net"],
	"description": "",
	"content": "   Friendly Name FQN Description     Exceptions Thrown/sec CLR_count_exceptions_thrown The number of exceptions thrown per second. This includes both .NET exceptions and unmanaged exceptions that are converted into .NET exceptions.   % Time in Garbage Collection CLR_percent_time_in_GC The percentage of elapsed time spent performing garbage collection since the last garbage collection cycle.   Application Restarts ASP_application_restarts The number of times an application has been restarted during the server’s lifetime.   Requests Current ASP_requests_current The current number of requests, including those that are queued, currently executing, or waiting to be written to the client. Under the ASP.NET process model, when this counter exceeds requestQueueLimit defined in the processModel configuration section, ASP.NET will begin rejecting requests.   Request Wait Time ASP_request_wait_time The time (in ms) that the most recent request waited in the processing queue.   Requests Queued ASP_requests_queued The number of requests waiting for service from the queue.   Request Execution Time ASP_request_execution_time The time it took (in ms) to execute the most recent request.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-sql/microsoft-sql-metrics/",
	"title": "Metrics",
	"tags": ["#metrics", "#integrations", "#microsoft sql"],
	"description": "",
	"content": " Collected    Category Instance Fully Qualified Name (FQN) Description     Process sqlserver sql_server.percent_processor_time The percentage of time the processor is busy.   General Statistics N/A sql_server.user_connections The number of users currently connected to the SQL Server.   General Statistics N/A sql_server.processes_blocked The number of processes that are blocked.   Locks _Total sql_server.total_lock_waits_per_sec The number of locks per second that had to wait for resources.   SQL Statistics N/A sql_server.batch_requests_per_sec The number of batches the server is receiving per second.   SQL Statistics N/A sql_server.sqL-compilations_per_sec The number of SQL compiles per second.   SQL Statistics N/A sql_server.sql_recompilations_per_sec The number of SQL recompiles per second.   Buffer Manager N/A sql_server.checkpoint_pages_per_sec The number of pages written to disk per second by a checkpoint operation.   Buffer Manager N/A sql_server.buffer_cache_hit_ratio The ratio of how many pages are going to memory versus the disk.   Buffer Manager N/A sql_server.page_life_expectancy The number of seconds a page is in the buffer pool without references.   Access Methods N/A sql_server.page_splits_per_sec The number of page splits occurring per second.    Computed    Fully Qualified Name (FQN) Description Units Min Max BASE CORR UTIL     metricly.linux.mongo.connections.utilizationpercent The percentage of available connections currently being utilized. Computation: (mongo.connections.current / (mongo.connections.current +mongo.connections.available)) * 100 percent 0 100 yes no yes   metricly.linux.mongo.opcounters.totalreads The total number of read operations currently taking place (reads include both query and getmore requests). Computation: mongo.opcounters.query + mongo.opcounters.germore count 0 none yes no no   metricly.linux.mongo.opcounters.totalwrites The total number of write operations currently taking place (writes include insert, update, and delete requests). Computation: mongo.opcounters.insert + mongo.opcounters.update + mongo.opcounters.delete count 0 none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/mongodb/mongodb-metrics/",
	"title": "Metrics",
	"tags": ["#metrics", "#integrations", "#mongodb"],
	"description": "",
	"content": "   Category Instance Fully Qualified Name (FQN) Description     Process sqlserver sql_server.percent_processor_time The percentage of time the processor is busy.   General Statistics N/A sql_server.user_connections The number of users currently connected to the SQL Server.   General Statistics N/A sql_server.processes_blocked The number of processes that are blocked.   Locks _Total sql_server.total_lock_waits_per_sec The number of locks per second that had to wait for resources.   SQL Statistics N/A sql_server.batch_requests_per_sec The number of batches the server is receiving per second.   SQL Statistics N/A sql_server.sqL-compilations_per_sec The number of SQL compiles per second.   SQL Statistics N/A sql_server.sql_recompilations_per_sec The number of SQL recompiles per second.   Buffer Manager N/A sql_server.checkpoint_pages_per_sec The number of pages written to disk per second by a checkpoint operation.   Buffer Manager N/A sql_server.buffer_cache_hit_ratio The ratio of how many pages are going to memory versus the disk.   Buffer Manager N/A sql_server.page_life_expectancy The number of seconds a page is in the buffer pool without references.   Access Methods N/A sql_server.page_splits_per_sec The number of page splits occurring per second.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/mysql/mysql-metrics/",
	"title": "Metrics",
	"tags": ["#metrics", "#integrations", "#mysql"],
	"description": "",
	"content": " Collected    Description Type Units Statistic* Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     The total number of bytes received by the server over the interval. counter bytes  0 none none yes yes no   The total number of bytes sent by the server over the interval. counter bytes  0 none none yes yes no   The total number of connection attempts made to the server over theprevious interval. counter count  0 none none yes no no   The total number of times that the query handler read various sectionsof the indices. These metrics are important for computing the percentageof full table scans. counter count  0 none none no no no   The maximum number of connections that have ever been open concurrentlysince the server was started. This will be a relatively static number. gauge count max 0 none none no no no   The raw data received every minute represents the number of currentlyopen files at that minute. The 5-minute data is the average number offiles in an open state during the previous 5 minutes. gauge count average 0 none none no no no   The raw data received every minute represents the number of currentlyopen tables at that minute. The 5-minute data is the average number oftables in an open state during the previous 5 minutes. gauge count average 0 none none no no no   The total number of files that were opened during the previous interval.Note that some (or all) of them may have been closed during the intervalas well. counter count  0 none none yes yes no   The total number of tables that were opened during the previousinterval. Note that some (or all) of them may have been closed duringthe interval as well. counter count  0 none none yes yes no   The raw data received every minute represents the current number ofprepared statements at that minute. The 5-minute data is the averagenumber of prepared statements during the previous 5 minutes. counter count  0 none none no no no   The total number of queries made to the server over the previousinterval. counter count  0 none none yes yes no   The total number of threads that were slow to launch during the previousinterval. counter count  0 none none no no no   The total number of queries that were slow to execute during theprevious interval. counter count  0 none none no no no   The total number of requested table locks that the server was able togrant immediately during the previous interval. gauge count sum 0 none none yes yes no   The total number of requested table locks that the server had to waitbefore granting during the previous interval. gauge count sum 0 none none yes yes no   The raw data received every minute represents the current number ofthreads in the thread cache at that minute. The 5-minute data is theaverage number of threads in the cache during the previous 5 minutes. counter count  0 none none yes yes no   The raw data received every minute represents the current number ofconnections at that minute. The 5-minute data is the average number ofconnections during the previous 5 minutes. counter count  0 none none yes yes no   The raw data received is a counter, representing the total number ofthreads that have been created since the server was last started. The5-minute data computes the deltas in these values to give the totalnumber of threads created over the past 5 minutes. counter count  0 none none yes yes no   The raw data received every minute represents the current number ofthreads which are running at that minute. The 5-minute data is theaverage number of threads running during the previous 5 minutes. gauge count average 0 none none yes yes no    Computed    Name Fully Qualified Name (FQN) Description Units Min Max BASE CORR UTIL     Percentage of Full Table Scans metricly.linux.mysql.fulltablescans.percentage A full table scan occurs when a query is unable to use an index toassist with its execution, and therefore is required to parse the entiretable to find all the rows that satisfy the query. This metric reportsthe percentage of queries that needed to perform full table scans.Computation:100 * ((data[‘mysql.Handler_read_rnd_next’].actual +data[‘mysql.Handler_read_rnd’].actual) /(data[‘mysql.Handler_read_rnd_next’].actual +data[‘mysql.Handler_read_rnd’].actual +data[‘mysql.Handler_read_first’].actual +data[‘mysql.Handler_read_next’].actual +data[‘mysql.Handler_read_key’].actual +data[‘mysql.Handler_read_prev’].actual)) percent 0 100 yes yes no   Percentage of Slow Queries metricly.linux.mysql.slowqueries.percentage Percentage of queries that are running slow.Computation:(data[‘mysql.Queries’].actual == null  data[‘mysql.Queries’].actual ==0) ? 0 : 100 * (data[‘mysql.Slow_queries’].actual /data[‘mysql.Queries’].actual) percent 0 100 no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/ngnix/ngnix-metrics/",
	"title": "Metrics",
	"tags": ["#ngnix", "#integrations", "#metrics"],
	"description": "",
	"content": " Collected    Fully Qualified Name (FQN) Description Statistic Units Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     nginx.act_reads The average number of active connections that were reading during theprior interval. average count 0 none none yes yes no   nginx.act_waits The average number of active connections that were waiting during theprior interval. average count 0 none none yes yes no   nginx.act_writes The average number of active connections that were writing during theprior interval. average count 0 none none yes yes no   nginx.active_connections The average number of active connections during the prior interval. average count 0 none none yes yes no   nginx.conn_accepted The total number of connections accepted during the prior interval. sum count 0 none none yes yes no   nginx.conn_handled The total number of connections handled during the prior interval. sum count 0 none none yes yes no   nginx.req_handled The total number of requests handled during the prior interval. sum count 0 none none yes yes no    Computed    Fully Qualified Name (FQN) Description Units Min Max BASE CORR UTIL     metricly.nginx.requests_per_connection The average number of requests handled by each connection during theprior interval.Computation:data[‘nginx.conn_handled’].actual == 0 ? 0: data[‘nginx.req_handled’].actual / data[‘nginx.conn_handled’].actual count 0 none yes no no   metricly.nginx.requests_per_second The average number of requests per second.Computation:data[‘nginx.req_handled’].actual / 300 ops 0 none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-azure/",
	"title": "Microsoft Azure",
	"tags": ["#microsoft", "#azure", "#integrations"],
	"description": "",
	"content": " Microsoft Azure is a cloud computing platform, similar to Amazon Web Services. With Azure integration in Metricly, you can monitor the performance of your entire cloud infrastructure. Metricly requires Reader role permissions of your Azure environment, which can be granted using the Owner or User Access Administrator roles.\nRelated Topics \rAzure Installation\r\r\rAzure Metrics\r\r\rEnable Guest OS Diagnostic Metrics\r\r\rFilter Elements\r\r\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-iis/",
	"title": "Microsoft IIS",
	"tags": ["#microsoft iis", "#integrations"],
	"description": "",
	"content": " Metricly can monitor the performance of your IIS server(s) using our Windows Agent. Our Windows agent is a Microsoft Windows service that collects, aggregates, and publishes windows performance counters and attributes.\nPrerequisites The Windows Agent is required. If you need to disable the Windows integration or view the unique API key assigned to your account, navigate to the Integrations page under the user account drop-down menu and click the integration designated as Windows under the Integration column.\nConfigure 1. Add Custom Metrics  Open the Add Counters window Open perfmon (Performance Monitor) on your computer. Click Performance Monitor in the Monitoring Tools folder. A graph generates. Click Add above the graph. An Add Counters window opens. Leave the window open.  2. Prepare a New Counter  Navigate to the ReadWindowsPerfCounters file (typically located in C:\\Program Files\\CollectdWin\\config) and open it. Optionally, at the top of the file but below the \u0026lt;Counters\u0026gt; tag, place a comment to section off your new custom category of counters.  \u0026lt;!-- CustomCategoryName --\u0026gt;  3. Add a blank Counter tag template:\n\u0026lt;Counter Category=\u0026quot;\u0026quot; Name=\u0026quot;\u0026quot; Instance=\u0026quot;\u0026quot; CollectdPlugin=\u0026quot;\u0026quot; CollectdType=\u0026quot;\u0026quot; CollectdTypeInstance=\u0026quot;\u0026quot; /\u0026gt;  3. Fill in Counter information  Follow the diagram below to fill out the Category, Name, and Instance fields (case sensitive) in the blank counter template you added in step 2.3. The picture outlines the expanded Processor counter category.   Not all categories have instances available. In the above example, the instances correlate to the processor’s cores, where _Total would calculate the metric selected for all four cores.\n\r2. Navigate to the types.db file (typically located in C:\\Program Files\\CollectdWin) and open it.\n3. Use your best judgment to match a type in types.db to the category you selected in step 3.1. Input the type (case sensitive) you wish to use into the CollectdType field.\n4. Create a metric category for the CollectdPlugin field. This category displays in the Metrics tree and search field. 5. Create a metric name using the CollectdTypeInstance field. This field is used as the metric’s name in Metricly, but be sure to make it entirely unique.\n6. Save theReadWindowsPerfCounters file.\nExample Counters A Web Service Tracking Total Instances of Current Connections:\n\u0026lt;Counter Category=\u0026quot;Web Service\u0026quot; Name=\u0026quot;Current Connections\u0026quot; Instance=\u0026quot;_Total\u0026quot; CollectdPlugin=\u0026quot;custom_iis\u0026quot; CollectdType=\u0026quot;current_connections\u0026quot; CollectdTypeInstance=\u0026quot;curr_connections\u0026quot; /\u0026gt;  Three Process Counters Checking Status of different aspects of the Windows agent service:\n\u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;% Processor Time\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;percent\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.percent_processor_time\u0026quot; /\u0026gt;  \u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;Thread Count\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;count\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.thread_count\u0026quot; /\u0026gt;  \u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;Private Bytes\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;bytes\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.private_bytes\u0026quot; /\u0026gt;  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-net/",
	"title": "Microsoft NET",
	"tags": ["#microsoft net", "#integrations"],
	"description": "",
	"content": " Microsoft .NET Framework metrics come packaged with the Metricly Windows Agent. Our Windows agent is a Microsoft Windows service that collects, aggregates, and publishes windows performance counters and attributes.\nConfigure There’s no additional configuration necessary for the Microsoft .NET Framework if you’ve already installed the Windows agent unless you want to add additional custom metrics to supplement the default collected metrics.\n1. Add Custom Metrics  Open the Add Counters window Open perfmon (Performance Monitor) on your computer. Click Performance Monitor in the Monitoring Tools folder. A graph generates. Click Add above the graph. An Add Counters window opens. Leave the window open.  2. Prepare a New Counter  Navigate to the ReadWindowsPerfCounters file (typically located in C:\\Program Files\\CollectdWin\\config) and open it. Optionally, at the top of the file but below the \u0026lt;Counters\u0026gt; tag, place a comment to section off your new custom category of counters.  \u0026lt;!-- CustomCategoryName --\u0026gt;  3. Add a blank Counter tag template:\n\u0026lt;Counter Category=\u0026quot;\u0026quot; Name=\u0026quot;\u0026quot; Instance=\u0026quot;\u0026quot; CollectdPlugin=\u0026quot;\u0026quot; CollectdType=\u0026quot;\u0026quot; CollectdTypeInstance=\u0026quot;\u0026quot; /\u0026gt;  3. Fill in Counter information  Follow the diagram below to fill out the Category, Name, and Instance fields (case sensitive) in the blank counter template you added in step 2.3. The picture outlines the expanded Processor counter category.   Not all categories have instances available. In the above example, the instances correlate to the processor’s cores, where _Total would calculate the metric selected for all four cores.\n\r2. Navigate to the types.db file (typically located in C:\\Program Files\\CollectdWin) and open it.\n3. Use your best judgment to match a type in types.db to the category you selected in step 3.1. Input the type (case sensitive) you wish to use into the CollectdType field.\n4. Create a metric category for the CollectdPlugin field. This category displays in the Metrics tree and search field. 5. Create a metric name using the CollectdTypeInstance field. This field is used as the metric’s name in Metricly, but be sure to make it entirely unique.\n6. Save theReadWindowsPerfCounters file.\nExample Counters A Web Service Tracking Total Instances of Current Connections:\n\u0026lt;Counter Category=\u0026quot;Web Service\u0026quot; Name=\u0026quot;Current Connections\u0026quot; Instance=\u0026quot;_Total\u0026quot; CollectdPlugin=\u0026quot;custom_iis\u0026quot; CollectdType=\u0026quot;current_connections\u0026quot; CollectdTypeInstance=\u0026quot;curr_connections\u0026quot; /\u0026gt;  Three Process Counters Checking Status of different aspects of the Windows agent service:\n\u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;% Processor Time\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;percent\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.percent_processor_time\u0026quot; /\u0026gt;  \u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;Thread Count\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;count\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.thread_count\u0026quot; /\u0026gt;  \u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;Private Bytes\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;bytes\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.private_bytes\u0026quot; /\u0026gt;  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/microsoft-sql/",
	"title": "Microsoft SQL",
	"tags": ["#microsoft sql", "#integrations"],
	"description": "",
	"content": " Microsoft SQL Server metrics come packaged with the Metricly Windows agent. Our Windows agent is a Microsoft Windows service that collects, aggregates, and publishes windows performance counters and attributes. For more information on the Agent itself as well as any plugins available, see the Windows Agent page.\nConfiguration There’s no additional configuration necessary for the Microsoft SQL Server if you’ve already installed the Windows agent unless you want to add additional custom metrics to supplement the default collected metrics.\n1. Add Custom Metrics  Open the Add Counters window Open perfmon (Performance Monitor) on your computer. Click Performance Monitor in the Monitoring Tools folder. A graph generates. Click Add above the graph. An Add Counters window opens. Leave the window open.  2. Prepare a New Counter  Navigate to the ReadWindowsPerfCounters file (typically located in C:\\Program Files\\CollectdWin\\config) and open it. Optionally, at the top of the file but below the \u0026lt;Counters\u0026gt; tag, place a comment to section off your new custom category of counters.  \u0026lt;!-- CustomCategoryName --\u0026gt;  3. Add a blank Counter tag template:\n\u0026lt;Counter Category=\u0026quot;\u0026quot; Name=\u0026quot;\u0026quot; Instance=\u0026quot;\u0026quot; CollectdPlugin=\u0026quot;\u0026quot; CollectdType=\u0026quot;\u0026quot; CollectdTypeInstance=\u0026quot;\u0026quot; /\u0026gt;  3. Fill in Counter information  Follow the diagram below to fill out the Category, Name, and Instance fields (case sensitive) in the blank counter template you added in step 2.3. The picture outlines the expanded Processor counter category.   Not all categories have instances available. In the above example, the instances correlate to the processor’s cores, where _Total would calculate the metric selected for all four cores.\n\r2. Navigate to the types.db file (typically located in C:\\Program Files\\CollectdWin) and open it.\n3. Use your best judgment to match a type in types.db to the category you selected in step 3.1. Input the type (case sensitive) you wish to use into the CollectdType field.\n4. Create a metric category for the CollectdPlugin field. This category displays in the Metrics tree and search field. 5. Create a metric name using the CollectdTypeInstance field. This field is used as the metric’s name in Metricly, but be sure to make it entirely unique.\n6. Save theReadWindowsPerfCounters file.\nExample Counters A Web Service Tracking Total Instances of Current Connections:\n\u0026lt;Counter Category=\u0026quot;Web Service\u0026quot; Name=\u0026quot;Current Connections\u0026quot; Instance=\u0026quot;_Total\u0026quot; CollectdPlugin=\u0026quot;custom_iis\u0026quot; CollectdType=\u0026quot;current_connections\u0026quot; CollectdTypeInstance=\u0026quot;curr_connections\u0026quot; /\u0026gt;  Three Process Counters Checking Status of different aspects of the Windows agent service:\n\u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;% Processor Time\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;percent\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.percent_processor_time\u0026quot; /\u0026gt;  \u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;Thread Count\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;count\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.thread_count\u0026quot; /\u0026gt;   \u0026lt;Counter Category=\u0026quot;Process\u0026quot; Name=\u0026quot;Private Bytes\u0026quot; Instance=\u0026quot;^CollectdWinService$\u0026quot; CollectdPlugin=\u0026quot;processes\u0026quot; CollectdPluginInstance=\u0026quot;\u0026quot; CollectdType=\u0026quot;bytes\u0026quot; CollectdTypeInstance=\u0026quot;collectdwin.private_bytes\u0026quot; /\u0026gt; ph. An Add Counters window opens. Leave the window open.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-microsoft-teams/",
	"title": "Microsoft Teams Notifications",
	"tags": ["#alerts", "#notifications", "#microsoft teams"],
	"description": "",
	"content": " Configuration 1. Add an Incoming Webhook in Microsoft Teams  Login to your Microsoft Teams account. Navigate to Store and search for Incoming Webhook.  Choose a Microsoft Team that will receive Metricly notifications. Click Install. Select a channel from your Microsoft team and click Set up.  Provide a name for your Webhook. You may also upload a photo at this point. Click Create. Copy the Webhook URL that is generated.  Click Done. The next steps are in Metricly and require the copied Webhook URL.  2. Create a Webhook Notification in Metricly  In Metricly, navigate to the Policy Editor. Click tab 3. Notifications. Click Add Notification and select Webhook as the Notification Type. Provide a name for the webhook notification. Choose your re-notification frequency. Click New Webhook. Name the Webhook. For URL, paste the endpoint URL from Microsoft Teams. Provided a username and password if required. Select Custom for Payload and input your custom JSON. (See example below on this page.) Note that a default payload does not work for Microsoft Teams notifications.  Click Test and Save. The endpoint URL must return an HTTP code 200 to pass the validation.\n\r Click Save.  Example\n{ \u0026quot;@context\u0026quot;: \u0026quot;http://schema.org/extensions\u0026quot;, \u0026quot;@type\u0026quot;: \u0026quot;MessageCard\u0026quot;, \u0026quot;summary\u0026quot;: \u0026quot;**Metricly Policy Violation \u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;CLEARED\u0026lt;#else\u0026gt;${eventCategory.name}\u0026lt;/#if\u0026gt;:**\u0026quot;, \u0026quot;themeColor\u0026quot;: \u0026quot;${color}\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;\u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;CLEARED\u0026lt;#else\u0026gt;${eventCategory.name}\u0026lt;/#if\u0026gt; Metricly Event:\u0026quot;, \u0026quot;sections\u0026quot;: [ { \u0026quot;activityTitle\u0026quot;: \u0026quot;**Metricly Policy Violation:**\u0026quot;, \u0026quot;activitySubtitle\u0026quot;: \u0026quot;${timestamp?datetime?string.iso} UTC\u0026quot;, \u0026quot;activityImage\u0026quot;: \u0026quot;https://s3-us-west-2.amazonaws.com/com-netuitive-app-usw2-slack/metricly_teams_icon.png\u0026quot;, \u0026quot;facts\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;Title:\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;${policyName}\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;Element:\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;${elementName}\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;Type:\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;${elementType}\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;Category:\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;${eventCategory.name}\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;Description:\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;\u0026lt;#if policyDescription?has_content\u0026gt;${policyDescription?json_string}\u0026lt;#else\u0026gt;No description provided\u0026lt;/#if\u0026gt;\u0026quot; } ], \u0026quot;text\u0026quot;: \u0026quot;**Violation:** \u0026lt;#if event.data??\u0026gt;\u0026lt;#if event.data.results??\u0026gt;\u0026lt;#assign results = event.data.results?eval\u0026gt;\u0026lt;#if results.conditions??\u0026gt;\u0026lt;#list results.conditions as condition\u0026gt;\u0026lt;#if condition?counter \u0026lt;= 5\u0026gt;${condition.expression}\u0026lt;/#if\u0026gt;\u0026lt;/#list\u0026gt;\u0026lt;/#if\u0026gt;\u0026lt;/#if\u0026gt;\u0026lt;/#if\u0026gt;\u0026quot;, \u0026quot;potentialAction\u0026quot;: [ { \u0026quot;@type\u0026quot;: \u0026quot;OpenUri\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Browse Metrics\u0026quot;, \u0026quot;targets\u0026quot;: [ { \u0026quot;os\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;uri\u0026quot;: \u0026quot;${baseUrl}/metrics?event_id=\u0026lt;#if event.id??\u0026gt;${event.id}\u0026lt;/#if\u0026gt;\u0026amp;timeRangeDuration=14400\u0026amp;endTime=${timestamp?datetime?string.iso}\u0026quot; } ] }, { \u0026quot;@type\u0026quot;: \u0026quot;OpenUri\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Edit Policy\u0026quot;, \u0026quot;targets\u0026quot;: [ { \u0026quot;os\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;uri\u0026quot;: \u0026quot;${baseUrl}/policies/${policyId}\u0026quot; } ] } ] } \u0026lt;#if images?has_content \u0026amp;\u0026amp; (images?size == 1)\u0026gt; , { \u0026quot;text\u0026quot;: \u0026quot;![${images[0].elementFqn} - ${images[0].metricFqn} Metric Graph\u0026quot;](${images[0].url})\u0026quot; } \u0026lt;/#if\u0026gt; \u0026lt;#if images?has_content \u0026amp;\u0026amp; (images?size \u0026gt; 1)\u0026gt; \u0026lt;#list images as image\u0026gt; , { \u0026quot;text\u0026quot;: \u0026quot;![${image.elementFqn} - ${image.metricFqn} Metric Graph](${image.url})\u0026quot; } \u0026lt;/#list\u0026gt; \u0026lt;/#if\u0026gt; ] }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/mongodb/",
	"title": "MongoDB",
	"tags": ["#mongoDB", "#integrations"],
	"description": "",
	"content": " MongoDB is a document-oriented NoSQL database. Metricly can be used to monitor your MongoDB’s performance.\nPrerequisites The Linux Agent must be setup before you proceed with the MongoDB integration.\nConfigure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the MongoDBCollector.conf file. Change the enabled setting to True. Replace the default host address and/or port number if necessary. Save the configuration file, and restart the Linux Agent.  Due to the large number of metrics generated by MongoDB, you shouldn’t monitor more than one MongoDB host per agent.\n\rCollector Options    Option Default Description     enabled FALSE Enable collecting these metrics.   host 127.0.0.1:27017 A single hostname(:port) to collect from. Overrides hosts.   metrics_blacklist “.databases. .metrics.repl.executor.shuttingDown.   simple TRUE Set to “True” to only collect the same metrics as mongostat.   byte_unit  Default numeric output(s).   cluster  If this node is part of a cluster, the collector will collect metrics on the cluster health.   collection_sample_rate  Only send stats for a consistent subset of collections. This is applied after collections are ignored via the ignore_collectionssetting. Sampling uses crc32 to ensure consistency across replicas. Value between 0 and 1.   databases  A regex of databases to gather metrics for.   hosts  An array of hostname(:port) elements to collect metrics from. Set an alias by prefixing “host:port” with alias@   ignore_collections  A regex of which collections to ignore. MapReduce temporary collections (tmp.mr.*)are ignored by default.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.   network_timeout  Timeout for mongodb connection (in milliseconds).   passwd  Password for authenticated login (optional).   replica  Set to “True” to enable replica set logging. Reports health of individual nodes as well as basic aggregate stats.   ssl  Set to “True” to enable SSL connections to the MongoDB server.   translate_collections  Translate dot (.) to underscores (_) in collection names.   user  User name for authenticated login (optional).    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/mongodb-policies/",
	"title": "MongoDB Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#mongoDB"],
	"description": "",
	"content": "Policy names are prefixed with MongoDB –\n\r   Policy name Duration Condition 1 (and) Condition 2 Category Description     Connections in Use Threshold Exceeded 5 min metricly.linux.mongo.connections.utilization percent has a static threshold \u0026gt; 90%  CRITICAL More than 90% of the total connections to MongoDB are in use. You may need to scale your servers to handle the load.   Elevated Number of Queued Read Requests 30 min mongo.globalLock.currentQueue.readers has an upper baseline deviation  WARNING The number of read requests waiting in the queue has been higher than expected for at least the past 30 minutes.   Elevated Number of Queued Write Requests 30 min mongo.globalLock.currentQueue.writers has an upper baseline deviation  WARNING The number of write requests waiting in the queue has been higher than expected for at least the past 30 minutes.   Elevated Percentage of Connections in Use 30 min metricly.linux.mongo.connections.utilizationpercent has an upper baseline deviation  WARNING The percentage of client connections in use has been higher than expected for at least the past 30 minutes.   Suspicious Read Activity 15 min metricly.linux.mongo.opcounters.totalreads has an upper baseline deviation mongo.globalLock.activeClients.readers has no deviation WARNING The total number of reads (query and getmore requests) has been higher than expected for at least the past 15 minutes. During this time, the number of active readers has remained within the expected range. Since the increase in read activity cannot be explained by a corresponding increase in the number of readers, the increase is deemed to be suspicious.   Suspicious Write Activity 15 min metricly.linux.mongo.opcounters.totalwrites has an upper baseline deviation mongo.globalLock.activeClients.writers has no deviation WARNING The total number of writes (insert, update, and delete requests) has been higher than expected for at least the past 15 minutes. During this time, the number of active writers has remained within the expected range. Since the increase in write activity cannot be explained by a corresponding increase in the number of writers, the increase is deemed to be suspicious.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/multi-metric-widget/",
	"title": "Multi Metric Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "Options for this widget type include: line, area, and stacked.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/mute-policies/",
	"title": "Mute Policies",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#mute"],
	"description": "",
	"content": "This silences all attached notifications for the policies selected for a set duration. You can manually unmute a policy at any time as well.\n Select all policies you wish to mute. Click Mute Notifications. Input a mute duration and click OK. Your selected policies will remain muted until your chosen duration expires or when you manually unmute them.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/mysql/",
	"title": "MySQL",
	"tags": ["#mysql", "#integrations"],
	"description": "",
	"content": " MySQL is an open source relational database management system that uses the Structured Query Language to navigate its stores. Metricly can help monitor the performance and throughput of your MySQL database.\nPrerequisites The Linux Agent must be setup before you proceed with the MongoDB integration.\nConfigure  Open the interface for the database you want to monitor and enter one of the following commands:  For Normal Usage:\nGRANT REPLICATION CLIENT on *.* TO '\u0026lt;\u0026lt;username\u0026gt;\u0026gt;'@'\u0026lt;\u0026lt;host\u0026gt;\u0026gt;' IDENTIFIED BY '\u0026lt;\u0026lt;password\u0026gt;\u0026gt;';  If you’re having permission issues with the above command, try this one instead:\nGRANT ALL PRIVILEGES ON * . * TO '\u0026lt;\u0026lt;username\u0026gt;\u0026gt;'@'\u0026lt;\u0026lt;host\u0026gt;\u0026gt;';  For Innodb Engine Status:\nGRANT SUPER ON *.* TO '\u0026lt;\u0026lt;username\u0026gt;\u0026gt;'@'\u0026lt;\u0026lt;host\u0026gt;\u0026gt;' IDENTIFIED BY '\u0026lt;\u0026lt;password\u0026gt;\u0026gt;';  For Innodb Engine Status on MySQL Versions 5.1.24 and Greater:\n GRANT PROCESS ON *.* TO '\u0026lt;\u0026lt;username\u0026gt;\u0026gt;'@'\u0026lt;\u0026lt;host\u0026gt;\u0026gt;' IDENTIFIED BY ''\u0026lt;\u0026lt;password\u0026gt;\u0026gt;';  2. Navigate to the MySQLCollector.conf file.\n3. The default location is /opt/netuitive-agent/conf/collectors/MySQLCollector.conf.\n4. Change the enabled setting to True.\n5. Change the hosts setting to the proper credentials:\n username is your MySQL user name\n password is your MySQL password\n 127.0.1.1:3306 is your host:port number respectively\n mysql is the name of your database that you want to monitor  6. Save the file, and restart the Linux Agent.\nCollector Options    Option Default Description     enabled FALSE Enable collecting MySQL metrics.   hosts username:password@127.0.1.1:3306/mysql, List of hosts to collect from. Use db “None” to avoid connecting to a particular database. The format is username:password@host:port/db[/nickname]   master TRUE Enable collecting SHOW MASTER STATUS.   metrics_blacklist “^Ssl_ ^Innodb_   byte_unit  Default numeric output(s).   innodb  Enable collecting SHOW ENGINE INNODB STATUS.   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   publish  Which SHOW GLOBAL STATUS rows you would like to publish, or leave blank to publish all rows.   slave  Enable collecting SHOW SLAVE STATUS.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/ngnix/",
	"title": "NGNIX",
	"tags": ["#ngnix", "#integrations"],
	"description": "",
	"content": " Prerequisites Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the NginxCollector.conf file. Change the enabled setting to True. Save the file. Navigate to your Nginx server configuration file. Add an additional section to your file:  server { listen 127.0.0.1; server_name localhost; location /nginx_status { # turns on nginx stats # stub_status on; # turns off logging # access_log off; allow 127.0.0.1; # sends rest of world to /dev/null # deny all; } }  8. Save the Nginx configuration file, and restart the Linux Agent.\nThis integration’s package (computed metrics, dashboards, and policies that will give you important events and alerts) will be automatically enabled and provisioned to your account as soon as Metricly receives data from the integration. The PACKAGES button on the integration setup page will become active once data is received, so you’ll be able to disable and re-enable the package at will.\nCollector Options    Option Default Description     enabled FALSE Enable collecting Nginx metrics.   req_host localhost Hostname to collect from.   req_port 80 Port to collect from.   req_path /nginx_status Path to Nginx server.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   req_host_header  The name of the HTTP host header (required for SSL certificate validation).   req_ssl  Enable SSL support.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-nlb/",
	"title": "NLB Metrics",
	"tags": ["#aws", "#metrics", "#nlb"],
	"description": "",
	"content": " Collected    Friendly Name FQN Statistic Baseline Correlation     Active Flow Count aws.networkelb.activeflowcount AVG yes no   ELB Consumed ICUs aws.networkelb.consumedlcus MAX no no   ELB Healthy Host Count aws.networkelb.healthyhostcount MAX no no   ELB New Flow Count aws.networkelb.newflowcount SUM yes no   ELB Processed Bytes aws.networkelb.processedbytes SUM yes no   TCP Client Reset Count aws.networkelb.tcp_client_reset_count SUM no no   TCP ELB Reset Count aws.networkelb.tcp_elb_reset_count SUM no no   TCP Target Reset Count aws.networkelb.tcp_target_reset_count SUM no no   Unhealthy Host Count aws.networkelb.unhealthyhostcount MAX no no    Computed    Fully Qualified Name (FQN) Description Units BASE     aws.networkelb.unhealthyhostpercent Unhealthy host percent Percent yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/nagios/",
	"title": "Nagios",
	"tags": ["#nagios", "#integrations"],
	"description": "",
	"content": " Nagios is a comprehensive enterprise-class open source monitoring service. You can use our Metricly Event Handler to send your Nagios events to Metricly.\nSending Nagios Events to Metricly  Hover on your account name in the top right-hand corner and click API Keys from the drop-down menu. Copy the API Key from the Custom integration in the table. Install the Metricly Event Handler. Download the Netuitive Event Handler to the /bindirectory.  sudo curl http://repos.app.netuitive.com/cli-agent/netuitive-event-handler-linux -o \u0026quot;/bin/netuitive-event-handler\u0026quot;  5. Ensure the file is executable (use the chmod command).\nsudo chmod 755 /bin/netuitive-event-handler  6. Create and configure the /etc/netuitive/netuitive-event-handler.yaml file using the API key you copied in step 2 and the URL to the events ingest API.\napikey: your-apikey url: \u0026quot;https://api.app.netuitive.com/ingest/events\u0026quot;  7. On your Nagios server, navigate to the commands.cfg file, located at etc/nagios/objects/commands.cfg.\n8. In the commands.cfg file, create a host and service notification.\nHost\ndefine command{ command_name notify-host-by-netuitive-event command_line /bin/netuitive-event-handler -s Nagios -e \u0026quot;$HOSTALIAS$\u0026quot; -t \u0026quot;Host $HOSTALIAS$ is $HOSTSTATE$\u0026quot; -l \u0026quot;$HOSTSTATE$\u0026quot; -m \u0026quot;Host $HOSTALIAS$ is $HOSTSTATE$ - Info: $HOSTOUTPUT$\u0026quot; }  Service\ndefine command{ command_name notify-service-by-netuitive-event command_line /bin/netuitive-event-handler -s Nagios -e \u0026quot;$HOSTALIAS$\u0026quot; -t \u0026quot;Service $SERVICEDESC$ is $SERVICESTATE$\u0026quot; - l \u0026quot;$SERVICESTATE$\u0026quot; -m \u0026quot;Service $SERVICEDESC$ is $SERVICESTATE$ - Info: $SERVICEOUTPUT$\u0026quot; }  9. Open the Nagios UI.\n10. Under the Shortcuts column, click Hosts.\n11. Select the checkbox next to your Nagios host server, and then click Edit.\n12. Under the Actions section of the menu on the right, click Add Service Checks.\n13. Input a Service Description.\n14. Click Save service and let me edit it further. 15. Once the service has been saved, click the Advanced tab. 16. In the check_command field, input the command you want Nagios to run to perform the service check. 17. In the event_handler field, input the following:\nnotify-service-by-netuitive-event  18. In the event_hander_enabled field, input a 1 to enable the event handler.\n19. Check Metricly for your new Nagios events.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/netuitive-statsd/",
	"title": "Netuitive StatsD",
	"tags": ["#netuitive", "#integrations", "#netuitive statsd", "#statsd", "#custom metrics"],
	"description": "",
	"content": " The Netuitive StatsD integration interprets, aggregates, and forwards custom metrics generated from your application. Using the values instrumented from your application’s key actions and data (method calls, database queries, etc.), Metricly aggregates the values, associates them with corresponding metrics, and analyzes them in our analytics cycles.\nThe Netuitive StatsD server comes pre-installed as part of the Linux Agent. We recommend setting up a Netuitive StatsD integration if you do not have a StatsD server already.\nMetrics are taken into the server using the specified UDP format:\nmetric.name:floatvalue|metrictype|@samplerate|#tag1:value1, tag2, tag3:value3  Prerequisites  Linux Agent  Configure  Navigate to the Linux Agent configuration file, /opt/netuitive-agent/conf/netuitive-agent.conf. Change the enabled setting to True in the [[[statsd]]] section of the file.  Optionally, adjust the listen (listen_port and listen_ip) and forward (forward_ip, forward_port, and forward) options. The listen settings tell the Linux Agent where to listen for metrics; typically the server that your application is located. The forward settings tell the Linux Agent where to send the information.  Restart the Linux Agent.  Instrumentation Netuitive StatsD will collect and organize your data as your application calls functions and methods. This data is flushed to the Metricly StatsD server every 60 seconds by default, and then aggregated in Metricly’s five-minute batch analytics cycle. After Metricly analyzes your data, it’s then graphed for you to see. The Metricly StatsD server will place all of your metrics under the StatsD namespace in the Metrics page. Metrics about the Netuitive StatsD server itself are organized under the netuitive-statsd namespace in the Metrics page.\nBefore you begin instrumenting custom metrics, you’ll need to find a language library to “talk” to the Netuitive StatsD server using certain metric types. Netuitive StatsD supports the following metric types:\nCounters Count how many times an event occurs.\nexample.counter:1|c  Example Each time a different language is given in the function below, a metric’s value increments by one. If a language is not found, another metric is created to show how many times a language was not found.\n//hello-translator.js var Client = require('node-statsd-client').Client; var netuitiveStatsd = new Client(\u0026quot;localhost\u0026quot;, 8125); function translateHello(language) { if (language == \u0026quot;German\u0026quot;) { netuitiveStatsd.increment('myserver.data.german-counter') return \u0026quot;Hallo\u0026quot;; } if (language == \u0026quot;Spanish\u0026quot;) { netuitiveStatsd.increment('myserver.data.spanish-counter') return \u0026quot;Hola\u0026quot;; } if (language == \u0026quot;French\u0026quot;) { netuitiveStatsd.increment('myserver.data.french-counter') return \u0026quot;Bonjour\u0026quot;; } else { netuitiveStatsd.increment('myserver.data.no-language-counter') return \u0026quot;Sorry, I don't recognize that language.\u0026quot;; } } var languageName = prompt(\u0026quot;Please enter which language you want to translate 'Hello' to:\u0026quot;); alert(translateHello(languageName));  Timers Measure in milliseconds how long an action took.\nexample.timer:250|ms  example We want to see how long it takes for our PHP server to count to 10000.\n\u0026lt;?php $start = microtime(true); for ($x=0; $x\u0026lt;10000; $x++) {} $end = microtime(true); $finalTime = $end-$start; echo 'It took ' . $finalTime . ' seconds!'; .timing('myserver.data.timer', $finalTime, 1); ?\u0026gt;  Gauge An arbitrary, persistent value (e.g., a fuel meter).\nexample.gauge:0.6|g  Example Each time you order a pizza, you want to know what percentage of the pizza you ate.\n#!/usr/bin/my ruby srv require 'rubygems' if RUBY_VERSION \u0026lt; '1.9.0' require './statsdclient.rb' Statsd.host = 'localhost' Statsd.port = 8125 class Numeric def percent_of(n) self.to_f / n.to_f * 100.0 end end def prompt(*args) print(*args) gets end #input variables total_pizza_slices = 0 eaten = 0 #user prompts total_pizza_slices = prompt \u0026quot;How many total slices made up the pizza? \u0026quot; eaten = prompt \u0026quot;How many slices did you eat? \u0026quot; #calculation percent_eaten = eaten.percent_of(total_pizza_slices) p \u0026quot;You ate #{percent_eaten} of the pizza!\u0026quot; Statsd.gauge('myserver.data.gauge', percent_eaten)  Sets A number of unique elements received over a set interval.\nexample.set:username|s  Histograms The statistical distribution of a set of values.\nexample.histogram:129|h  Tagging You can also pass in tags to any of your metrics like so:\nnetuitive_statsd.increment('login.errors', tags=['name', 'value'])  Reserved Metric Tags Netuitive StatsD already uses a few tags, so be mindful when passing in tags with StatsD metrics.\n h: Sets the hostname (element ID) of the element. The h tag should be replaced with caution, as replacing it with a custom value will create a separate, extra element. un: Sets the unit of the metric you’re creating. An exhaustive list of the units Netuitive StatsD supports can be found here. sds: Defines the strategy for replacing missing data. You can either replace missing data with a zero (ReplaceWithZero) or take no strategy at all (None). You should schedule a data push at least once in every five-minute cycle. If you cannot send data every five minutes, you should consider sending zeroes. ty: Sets the type of the element in Netuitive StatsD (e.g., SERVER).  Optional Configuration    Option Default Description     enabled TRUE Enable collecting Netuitive StatsD metrics.   interval 60 The interval (in seconds) at which to collect metrics.   listen_port 8125 User Datagram Protocol (UDP) port to listen on.   listen_ip 127.0.0.1 IP address to listen on.   element_type SERVER Element type applied to your netuitive-statsd server instance in Metricly.   prefix statsd Prefix applied to your netuitive-statsd metrics in Metricly. Setting an empty prefix causes no prefix to be added.   forward_ip 127.0.0.1 IP address to forward StatsD messages to.   forward_port 9125 UDP port to forward StatsD messages to.   forward FALSE Enable StatsD forwarding.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/diamond-agent/diamond-agent-metrics/diamond-agent-network-metrics/",
	"title": "Network Metrics",
	"tags": ["#diamond", "#integrations", "#agents", "#network"],
	"description": "",
	"content": " Computed    Fully Qualified Name(FQN) Description Units Min Max BASE CORR UTIL     metriclyicly.linux.network.*.errors The total number of errors, both transmit and receive. Computation: network..rx_errors + network..tx_errors errors 0 none yes no no   metriclyicly.linux.network.*.packets The total number of packets, both transmitted and received. Computation: network..rx_packets + network..tx_packets packets 0 none yes yes no   metriclyicly.linux.network.*.errors.percent The percentage of errors, both transmit and receive. Computation: (metriclyicly.diamond.network..errors /metriclyicly.diamond.network..packets) * 100 percent 0 100 yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/nodejs/",
	"title": "Node.js",
	"tags": ["#node.js", "#integrations"],
	"description": "",
	"content": " You can monitor your Node.js-based applications using the Linux Agent and Metricly StatsD server. All it takes is installing our agent and instrumenting your custom metrics, and then you’ll be visualizing the performance of your Node.js applications.\nPrerequisites  Linux Agent  Configure  Navigate to the netuitive-agent.conf file Update statsd to enabled = True.   # local statsd server [[[statsd]]] enabled = True  3. Ensure Node.js is installed properly using the node command.\n4. StatsD requires a client library to push metrics, so you’ll need to install a Node.js library. For this example, we’ll be implementing the statsd-client. The open source community also has many Node.js libraries for StatsD that should all work with our agent.\nnpm install statsd-client  5. Import the client into your application file and specify the location of the Metricly StatsD backend. By default, the Metricly StatsD runs on localhost port 8125 (as specified in the /opt/netuitive-agent/conf/netuitive-agent.conf file).\nvar SDC = require('statsd-client'), client = new SDC({host: 'statsd.example.com', port: 8125});  6. Instrument your application code by calling the appropriate functions.\n// Counter Increment – Count occurrences of an event client.increment('example.data.counterup'); //Counter Decrement - Subtract values from metrics client.decrement('example.data.counterdown', -10); // Timer – Measure the amount of time anaction took to complete client.timing('example.data.timer', 250); // Gauge – Set an static value andcompare against it to evaluate fluctuations client.gauge('example.data.gauge', 5); // Histogram - Create a histogram with tags client.histogram('example.data.histogram', 10, {foo: 'bar'})  7. Save and restart your application and the Linux Agent.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/",
	"title": "Notifications",
	"tags": ["#alerts", "#notifications"],
	"description": "",
	"content": " Notifications are optional alerts sent to another source (e.g., email, PagerDuty, OpsGenie) when an event occurs. You will only receive notifications from policies that have a notification(s) configured. While notifications are enabled by default, they will be automatically disabled if they are used in a policy and fail for a period of time.\nUsing Notifications The Policy Editor Set up notifications by opening the desired policy in Policy Editor. To enable or disable existing notifications, see below.\n In the Policy Editor, under Notifications, click Add Notification. Select the desired notification type. Once a type is selected, choose a notification you have set up for the selected type. You can also create a new notification directly from here. Select how often\u0026ndash;between 5 minutes and 24 hours or never\u0026ndash;the policy should re-notify you if a policy is creating events. Enable Notify on Clear if you’d like to receive a notification when the policy stops triggering. Save the policy.  Enable/Disable Notifications  From the user account drop-down menu, select Notifications. Open the desired notification. Select (or clear) the Enabled checkbox. Click Save.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-opsgenie/",
	"title": "OpsGenie Notifications",
	"tags": ["#alerts", "#notifications", "#opsgenie"],
	"description": "",
	"content": " Configuration 1. Create a Metricly integration within OpsGenie  Log in to your OpsGenie account. Under Integrations, select Metricly. Copy the API key provided on this page to your clipboard. You will use this to set up a new OpsGenie notification in Metricly. Leave the Teams and Recipients fields as {{teams}} and {{recipients}}, respectively. This ensures that the Teams and Recipients you include in Part 2 are passed from Metricly to your OpsGenie account, and will receive alerts.\n\r Ensure that Enabled is selected. Click Save Integration.  2. Link the integration to Metricly  In Metricly, navigate to Username \u0026gt; Notifications. Click OpsGenie \u0026gt; Add OpsGenie and type a name for the OpsGenie notification. Ensure the Enabled checkbox is selected. For API Key, paste the API key you copied from your Metricly Integration in OpsGenie in step 3 of Part 1. For Description, add a description of the notification. For Teams, type a comma-separated list of any OpsGenie teams that should receive notifications. For Recipients, type a comma-separated list of any OpsGenie recipients that should receive notifications. If you include no teams or recipients, and when setting up a Metricly Integration in OpsGenie, left the Teams and Recipients fields as {{teams}} and {{recipients}}, no parties will receive notifications for this policy. However, an alert will still appear in OpsGenie when an event for this policy is generated in Metricly.\n\r For Tags, type a comma-separated list of any tags you want to apply to the OpsGenie alert (e.g. tag1, tag2, tag3). Click Test and Save.  Optional Configuration About Endpoints If you have not chosen an API instance for your OpsGenie account, it will default to the US. This can be changed to any supported OpsGenie endpoint.\nAvailable Endpoints:\n US: https://api.opsgenie.com EU: https://api.eu.opsgenie.com Test: your test url  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/ruby-agent-options/",
	"title": "Optional Config",
	"tags": ["#ruby", "#integrations", "#agents"],
	"description": "",
	"content": " Log Options  logLocation: The absolute path of the log file. Leave this option blank to use the default location in the gem directory. logAge: Specify either the number of log files to keep or the frequency of rotation (daily, weekly, or monthly). logSize: Specify the maximum log file size (in bytes). debugLevel: Options include (in ascending order of severity) error, info, and debug.  Active Support Notifications The active support notifications are a pub-sub model that trigger active support notifications when certain actions are performed within your rails application(s). Each flag is toggling a certain set of active support notifications for a subset of metrics in Metricly.\n actionControllerEnabled: Set to true to enable action_conroller metric collection. activeRecordEnabled: Set to true to enable active_record metric collection. actionViewEnabled: Set to true to enable action_view metric collection. actionMailerEnabled: Set to true to enable action_mailer metric collection. activeSupportEnabled: Set to true to enable active_support metric collection. activeJobEnabled: Set to true to enable active_job metric collection.  Injected Instrumentation  requestWrapperEnabled: Set to true to enable the queue time metric, which is the time (in ms) taken after a request enters your system and before it reaches your application. Metricly takes either the X-Queue-Start or X-Request-Start headers to calculate the queue time, but time unit types won’t be automatically converted. actionErrorsEnabled: Set to true to inject code into the action controller which will silently track exceptions. Exceptions will be sent to Metricly as an external event. An errors metric will also be available on the Metrics page under the action_controller branch for the element that tracks the number of exceptions seen.  Interpreter Metrics  gcEnabled: Set to true to enable garbage collection metric collection. objectSpaceEnabled: Set to true to enable object space metric collection.  3rd Party  sidekiqEnabled: Set to true to enable sidekiq metric and error collection.  Sidekiq metrics include number of jobs per queue, number of jobs ran per queue, and number of jobs ran per job. Errors will be sent to Metricly as an external event. An errors metric will also be available on the Metrics page under the sidekiq branch for the element that tracks the number of exceptions seen.   Error Tracking Features sendErrorEvents: Set to true to send exceptions from sidekiq and action_controller as events to Metricly. - If this setting is set to false, but actionErrorsEnabled and sidekiqEnabled are set to true, errors will not be sent to Metricly as events but all metrics will still be collected.\nFeature Configs  queueTimeUnits: The divisor required to convert the queue time metric into seconds (e.g., seconds = 1, milliseconds = 1000, microseconds = 1000000). ignoredErrors: List of exceptions to ignore. List should be provided in one of the following formats:  yaml\nignoredErrors: - Runtime Error - Argument Error  environment variable\nnetuitive_RAILS_IGNORED_ERRORS=RuntimeError,ArgumentError  You can ignore exceptions that match agains an ancestor using a ^, so netuitive_RAILS_IGNORED_ERRORS=RuntimeError^ would ignore all errors that inherit from RuntimeError.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/php/",
	"title": "PHP",
	"tags": ["#php", "#integrations"],
	"description": "",
	"content": " You can monitor your PHP applications using our PHP client library, the Linux Agent, and the Metricly StatsD server.\nPrerequisites  Linux Agent  Configure  Navigate to the metricly-agent.conf file. Update the statsd setting to enabled = True.  # local statsd server [[[statsd]]] enabled = True  3. StatsD requires a client library to push metrics. You can use our PHP client library or an open source alternative. 4. Include the client library file on any page you want to collect metrics, or you can reference the file globally.\ninclude 'StatsD_Client.php';  5. Instrument your application code by calling the appropriate functions. Check out the example below or the timer example included in the library repo.\n//add a gauge in any section of your code .gauge('test.data.gauge', 20); //to add this time you must first add code to calculate the start and end time. //typically we use epoch time. And add code at the start and end of the code you want to measure. //the timing function expects time in milliseconds .timing('test.data.timer', 1000, 1); //you can add or subtract from any metric with these functions .increment('test.data.counterup', 1); .decrement('test.data.counterdown', 1);  6. Save and restart both your application and the Linux Agent.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/metrics/metric-page/",
	"title": "Page Features",
	"tags": ["#getting started", "#metrics"],
	"description": "",
	"content": " Sub Navigation Filters  Name Contains: Specific search based on name\n Search Metrics: Broad filter based on metric type, provided in tree and list form Element, Type, More: Additional expandable filter options\n Grouped By: Contains a menu of all quick groups, tags, and attributes available to Metricly. After you’ve rendered some metric charts, choose one of the groupings and Metricly will automatically group the metric charts based on your selection.  If you chose to display all EC2 metrics and then grouped by instance ID, each instance’s set of metrics would be grouped in a section together under the instance’s ID.\n\rOnce you have added all needed search criteria, click Render Charts to populate results.\nQuick Filters / Metric Charts Click a Quick Filter to render metric charts automatically for the selected filter. Metric charts are a visualization of a metric for an element. See below to learn more.\nEvents Graph The Events graph displays the events in your environment based on the Time Frame setting and other search filters. For more information, see Events graph. Click an event to have the option of viewing the violating metrics on the Metrics page or edit the policy the event is associated with.\nMetric Chart Size Select how wide or how tall you want your metric charts to be. Time Frame Controls The Time Frame controls the range of data displayed. To refresh data, click the refresh button. Selecting “1w” in the Time Frame displays the most recent week of data and/or elements. By selecting “Ending Now,” you can specify a range of data beginning with a date other than today. For more information, see Time Frame.\nData Aggregation Select the type of data displayed on the metric charts.\n   Option Description     Raw Shows data that has not been aggregated by Metricly. Computed metrics do not have raw data because they are calculated by Metricly.   5 Min Displays aggregate data that Metricly generates by averaging the data collected from a given integration at 5 minute intervals.   1 Hour Displays aggregate data that Metricly generates by averaging the data collected from a given integration at 1 hour intervals.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-pageryduty/",
	"title": "PagerDuty Notifications",
	"tags": ["#alerts", "#notifications", "#slack"],
	"description": "",
	"content": " Configuration 1. Create a service in PagerDuty  Log into your PagerDuty account. Navigate to Configuration \u0026gt; Services. Click Add New Services.  Type a name for the service and select your incident settings. For Integration Type, click the Select a Tool dropdown \u0026gt; Netuitive. Finish all other settings and click Add Service. Copy the Integration Key provided. This is needed to set up a new PagerDuty notification in Metricly.   2. Link the service with Metricly  Navigate to a Policy and click Notifications. Click Add Notification and select PagerDuty. Type a name for the PagerDuty integration and ensure the Enabled checkbox is selected.  Add the service key from the Metricly service you created in PagerDuty. Click Test and Save.  The endpoint URL must return an HTTP code 200 to pass the validation.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-plugins/",
	"title": "Plugins",
	"tags": ["#windows", "#integrations", "#plugins"],
	"description": "",
	"content": " There are two types of Windows plugins: Read (which allow our Windows agent to read data) and Write (which allow our Windows agent to write data). The following plugins are enabled by default:\n ReadWindowsPerfCounters ReadWindowsAttributes ReadWindowsEvents WriteNetuitive  This configuration is recommended for monitoring a Windows server with Metricly. Other Read/Write plugins are available as documented below (note that the Write Console plugin has no configuration settings).\nEnable/Disable To change which plugins are enabled, edit the CollectdWin.config file.\nThe file will be located in C:\\Program Files\\CollectdWin\\config or C:\\Program Files (x86)\\CollectdWin\\config depending on your environment.\n\rRead Windows Performance Metrics plugin This plugin uses the Windows Performance Count component to collect configured metrics. Each performance counter can be mapped to its Collectd equivalent metadata via configuration.\n Navigate to the ReadWindowsPerfCounters.config file. Add as many entries as you desire using the table below.     Value Required/Optional Description     ReloadInterval Required The period in seconds before rescanning for new/changed instances (defaults to 3600). This is configured once in the ReadWindowsPerfCounters element.   Category Required The name of the performance counter category.   Name Required Comma-separated performance counter names.   Instance Required This can be set to a specific instance or a regular expression to filter the instances. Some counter categories do not have instances; in this case, this field should be left blank.   CollectdPlugin Required Collectd plugin name.   CollectdPluginInstance Required Where the configuration is for a single instance, this value can be used to override the instance name. Where there are multiple instances, this value is automatically set for each instance.   CollectdType Required Metric type and units. This must be a value in types.db, which can be found in the deployment folder.   CollectdTypeInstance Required Name for the metric instance.   Multiplier Optional Float scale factor to be applied to the value.   DecimalPlaces Optional Integer number of decimal places for rounding.     Here’s a default entry in the ReadWindowsPerfCounters.config file:  \u0026lt;Counter Category=\u0026quot;Network Interface\u0026quot; Name=\u0026quot;Packets Received/Sec,Packets Sent/Sec\u0026quot; Instance=\u0026quot;*\u0026quot; CollectdPlugin=\u0026quot;interface\u0026quot; CollectdType=\u0026quot;if_packets\u0026quot; CollectdTypeInstance=\u0026quot;\u0026quot; /\u0026gt;  3. Save the file.\nRead Windows Event plugin This plugin reads from the Windows event logs on the server the agent is installed. The WriteNetuitive plugin will process the values it collects, but no other write plugins are able to do so.\n Navigate to the ReadWindowsEvents.config file. Add as many entries as you desire using the table below:     Value Required/Optional Description     Title Required A descriptive title for the events captured by this configuration entry. This is shown as the event title in Metricly.   Log Required The windows log (e.g., Application, System, Security).   Source Required The source of the event (this is the source field in the event viewer). This value can be left blank for any source.   MinLevel Optional The minimum log level to collect. Defaults to 1. Possible values (in order): 1 = critical, 2 = error, 3 = warning (warn), 4 = information, and 5 = verbose.   MaxLevel Required The maximum log level to collect. Offers the same levels as the MinLevel setting. Set to the same value as MinLevel to restrict to just one level.   MinEventId Optional The minimum event ID to collect between 0 and 65535. Defaults to 0.   MaxEventId Optional The maximum event ID to collect between 0 and 65535. Defaults to 65535. Set to the same as MinEventId to restrict collection to a single event.   FilterExp Optional A regular expression applied to the log message. Messages that do not match are disregarded.     Here’s a default entry in the ReadWindowsEvents.config file:  \u0026lt;Event Title=\u0026quot;Error 99 occurred in MyApp\u0026quot; Log=\u0026quot;Application\u0026quot; Source=\u0026quot;MyApp\u0026quot; MinLevel=\u0026quot;2\u0026quot; MaxLevel=\u0026quot;2\u0026quot; MinEventId=\u0026quot;99\u0026quot; MaxEventId=\u0026quot;99\u0026quot; /\u0026gt;  3. Save the file.\nRead Windows Attribute plugin This plugin reads non-numeric attributes of the server. The WriteNetuitive plugin will process the values it collects, but no other write plugins are able to do so. Three attributes are available by default:\n   Name Description     os The operating system version.   cpus The number of CPUs.   ram bytes Total system RAM.    If the server is hosted on an AWS EC2 and the ReadEC2InstanceMetadata attribute on the ReadWindowsAttributes element is set to true, the plugin will read metadata from the host EC2 instance as attributes (e.g., instanceId, instanceType, etc.) and also record the relationship between the two elements in Metricly.\nAny environment variable can be read as an attribute by adding it to the configuration section:\n Navigate to the ReadWindowsAttributes.config file. Following the format of the other available attributes, add as many attributes as you desire.  \u0026lt;EnvironmentVariable Name=\u0026quot;architecture\u0026quot; Value=\u0026quot;PROCESSOR_ARCHITECTURE\u0026quot;/\u0026gt;  3. Save the file.\nRead StatsD Plugin The Read StatsD plugin implements the StatsD Network Protocol. It listens on a UDP port and receives metrics from applications. The plugin supports four event types:\nGauges A gauge is an instantaneous measurement of a value. It differs from a counter by being calculated at the client rather than the server.\n\u0026lt;metric name\u0026gt;:\u0026lt;value\u0026gt;|g  Counters A counter is a gauge calculated at the server. Metrics sent by the client increment or decrement the value of a gauge rather than giving its current value. Counters may also have an associated sample rate given as a decimal of the number of samples per event counter.\n\u0026lt;metric name\u0026gt;:\u0026lt;value\u0026gt;|c[|@\u0026lt;sample rate\u0026gt;]  Timers A timer is a measure of the number of milliseconds elapsed between a start and end time.\n\u0026lt;metric name\u0026gt;:\u0026lt;value\u0026gt;|ms  Sets Unique occurrences of events within an interval.\nuniques:765|s  Properties Available Several properties are available by default:\n   Name Description     Statsd.Host Host name for StatsD UDP listener.   Statsd.Port Port number for StatsD UDP listener.   DeleteCache.Counters, DeleteCache.Timers, DeleteCache.Gauges,    DeleteCache.Sets This option controls the behavior when metrics are not updated in an   interval. If set to false, metrics are dispatched unchanged. If set    to true, metrics are not dispatched and removed from the internal    cache.    Timer.Lower, Timer.Upper, Timer.Sum, Timer.Count This option is to enable aggregate functions for timer metrics. If   enabled for each timer metric, its equivalent aggregate metric is    also dispatched with appropriate extensions (“-lower”, “-upper”,    “-sum”, “-count”).    Percentiles.Percentile Calculate and dispatch the configured percentile, i.e. compute the   latency so that Percent of all reported timers are smaller than or    equal to the computed latency. If enabled for each time metric, its    equivalent percentile metric is also dispatched with appropriate    extensions (“-percentile-90”, “-percentile-95”). If not configured,    no percentile is calculated or dispatched.     Configure  Navigate to the ReadStatsD.config file. Following the format of the default configuration, manipulate the properties as desired. Save the file.  Write Netuitive plugin This plugin is already configured to send all data gathered by the read plugins to Metricly via its REST API in step 2 of the installation instructions. The following are additional, advanced settings that should only be changed in discussion with Metricly support.\n   Name Description     Url Metricly ingest API URL.   PayloadSize (Optional) The number of metrics that are batched into a single POST. Set to -1 to send all metrics at once; the default is 25.   Location (Optional) Sets element location attribute.   Type (Optional) Overrides the element type in Metricly; the default is WINSRV.    Configure  Navigate to the WriteNetuitive.config file. Add any of the optional configuration attributes to the line in the file.  Example with API Key\n\u0026lt;WriteNetuitive Url=\u0026quot;https://api.app.metricly.com/ingest/windows/de2b497468d863accb9c402dfff22689\u0026quot;/\u0026gt;  3. Save the file.\nWrite StatsD plugin The Write StatsD plugin posts metrics as UDP datagrams to a StatsD server. The metric buckets follow the naming convention:\n[Prefix].[Hostname].[CollectdPlugin].[CollectdPluginInstance].[ CollectdTypeInstance]  Three attributes are available by default:\n   Name Description     Host Statsd hostname.   Port UDP Port number.   Prefix (Optional) Optional bucket name prefix.    Configure  Navigate to the WriteStatsd.config file. Add any of the optional configuration attributes to the line in the file. Save the file.  Write HTTP plugin The Write HTTP plugin works similarly to the collectd Write HTTP plugin. It posts metrics to the target URL in the following JSON format.\n[ { \u0026quot;values\u0026quot;: [197141504, 175136768], \u0026quot;dstypes\u0026quot;: [\u0026quot;counter\u0026quot;, \u0026quot;counter\u0026quot;], \u0026quot;dsnames\u0026quot;: [\u0026quot;read\u0026quot;, \u0026quot;write\u0026quot;], \u0026quot;time\u0026quot;: 1251533299, \u0026quot;interval\u0026quot;: 10, \u0026quot;host\u0026quot;: \u0026quot;leeloo.lan.home.verplant.org\u0026quot;, \u0026quot;plugin\u0026quot;: \u0026quot;disk\u0026quot;, \u0026quot;plugin_instance\u0026quot;: \u0026quot;sda\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;disk_octets\u0026quot;, \u0026quot;type_instance\u0026quot;: \u0026quot;\u0026quot; }, ... ]  Configure  Navigate to the WriteHTTP.config file. Update the Url attribute to the target URL. Save the file.  Write AMQP plugin The Advanced Messaging Queuing Protocol (AMQP) is an open standard application layer protocol for message-oriented middleware. The Write AMQP plugin publishes metrics to the configured message broker in JSON format. Several attributes are available by default:\n   Name Description     Name Name of the AMQP publisher.   Host Message broker’s host name.   Port Message broker’s AMQP listening port.   VirtualHost The name of the “virtual host” (or vhost) that specifies the namespace for entities (exchanges and queues) referred to by the protocol. Virtual hosts provide a way to segregate applications using the same message broker instance.   User User name for authentication.   Password Password for authentication.   Exhange Exchanges are AMQP entities where messages are sent. Exchanges take a message and route it into zero or more queues.   RoutingKeyPrefix A message sent to a message broker contains a routing key and message body.    Configure  Navigate to the WriteAMQP.config file. Add any of the optional configuration attributes to the Publishline in the file. Save the file.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/",
	"title": "Policies",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#conditions", "#scope"],
	"description": "",
	"content": "A policy is a set of conditional tests used to set custom rules for when Metricly will generate an event or other notifications. In other words, policies allow you to define various types of abnormal element behavior, then notify you when that abnormal behavior occurs.\nUse the Policy Editor to add, edit, enable, disable, or delete policies.\nA policy is made up of a scope, condition(s), duration, and notification(s).\n The Scope defines the element or elements to which a policy is applied. A condition is a test applied to an individual metric (or several) that is either true or false at any given time. For a policy to execute an event and/or notification, each of its conditions must be met. The Duration is the length of time for which the conditions in a policy must be met before an event and/or notification is executed. For example, if duration is 10 minutes, each of the conditions in a policy must be met for 10 consecutive minutes before you will receive a notification or see an event in Metricly. A Notification is sent if each of a policy\u0026rsquo;s conditions are met.  Policies with Metricly listed in the Created By column are called default policies. They serve as recommended policy configurations that you can edit, enable, disable, or delete. For more information about default policies, see Default policies.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/postresql/",
	"title": "PostreSQL",
	"tags": ["#postresql", "#integrations"],
	"description": "",
	"content": " PostgreSQL is an open-source database management system. Metricly can be used to monitor your PostgreSQL database(s).\nPrerequisites  Linux Agent  Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the PostgresqlCollector.conf file. Change the enabled setting to True. Update the dbname setting to the name of your database. Update the user and password settings to the proper credentials used to access the database. Save the configuration file, and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting PostgreSQL metrics.   host localhost Hostname to collect from   dbname postgres Database that contains list of databases in PostgreSQL.   user postgres Username used for database authentication.   password postgres Password used for database authentication.   port 5432 Port to collect from.   metrics_whitelist “^database.*” Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   byte_unit  Default numeric output(s).   extended  Enable collecting extended database stats.   has_admin  Setting that notes if admin privileges are required to run some queries.   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics  List of enabled metrics to collect.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   password_provider  Tells the agent whether to authenticate with the supplied password orthe .pgpass file password.   pg_version  The version of PostgreSQL you wish to monitor.   sslmode  Defines server certificate verification method to use for SSLconnections (if any). Available values include disable, allow, prefer, require, verify-ca,and verify-full. Full details included here.   underscore  Enables converting underscores (“_”) to periods (“.”).    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/powerdns/",
	"title": "PowerDNS",
	"tags": ["#powerdns", "#integrations"],
	"description": "",
	"content": " Prerequisites  Linux Agent  Configure You cannot activate the PowerDNS integration until Metricly begins receiving data. Once data arrives, the package (Dashboards and Policies) is automatically provisioned. To remove those Dashboards and Policies, click the toggle on the PowerDNS integration card.\n1. Get API Key  In Metricly, Navigate to Integrations \u0026gt; PowerDNS. Copy the API Key. Add this key to your Linux Agent.  2. Update the Configuration File  Open PowerDNSCollector.conf in the collectors folder, /opt/netuitive-agent/conf/collectors. Change the enabled setting to True,] Save the file and restart the agent.  Collector Options    Setting Default Description Type     bin /usr/bin/pdns_control The path to the pdns_control binary str   byte_unit byte Default numeric output(s) str   enabled FALSE Enable collecting these metrics bool   measure_collector_time FALSE Collect the collector run time in ms bool   metrics_blacklist None Regex to match metrics to block. Mutually exclusive with metrics_whitelist NoneType   metrics_whitelist None Regex to match metrics to transmit. Mutually exclusive with metrics_blacklist NoneType   sudo_cmd /usr/bin/sudo Path to sudo str   use_sudo FALSE Use sudo? bool    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/process-resources-collector/",
	"title": "Process Resource Collector",
	"tags": ["#process resource collector", "#integrations", "#collectors"],
	"description": "",
	"content": " The Process Resources Collector can be used to collect CPU- and Memory-type metrics on a per-process level.\nPrerequisites  Linux Agent  Configure Update the Configuration File  Navigate to the collectors folder, opt/netuitive-agent/conf/collectors. Open the ProcessResourcesCollector.conf file. Change the enabled setting to True. For each process you’d like to monitor, include the following below the [process] section:  [[process_name]] name = \u0026quot;.*regex-statement.*\u0026quot;  Example\n[[nginx]] name = ^nginx  5. Save the configuration file and restart the Linux Agent.\nCollector Options    Option Default Description     enabled FALSE Enable collecting these metrics.   process  A subcategory of settings inside of which each collected process has its configuration.   byte_unit  Default numeric output(s).   name  Regex that matches the process name.   cmdline  Regex that matches the full command line process name (including all the options).   exe  Regex that matches the executable file that’s used to run the process.   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   unit  The unit of the memory data collected.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-processes-metrics/",
	"title": "Processes Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#processes", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     processes.fork_rate.value Number of processes per second being forked. average forks/second 0 none none yes no no   processes.ps_state-blocked.value Number of processes in a blocked state. A process that is blocked is onethat is waiting for some event, such as a resource becoming available orthe completion of an I/O operation. average count 0 none none yes no no   processes.ps_state-paging.value Number of processes which are paging. average count 0 none none yes no no   processes.ps_state-running.value Number of processes which are running. average count 0 none none yes no no   processes.ps_state-sleeping.value Number of processes which are sleeping. A sleeping process is one whichis not currently doing any work. average count 0 none none yes no no   processes.ps_state-stopped.value Number of processes which are stopped. A stopped process is one whichwill not proceed until it receives a signal to continue. average count 0 none none yes no no   processes.ps_state-zombies.value Number of processes in the zombie state. A zombie is a child process,which has terminated, but still exists in the process table to bereferenced by the parent process. Long-running zombies are typicallyerrors that cause a drain on system resources. average count 0 none none yes no no    Computed    Fully Qualified Name(FQN) Description Statistic Units Min Max BASE CORR UTIL     metricly.collectd.processes.total Computation: processes.ps_state-blocked + processes.ps_state-paging +processes.ps_state-running + processes.ps_state-sleeping +processes.ps_state-stopped + processes.ps_state-zombies average count 0 none yes yes no   metricly.collectd.processes.blockedpercent Computation: (processes.ps_state-blocked / Total Processes) * 100 average percent 0 100 yes no no   metricly.collectd.processes.pagingpercent Computation: (processes.ps_state-paging / Total Processes) * 100 average percent 0 100 yes no no   metricly.collectd.processes.runningpercent Computation: (processes.ps_state-running / Total Processes) * 100 average percent 0 100 yes yes no   metricly.collectd.processes.sleepingpercent Computation: (processes.ps_state-sleeping / Total Processes) * 100 average percent 0 100 yes no no   metricly.collectd.processes.stoppedpercent Computation: (processes.ps_state-stopped / Total Processes) * 100 average percent 0 100 yes no no   metricly.collectd.processes.zombiepercent Computation: (processes.ps_state-zombie / Total Processes) * 100 average percent 0 100 yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-proxy/",
	"title": "Proxy",
	"tags": ["#windows", "#integrations", "#plugins"],
	"description": "",
	"content": " Determining if you have a proxy enabled  Open Internet Explorer. Click the Tools icon, and then click Internet Options. On the Connections tab, click LAN settings. If any of the checkboxes are selected and the appropriate information is filled out, you may need to configure proxy settings to enable data being posted by the agent on your server.  Configuring the proxy  Add the following to the end of the CollectdWinService.exe.config file after the  section and before the closing  tag:  \u0026lt;system.net\u0026gt; \u0026lt;defaultProxy enabled=\u0026quot;true\u0026quot; useDefaultCredentials=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;proxy/\u0026gt; \u0026lt;/defaultProxy\u0026gt; \u0026lt;/system.net\u0026gt;  2. Replace the  element with one of the options below (corresponding to which option was selected in Internet Explorer).\nProxy Options More information about proxy settings can be found in the MSDN.\nNo Proxy Automatically Detect Settings If the Automatically detect settings checkbox was selected, use the following proxy element: \u0026lt;system.net\u0026gt; \u0026lt;defaultProxy enabled=\u0026quot;true\u0026quot; useDefaultCredentials=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;proxy autoDetect=\u0026quot;true\u0026quot; /\u0026gt; \u0026lt;/defaultProxy\u0026gt; \u0026lt;/system.net\u0026gt;  Use automatic configuration script If the Use automatic configuration script checkbox was selected, use the following proxy element:\n\u0026lt;system.net\u0026gt; \u0026lt;defaultProxy enabled=\u0026quot;true\u0026quot; useDefaultCredentials=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;proxy scriptLocation=\u0026quot;http://www.test.com:1234/sampleScript\u0026quot; /\u0026gt; \u0026lt;/defaultProxy\u0026gt; \u0026lt;/system.net\u0026gt;  Replace SCRIPT_URI with the content of the Address text box in the LAN settings window.\nUse a proxy server for your LAN If the Use a proxy server for your LAN checkbox was selected and the address and port are specified, use the following proxy element:\n\u0026lt;system.net\u0026gt; \u0026lt;defaultProxy enabled=\u0026quot;true\u0026quot; useDefaultCredentials=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;proxy proxyAddress=\u0026quot;http://proxyhost:8088\u0026quot; /\u0026gt; \u0026lt;/defaultProxy\u0026gt; \u0026lt;/system.net\u0026gt;  Replace URI_STRING with the address and port settings used (e.g., http://proxyhost:8088). If the address and port are not specified, then the proxy is manually configured on the Advanced screen. Enter the proxy element as above but using the address and port given for the HTTPS protocol.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/puppetdb/",
	"title": "PuppetDB",
	"tags": ["#puppetDB", "#integrations"],
	"description": "",
	"content": " Prerequisites  Linux Agent  Configure You cannot activate the PuppetDB integration until Metricly begins receiving data. Once data arrives, the package (Dashboards and Policies) is automatically provisioned. To remove those Dashboards and Policies, click the toggle on the PuppetDB integration card.\n1. Get API Key  In Metricly, Navigate to Integrations \u0026gt; PuppetDB. Copy the API Key. Add this key to your Linux Agent.  2. Update the Configuration File  Open PuppetDBCollector.conf in the collectors folder, /opt/netuitive-agent/conf/collectors. Change the enabled setting to True,] Save the file and restart the agent.  enabled = True host = localhost port = 8080  4. View your data.\nMetricly starts displaying data in approximately 5 minutes.You can adjust the default settings as necessary depending on your environment.\n\rCollector Options    Setting Default Description Type     byte_unit byte Default numeric output(s) str   enabled FALSE Enable collecting these metrics bool   host localhost Hostname to collect from str   measure_collector_time FALSE Collect the collector run time in ms bool   metrics_blacklist None Regex to match metrics to block. Mutually exclusive with metrics_whitelist NoneType   metrics_whitelist None Regex to match metrics to transmit. Mutually exclusive with metrics_blacklist NoneType   port 8080 Port number to collect from int    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/python/",
	"title": "Python",
	"tags": ["#python", "#integrations"],
	"description": "",
	"content": " You can monitor your Python applications using a Python web module, the Linux Agent, and the Metricly StatsD server.\nPrerequisites  Linux Agent  Configure  Navigate to the netuitive-agent.conf file. Update the StatsD setting to enabled = True.  # local statsd server [[[statsd]]] enabled = True  3. Download the python web module and extract the files.\n\u0026gt;\u0026gt; wget http://webpy.org/static/web.py-0.37.tar.gz \u0026gt;\u0026gt; tar xzvf web.py-0.37.tar.gz  4. Move the web directory to the same folder as your application.\n\u0026gt;\u0026gt; mv web.py-0.37/web /opt/python  5. Download the pystatsd client from GitHub.\n\u0026gt;\u0026gt; git clone https://github.com/jsocol/pystatsd.git  6. Move the statsd directory to the same folder as your application.\n\u0026gt;\u0026gt; cd pystatsd \u0026gt;\u0026gt; mv statsd /opt/python/  7. Import the web and statsd modules into your application’s code.\nimport web import statsd  8. Instrument your application code by calling the appropriate functions. Here\u0026rsquo;s an example:\nimport web import statsd # Counter Increment c.incr('example.data.counterup', 1) # Counter Decrement c.decr('example.data.counterdown', 1) # Timer c.timing('example.data.timer', 320) # Gauge c.gauge('example.data.gauge', 4) urls = ( '/', 'index' ) class index: def GET(self): return \u0026quot;Hello, world!\u0026quot; if __name__ == \u0026quot;__main__\u0026quot;: app = web.application(urls, globals()) app.run()  9. Save and then restart your application and the Linux Agent.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/inventory/inventory-quickbar-actions/",
	"title": "Quickbar Actions",
	"tags": ["#getting started", "#metrics", "#elements", "#bulk actions", "#inventory page"],
	"description": "",
	"content": " The inventory page allows you to quickly navigate through all of your elements, sort, and perform bulk actions. The Inventory Explorer displays all the elements in your environment that were processed in the last hour. Elements are removed from the elements table roughly seven hours after an associated datasource is disabled.\nUse the Quick Bar Select the elements you’d like to edit using the checkboxes on the far left of each row. After a checkbox is selected, the Quick Bar appears.\nThen, select one of the following actions:\n View Metrics Add/Delete Tag Start/Stop Maintenance Delete Elements  Delete Elements Once you delete an element the metadata will be permanently removed. This cannot be undone. Historic time series data for that element will still be kept. If an element with the exact same metadata appears in Metricly, the available data for the element will be associated with it.\n Open the Inventory Explorer. Select the check box next to as many elements as desired. Click Delete Element(s) at the top of the Inventory Explorer table. . Click Yes, Delete.  Add Tags  Open the Inventory Explorer. Select the check box next to as many elements as desired. Click Add Tag at the top of the Inventory Explorer table. Type a Key and Value for the tag. An element can have multiple tags (up to 10), but keys cannot be used more than once. Click Confirm Changes. A summary of your changes will display. Click Save.  Delete/Edit tags  Open the Inventory Explorer. Select the check box next to as many elements as desired. Click Add Tag or Delete Tag at the top of the Inventory Explorer table. Type a key. Any elements that already have the tag will be highlighted blue in the Element(s) column. Type a value. If a tag already exists on an element, the value(s) will be replaced with the values you currently have typed. Click Confirm Changes. Click Save.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/rabbitmq-policies/",
	"title": "RabbitMQ Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#rabbitMQ"],
	"description": "",
	"content": "Policy names are prefixed with RabbitMQ –\n\r   Policy name Duration Conditions Category Description     Depressed Message Count 30 min rabbitmq.queue_totals.messages has a lower baseline deviation WARNING The number of messages across all queues has been lower than expected for at least the past 30 minutes.   Elevated Memory Usage 30 min rabbitmq.health.mem_used has an upper baseline deviation WARNING Memory usage has been higher than expected for at least the past 30 minutes.   Elevated Message Count 30 min rabbitmq.queue_totals.messages has an upper baseline deviation WARNING The number of messages across all queues has been higher than expectedfor at least the past 30 minutes.   Exceeded Disk Free Limit 5 min rabbitmq.health.disk_free has a metric threshold \u0026lt; rabbitmq.health.disk_free_limit CRITICAL Free disk space has dropped below the configured disk free space limit.   Exceeded Memory Limit 5 min rabbitmq.health.mem_used has a metric threshold \u0026lt; rabbitmq.health.mem_limit CRITICAL Memory utilization has exceeded the configured memory limit.   Memory Usage Approaching Limit 5 min metricly.aws.elb.unhealthyhostpercenthas a static threshold = 90% WARNING Memory utilization has reached 90% of the configured limit.   Unexpectedly Low Free Disk Space 30 min rabbitmq.health.disk_free has an lower baseline deviation WARNING Free disk space on the RabbitMQ node has been lower than expected for at least the past 30 minutes.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/range-widget/",
	"title": "Range Metric Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "Options for this widget type include: table, graph, bar.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-redshift/",
	"title": "Redshift Metrics",
	"tags": ["#aws", "#metrics", "#redshift"],
	"description": "",
	"content": " For each Redshift cluster, two types of elements are collected:\n RedshiftCluster: Contains cluster-specific metrics as well as metrics that are averages across all nodes. RedshiftNode: Contains node-specific metrics. There will be one element per Redshift node.  The table below denotes which metrics are cluster- or node-based (or both).\nCollected    Fully Qualified Name (FQN) Cluster Node AWS Metric Statistic Units Max BASE CORR UTIL     aws.redshift.cpuutilization yes yes CPUUtilization average percent 100 yes yes yes   aws.redshift.databaseconnections yes no DatabaseConnections average count none yes no no   aws.redshift.healthstatus yes no HealthStatus average  1 no no no   aws.redshift.maintenancemode yes no MaintenanceMode average  1 no no no   aws.redshift.networkreceivethroughput yes yes NetworkReceiveThroughput average Bps none yes yes no   aws.redshift.networktransmitthroughput yes yes NetworkTransmitThroughput average Bps none yes yes no   aws.redshift.percetagediskspaceused yes yes PercentageDiskSpaceUsed average percent 100 yes no yes   aws.redshift.readiops yes yes ReadIOPS average iops none yes yes no   aws.redshift.readlatency yes yes ReadLatency average seconds none yes yes no   aws.redshift.readthroughput yes yes ReadThroughput average Bps none yes yes no   aws.redshift.writeiops yes yes WriteIOPS average iops none yes yes no   aws.redshift.writelatency yes yes WriteLatency average seconds none yes yes no   aws.redshift.writethroughput yes yes WriteThroughput average Bps none yes yes no    Computed    Fully Qualified Name (FQN) Description Units BASE     netuitive.aws.redshift.totalthroughput This metric represents the total throughput, obtained by adding the read and write throughputs. Computation:(ReadThroughput + WriteThroughput) Bps yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/regex-guide/",
	"title": "Regex Guide",
	"tags": ["#alerts", "#notifications", "#events", "#policies", "#conditions", "#regex"],
	"description": "",
	"content": " Use Regex to Match Metric Conditions Regex uses all metrics that contain your input value. Typing aws.elb.httpcode.* would match both aws.elb.httpcode_backend_2xx, as well as netuitive.aws.elb.httpcodebackenderrorpercent.\n Exclude computed metrics using a ^ before the start of a metric name. Use Metric Tags to select a tag to further filter your condition.  We recommend testing any regular expressions that you create at https://regexr.com.\n\rMatch String Match the start and end of the string contained between ^ and $.\n Tag Key: ^Metricly$ Tag Value: ^true$  Matches the key-value pair Metricly = true\nMatch Multiple Variables Match multiple values separated by | between ( ).\n Tag Key: ^Name$ Tag Value: (my-server-one|my-server-two|my-server-three)  Matches any of the following key-value pairs:\n Name = my-server-one Name = my-server-two\n Name = my-server-three\n  Match Wildcard Match any character(s) using ., which acts as a wildcard.\n Tag Key: ^Name$ Tag Value: .Prod-app-1  Matches any value (e.g., Name = myProd-app-1, Name = yourProd-app-1) as long as Prod-app-1 followed:\nEscape Special Regex Characters Escape special regex characters . * / using a .\n Tag Key: ^Name$ Tag Value: my.server.one  Matches the key-value pair Name = my.server.one.\nFor a list of special regex characters you may have to escape, consult this page.\n\rMatch Entire Directory Match an entire website’s directory using .*\nQhttps://www.metricly.comE.*   Matches anything that comes after www.metricly.com The Q and E force the URL to be matched literally  Match Part of Directory Make the URL more specific to match everything from a particular part of the directory.\nQhttps://help.metricly.com/Content/Reports/E.*  Matches anything in the https://help.metricly.com/Content/Reports/directory - Match: https://help.metricly.com/Content/Reports/Cost/report_pic.png - Not a Match: https://help.metricly.com/Content/home.htm\nMatch Multiple Containers Match multiple containers between ( ) and separated by |. The following would match any of the following container IDs and exclude them from collection: abcdef123456, 123456abcdef, ghijkl789012.\nmetrics_blacklist = containers. (abcdef123456|123456abcdef|ghijkl789012)..*  Filter Exclusions Use a negative lookahead (?!) to specify a group that cannot match after the main expression\u0026ndash;if something matches, the result is discarded. The following would match anything but the _all, datastore, and docsindices and exclude them from collection.\nmetrics_blacklist = elasticsearch .indices.(?!_all$|datastore$|docs$)  Add Filter Add another index to a negative lookahead by placing the index name between | and $.\n(?!_all$|datastore$|docs$|myimportantindexname$)  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/reports/reports-resource-utilization/",
	"title": "Resource Utilization",
	"tags": ["#reports"],
	"description": "",
	"content": " The Resource Utilization report uses boxplots to provide simple visualizations of each of your element’s utilization. The types of boxplots shown are controlled by optional filters. Filters allow you to narrow the elements displayed by element name, element type, element tags, and element attributes.\nBoxplots are a standard way of displaying a distribution of data based on five values: the minimum, the lower quartile (25th percentile), the median, the upper quartile (the 75th percentile), and the maximum. Interquartile range (IQR) is the range between the lower quartile and upper quartile, represented by the width of the boxplot. The image below shows where each value is displayed in a boxplot.\nAvailable Views 1. Filters (Green): Contains several filters where you can search for element names, element types, tags, attributes, collectors, and more. Expand the More filter to see additional filters; select a filter to add it to the list of active filters. 2. Graph (Yellow): Displays the resource utilization for the selected metric and elements. Scroll over a boxplot to view the element it represents, as well as the minimum, lower quartile, median, upper quartile, and maximum values for that element’s utilization metric within the specified Time Frame setting. 3. View Options (Red): Use View Options to specify the utilization metric that’s used to provide the details in the graph; the number of boxplots displayed; sort boxplots by max, upper quartile, median, lower quartile, min, or interquartile range (IQR); and specify if the boxplots should be listed in ascending or descending order. See the following topics for more information on utilization metrics available for elements generated by some of the integrations Metricly provides:\n\rAmazon Metrics\n\rCollectd Metrics\n\rDiamond Metrics\n\rJava Metrics\n\rLinux Metrics\n\rWindows Metrics\n4. Time Frame Controls (Blue): The Time Frame controls the range of data displayed. To refresh data, click the refresh button.Selecting “1w” in the Time Frame displays the most recent week of data and/or elements. By selecting “Ending Now,” you can specify a range of data beginning with a date other than today. For more information, see Time Frame. The number of elements displayed on the Resource Utilization report is sensitive to the time frame setting i.e. an element that was available a week ago but not available now would show on the list when 1w is selected.\n\rFunctionality Widen Historical Scope Click Duration (past) and select a period of time. Selecting 1 hour displays the most recent hour of data. Pick Historical End Date Click Ending to specify an ending date other than today. View Sliding Window (Default) Data will automatically reload to reflect your changes.\nAssume that it is now 12:00 PM on January 8th. If the ending date in the Time Frame is set to today, selecting 1w allows you to view the most recent week of data. This means the data displayed is between 12:00 PM on January 1st and 12:00 PM on January 8th (now). Or, if you select 1h in the Time Frame, you can view data collected between 11:00 AM on January 8th and 12:00 PM on January 8th (now).\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/riemann/",
	"title": "Riemann",
	"tags": ["#riemann", "#integrations"],
	"description": "",
	"content": " Riemann is a powerful network monitoring tool that aggregates events from your servers and applications using streams to process them in a format that makes them easy to manipulate or summarize. You can forward your events collected by Riemann streams to Metricly. The Riemann integration is very different from most of the other integrations: the integration is configured in Riemann to send data to Metricly using our API.\nConfigure  Download the Metricly Riemann library. Place the metricly.clj file in the \u0026lt;riemann-directory\u0026gt;/etc directory, where \u0026lt;riemann-directory\u0026gt; is the location of your Riemann files. At the top of your riemann.config file (typically found at \u0026lt;riemann-directory\u0026gt;/etc/riemann.config), add:  (include \u0026quot;\u0026lt;riemann-directory\u0026gt;/etc/metricly.clj\u0026quot;)  4. At the bottom of the riemann.config file, add the following:\n(def metricly-forwarder (batch 100 1/10 (async-queue! :metricly-forwarder ; A name for the forwarder {:queue-size 1e4 ; 10,000 events max :core-pool-size 5 ; Minimum 5 threads :max-pools-size 100} ; Maximum 100 threads (riemann.metricly/metricly {:api-key \u0026quot;metricly -api-key\u0026quot; :type \u0026quot;Riemann\u0026quot;}))))  5. Update the :type setting as necessary. This setting controls the element display name in Metricly.\nThe :type setting will help provide a useful descriptor to your metrics. For example, if you’re using Riemann to pull in a group of metrics from your Elasticsearch instance, you could set the :type to myElasticsearchInstance.\n\r6. Replace the sample API key (metricly-api-key) with the API key from the Custom integration in your Metricly account.\n7. Below the new metricly-forwarder code, add:\n(streams metricly-forwarder )  This will start pushing events using the metricly-forwarder definition.\nOptional Configure Printing Events and Sending to the Log file In a new or existing stream, add the following to print all events to STDOUT and send events to the log.\n(streams prn #(info %) )  Filtering Events You can add additional qualifiers to the beginning of a stream to filter the events that are getting sent to Metricly.\nBelow is an example of filtering events that contain any of the listed tags for the service “web server”:\n(streams (where (and (service \u0026quot;web server\u0026quot;) (state \u0026quot;exception\u0026quot;)) (tagged \u0026quot;controller\u0026quot; (email \u0026quot;5551234567@txt.att.net\u0026quot;)) (tagged \u0026quot;view\u0026quot; (email \u0026quot;delacroix@trioptimum.com\u0026quot; \u0026quot;bronson@trioptimum.com\u0026quot;)) (tagged \u0026quot;model\u0026quot; (email \u0026quot;staff@vonbraun.mil\u0026quot;))))  Below is an example of usgin a regex to find all metrics that start with “riemann server” and forwards only the matching metrics.\n(streams (where (service #\u0026quot;riemann\\sserver.*\u0026quot;) metricly-forwarder ))  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/ruby-agent/",
	"title": "Ruby Agent",
	"tags": ["#ruby", "#integrations", "#agents"],
	"description": "",
	"content": " The Ruby Agent comprises three Ruby gems\u0026ndash;netuitived, netuitive_ruby_api, and netuitive_rails_agent\u0026ndash;that work in tandem to monitor the performance of your Ruby applications.\n netuitived: allows metrics to be exported to the Metricly API. netuitive_ruby_api: allows for easy integration with netuitived. netuitive_rails_agent: provides default Ruby on Rails metrics and sends them to netuitived using netuitive_ruby_api.  The Ruby Agent can also be tuned to help application performance and used to read garbage collection metrics. The flow-chart below details the flow of data from your application to Metricly.\nConfigure 1. Copy API Key From Ruby Integration  From the top navigation menu, select Integrations. Select the Ruby card. The name should be already populated, and Data Collection should be enabled. A unique API key for your account has already been generated. Copy the API Key.  2. Install Gems  Install the netuitived gem using the below command:  gem install netuitived  2. Run the start script once the gem has been installed:\nnetuitived start  3. Enter the desired element name into the prompt, then type into the prompt the unique API key generated for your account that you copied in step 1.\n Optionally, edit the** netuitived config/agent.yml** file if you wish to update the caching interval, use environment variables, change the host location instead of using the default, or want to adjust the logging configuration options.  4. Add the following line to the Gemfile in your rails application:\ngem 'netuitive_rails_agent'  6. Inside your rails application project directory, run the following code snippet to install both the netuitive_rails_agent and netuitive_ruby_api gems:\nbundle install  7. Restart your rails application and begin monitoring your data with Metricly.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-s3/",
	"title": "S3 Metrics",
	"tags": ["#aws", "#metrics", "#s3"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) AWS Metric Statistic Units BASE     Bucket Size Bytes aws.s3.bucketsizebytes BucketSizeBytes average GiB/KiB yes   Number of Objects aws.s3.NumberOfObjects NumberOfObjects average K yes   4xx Errors aws.s3.4xxerrors 4xxErrors average count yes   4xx Errors aws.s3.5xxerrors 5xxErrors average count yes   All Requests aws.s3.allrequests AllRequests average count yes   First Byte Latency aws.s3.firstbytelatency FirstByteLatency average miliseconds yes   Hard Requests aws.s3.headrequests HeadRequests average count yes   Total Request Latency aws.s3.totalrequestlatency TotalRequestLatency average miliseconds yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/snmp-interface-collector/",
	"title": "SNMP",
	"tags": ["#snmp", "#integrations", "#collectors"],
	"description": "",
	"content": " The SNMP Collector is used to allow Metricly to monitor the performance of SNMP-enabled devices using a set of specified OIDs. The collector can gather data from as many devices as necessary by adding additional configuration sections under the [devices] header.\nPrerequisites You should have SNMP set-up and your community string ready prior to activating the SNMP collector.\n Linux Agent  Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the SNMPCollector.conf file. Change the enabled setting to True. Change the my-identification-for-this-host header to the name of the host you want to monitor. Under the [[[oids]]] section, add additional OID-metric pairs list as necessary for the metrics you want Metricly to collect. Save the configuration file and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting SNMP metrics.   interval 60 How often the collector collects metrics (in seconds). The 60-second default may be taxing on your hardware. You may want to increase the collection interval to 120 seconds.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelistoption.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.   retries  Number of times the collector will retry before stopping.   timeout  Seconds before the SNMP connection will automatically timeout.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/snmp-collector/",
	"title": "SNMP Interface",
	"tags": ["#snmp", "#integrations", "#collectors"],
	"description": "",
	"content": " The Simple Network Management Protocol (SNMP) Interface collector is used to allow the Linux agent to monitor the performance of remote SNMP-enabled devices like routers and switches. The collector can gather data from as many devices as necessary by adding additional configuration sections under the [devices] header; see the example below for details.\nPrerequisites You should have SNMP set-up and your community string ready prior to activating the SNMP collector.\n Linux Agent  Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the SNMPInterfaceCollector.conf file. Change the enabled setting to True. Update the other settings as necessary, or add additional devices using the defaults as a guide. Save the configuration file and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting SNMP metrics.   path interface The file path to the SNMP Interface.   interval 60 How often the collector collects metrics (in seconds). Note The 60-second default may be taxing on your hardware. You may want to increase the collection interval to 120 seconds.   retries 3 Number of times the collector will retry before stopping.   timeout 5 Seconds before the SNMP connection will automatically timeout.   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelistoption.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/customize-notification-payloads/freemarker-sns-payloads/",
	"title": "SNS Payloads",
	"tags": ["#alerts", "#notifications", "#sns"],
	"description": "",
	"content": " SNS Payloads You must have AWS SNS setup in your console to use this payload type. The below payload returns the event category when active; once the event has cleared it returns CLEAR.\n{ \u0026quot;timestamp\u0026quot;: \u0026quot;${eventTimestamp}\u0026quot;, \u0026quot;category\u0026quot;: \u0026quot;\u0026lt;#if payloadType == 'event_cleared'\u0026gt;CLEAR\u0026lt;#else\u0026gt;${eventCategory.name}\u0026lt;/#if\u0026gt;\u0026quot;, \u0026quot;element\u0026quot;: \u0026quot;${elementFqn}\u0026quot;, \u0026quot;policy\u0026quot;: \u0026quot;${policyName}\u0026quot; }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/aws-integration/metrics/aws-metrics-sqs/",
	"title": "SQS Metrics",
	"tags": ["#aws", "#metrics", "#sqs"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) AWS Metric Statistic Units BASE     Approximate Age of Oldest Message aws.sqs.approximateageofoldestmessage ApproximateAgeOfOldestMessage average seconds yes   Approximate Number of Messages Delayed aws.sqs.approximatenumberofmessagesdelayed ApproximateNumberOfMessagesDelayed sum Count yes   Approximate Number of Messages Not Visible aws.sqs.approximatenumberofmessagesnotvisible ApproximateNumberOfMessagesNotVisible sum Count yes   Approximate Number of Messages Visible aws.sqs.approximatenumberofmessagesvisible ApproximateNumberOfMessagesVisible sum Count yes   Number of Empty Receives aws.sqs.numberofemptyreceives NumberOfEmptyReceives sum Count yes   Number of Messages Deleted aws.sqs.numberofmessagesdeleted NumberOfMessagesDeleted sum Count yes   Number of Messages Received aws.sqs.numberofmessagesreceived NumberOfMessagesReceived sum Count yes   Number of Messages Sent aws.sqs.numberofmessagessent NumberOfMessagesSent sum Count yes   Sent Message Size aws.sqs.sentmessagesize SentMessageSize average Bytes yes    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/salt/",
	"title": "Salt",
	"tags": ["#salt", "#integrations", "#configuration management"],
	"description": "",
	"content": " Salt (or SaltStack) is configuration management software that’s designed to automate infrastructure setup. Metricly’s formula will help get our Linux agent running on all of your minions quickly, so you can start seeing basic host data (as well as collector information if you so choose) for your whole environment using a single command.\nConfiguration  Add the netuitive-agent-formula to a directory on your Salt master.\n mkdir -p /metricly/formulas cd /metricly/formulas git clone https://github.com/netuitive/netuitive-agent-formula.git  Add the new directory to file_roots:   file_roots: base: - /srv/salt - /metricly/formulas/netuitive-agent-formula   Restart the Salt Master. Include the formula in an existing state tree or from a top file. Read more about this as well as about using formulas here. Copy the contents of our example salt pillar and merge it into your pillar file. Edit the default pillar settings as necessary, ensuring you maintain proper nesting and formatting. Replace the api_key value with the Linux integration API key from Metricly. To find this API key, point to the user account menu in the top right-hand corner of Metricly and select Integrations. Your Linux API key is found next to the integration listed as INFRASTRUCTURE. Run the init.sls script. Apply the formula to all of your salt minions.\n sudo salt '*' state.apply netuitive-agent   The pillar applies to your minions universally. If you want a minion to use a different version of a collector from a separate pillar file, you’ll need to specify which minion in your top.sls file. If you update the pillar file, you’ll need to reapply the pillar to your minions.   "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-element-tags-zorka/",
	"title": "Send Tags Via Zorka",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " Send Element Tags via Zorka Agent  Navigate to the zorka.properties file in your Java agent directory. Near the bottom of the file, uncomment the #netuitive.api.tags list and add tags following the below format:   netuitive.api.tags = name:value, second:value  3. Save the file.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/sensu/",
	"title": "Sensu",
	"tags": ["#sensu", "#integrations"],
	"description": "",
	"content": " Sensu is a monitoring tool that can create events to alert users about server failures, application health, and more. Sensu can be configured to send external events to Metricly. This feature is only compatible with Linux machines.\nHow to Send Events From Sensu  Hover on your account name in the top right-hand corner and click API Keys from the drop-down menu. Copy the API key from the custom integration in the table. Install the Metricly Event Handler. Download the Metricly Event Handler to the /bin directory.  sudo curl http://repos.app.metricly.com/cli -agent/metricly-event-handler-linux -o \u0026quot;/bin/metricly-event-handler\u0026quot;  5. Ensure the file is executable (use the chmod command).\n6. Create and configure the /etc/metricly/metricly-event-handler.yaml file using the API key you copied in step 2 and the URL to the events ingest API.\nurl: \u0026quot;https://api.app.metricly.com/ingest/events\u0026quot;  7. Create a handler in Sensu.\n8. Create a file named metricly_handler.json in etc/sensu/conf.d\n{ \u0026quot;handlers\u0026quot;: { \u0026quot;metricly-event-handler\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;pipe\u0026quot;, \u0026quot;command\u0026quot;: \u0026quot;/bin/metricly -event-handler stdin -s Sensu\u0026quot;, \u0026quot;severities\u0026quot;: [ \u0026quot;critical\u0026quot;, \u0026quot;ok\u0026quot; ] } } }  9. Create at least one check in Sensu.\n10. Restart the Sensu services to pick up the new check and handler.\n11. Check Metricly for your new Sensu events.\nExample To add a check to detect if the Linux Agent supervisor is running:\n Install the process checks script  sudo sensu-install -p process-checks:0.0.6  2. Create a file named check_linux-agent.json in etc/sensu/conf.d.\n{ \u0026quot;checks\u0026quot;: { \u0026quot;linux-agent\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;check-process.rb -p 'linux-agent - Handlers' -W 1 -C 1 -w 1 -c 1\u0026quot;, \u0026quot;standalone\u0026quot;: true, \u0026quot;interval\u0026quot;: 60, \u0026quot;handlers\u0026quot;: [\u0026quot;debug\u0026quot;, \u0026quot;metricly-event-handler\u0026quot;] } } }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/share-dashboard/",
	"title": "Share a Dashboard",
	"tags": ["#getting started", "#metrics", "#elements", "#dashboards"],
	"description": "",
	"content": " You can configure a dashboard to be either public or private. By default, dashboards you create are private.\nMake a Dashboard Public  Navigate to the Dashboards menu. Select All Dashboards \u0026gt; My Dashboards. A list of the dashboards you have created appears.  Toggle Shared to active (green) to make the dashboard public.  Make a Dashboard Private To make a dashboard private, repeat the above steps and toggle Shared to inactive (grey).\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/alerts-widget/",
	"title": "Single Metric Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "Options for this widget type include: map, heat map, and ticker.\nThe map option is currently limited to AWS integrations. Map alerts can be grouped via element or policies. See the Alerts User Guide for a full explanation of events and alerts, and their relationship to policies. "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/single-metric-widget/",
	"title": "Single Metric Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "Options for this widget type include: chart, gauge, value, and time series.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-slack/",
	"title": "Slack Notifications",
	"tags": ["#alerts", "#notifications", "#slack"],
	"description": "",
	"content": " Configuration 1. Install Incoming Webhooks on Slack If you’ve already installed the Incoming Webhooks app, you can skip to step 2.\n\r Go to Slack’s app directory. Search for Incoming Webhooks. It should dynamically update a drop-down beneath the search bar. Click Incoming Webhooks.  Click Add Configuration.  Select a channel from Choose a Channel… or create a new one.  Click Add Incoming WebHooks Integration.  2. Add an Integration to Slack  Log into your Slack client. Click your username in the top left-hand corner. A menu will open. Click Administration \u0026gt; Manage Apps.  Navigate to Custom Integrations. Click Incoming WebHooks. In the Customize Name section, type your desired name. We recommend naming it Metricly Event. Click Copy URL in the Webhook URL section. Click Save Settings at the bottom of the page.  3. Create a Slack Notification in Metricly If you want to display a custom message for your Slack notification, you’ll have to add and configure a Webhook notification instead, using the URL in 2.11 as your Webhook notification’s URL.\n\r Type a name for the Slack notification. We recommend naming it Slack-{yourChannelName} so it’s easy to find later.  Ensure the Enabled checkbox is selected. For Webhook URL, paste the URL you obtained from creating the Slack integration. Input a bot username that will be used when Metricly posts to your Slack channel. Click Test and Save to test the Slack notification. The test must return an HTTP code 200 to pass the validation. If the test succeeds, the notification will automatically save.  Optional Configuration Icons \u0026amp; Emojis You can customize the icon from slack by returning to the custom Webhook integration you’ve created and editing it. To distinguish your Metricly events in the chat, we recommend saving our logo to your computer and uploading it. You can also add an emoji or icon via Metricly when editing your notification.\nChannel Override Input a channel override. This can be a different channel (#other-channel), another user (@otheruser), or multiple users.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/solr/",
	"title": "Solr",
	"tags": ["#solr", "#integrations"],
	"description": "",
	"content": " Solr is an open source search platform, allowing for full-text search, hit highlighting, faceted search, and much more. Metricly can be used to monitor the performance of your Solr server.\nPrerequisites  Linux Agent  Configuration  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the SolrCollector.conf file. Change the enabled setting to True. Save the configuration file and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting Solr metrics.   byte_unit  Default numeric output(s).   core  Which cores the collector should report information on.   host  Hostname to collect from.   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelistoption.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.   port  Port to collect from.   stats  Types of stats reported from the collector. All options are enabled by default.    Stats Options  core: Stats on the different cores on your machine. response: Stats on ping response. query: Stats on query handling. update: Stats on update handling. cache: Stats on fieldValue, filter, document, and queryResult caches. jvm: Stats on the JVM. replication: Stats on replication.Values should be formatted as a comma separated list.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/inventory/inventory-sort-elements/",
	"title": "Sort Elements",
	"tags": ["#getting started", "#metrics", "#elements", "#inventory page"],
	"description": "",
	"content": "Select two or more elements and then click View Metrics to open multiple elements on the Metrics page. The Elements table initially has six columns:\n Type: Shows icon for an element’s type. You can see all the icons here. Name: Name of the element. Data Collection: The percentage of metrics that were collected in the last analytics cycle (5 minutes).If no metrics were collected, there could have been an issue with collection or too many metrics were collected, which forces Metricly to not collect any metrics. Collectors: The names of the collector(s) currently enabled on the element. Created: The date when the element was created in Metricly. Last Processed: The last time and/or date each element was processed by Metricly  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/inventory/inventory-startstop-maintenance/",
	"title": "Start or Stop Maintenance",
	"tags": ["#getting started", "#metrics", "#elements", "#maintenance", "#cli", "#inventory page"],
	"description": "",
	"content": "You can place elements into maintenance mode from the Inventory Explorer or via the Metricly CLI (Command Line Interface). While an element is in maintenance mode, learning for that element is disabled (i.e. no contextual or baseline bands will be displayed) and events will not be generated for the element.\n Open the Inventory Explorer. Select the check box next to as many elements as desired. Click Start or Stop Maintenance at the top of the Inventory Explorer table. A summary page displays. Select a duration via the Expire After dropdown.  Click Confirm.  If you do not want to set a duration for the maintenance mode, you can still return to the inventory page at a later time and manually end maintenance via selecting the elements and clicking the Stop Maintenance button.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/analytics/static-thresholds/",
	"title": "Static Thresholds",
	"tags": ["#getting started", "#analytics", "#metrics"],
	"description": "",
	"content": " Static Thresholds are unchanging levels that are compared against a metric’s current value.\nCreate Static Threshold conditions in policies to use static thresholds to monitor the elements in your environment. If the value of a metric is greater than, less than, greater than or equal to, less than or equal to, equal to, or not equal to the specified level of a Static Threshold condition (depending on the operator selected), then an event is generated.\nFor more information about using Static Threshold conditions, see Conditions.\nStatic Threshold Example If a Static Threshold level of greater than 80% is applied to a CPU utilization metric for a server element, then an event will be generated when the value of that metric is greater than 80%.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-stride/",
	"title": "Stride Notifications",
	"tags": ["#alerts", "#notifications", "#stride"],
	"description": "",
	"content": " Setting up alert notifications from Metricly to Stride just requires a few quick steps. Once complete, your alerts are forwarded to the designated chat room within Stride.\nConfiguration  Log in to Stride. Select a room where alerts should be delivered or create a new one.  Click Apps \u0026gt; Add Custom App.  Click API tokens and input Metricly Alerts in Specify a token name. Click Create. In the popup window, copy the access token and conversation URL. These are used in the Metricly DS creation form and needed for the cURL post in testing. Log into Metricly and navigate to Account \u0026gt; Notifications \u0026gt; Stride.  Provide the new notification with a name and paste the URL obtained in Stride.  You are now set up with Stride! Remember to invite all relevant users to the channel that you have configured to receive these alerts.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/analytics/sudden-change-detection/",
	"title": "Sudden Change Detection",
	"tags": ["#getting started", "#analytics", "#metrics"],
	"description": "",
	"content": " Sudden Change is a time-series metric used to analyze trends of historical data and make predictions based on past behavior.\nThis process finds an expected average of activity by generating data points every 5 minutes in a sliding, one-hour window of time. It then uses this data to make predictions on the next interval.\nWhen the future point is actualized and falls outside the expected prediction range, that interval is defined as a sudden change event. You can configure the scope of this metric’s prediction range by adjusting the acceptable percentage change of the future interval; doing so increases or decreases the sensitivity of your policy and affects the frequency of any associated alerts.\nSudden Change is useful for trend analysis on hourly min/max rollup data, like disk space usage or number of page hits. A best practice to consider when setting up a Sudden Change condition is to understand the average behavior of a metric beforehand. If the behavior is naturally prone to fluctuate, use a higher percentage. This widens the predictability scope, avoiding unnecessary policy activity and alerts.\nSudden Change Example 1 You are monitoring the response time for a transaction. The conditions for the policy are looking for increases in response time of more than 50%, with a duration of 2 hours. An event is generated after the response time has exceeded the average by 50% for that specified duration.\nConfiguring The Sudden Change Condition Complete the following steps to configure a new policy using the Sudden Change condition:\n Navigate to Alerts \u0026gt; + Add New Policy. Under the Conditions tab, select Add Condition \u0026gt; Add Metric Condition. In the Deviation(s) section, check Sudden Change.  Select Increase/Decrease by More Than. Enter a percentage value.   Sudden Change Example 2 The following graph depicts a policy with a sudden change deviation condition on a certain metric. In this example, an alert triggers due to a sudden change event (in red) on the 25th data point.\n Black Dots: Each black point represents 1 of the 24 previous 5-minute values (PT5M) of a metric Black Line: A best-fit regression line through the black points Blue Line: The projected trend of the 25th data point, based off of the historical data shown Blue Dot: The predicted value of the 25th data point Red Line: Breadth of sudden change, deviating from the expected projection in blue Red Dot: 25th data point’s actual observed value  This graph is for functionality demonstration and not found in the product. In Metricly, a red dot appears on the Metric Explorer graph where the sudden change event occurred.\n\rHow a Percent Drop is Measured A percent drop, or step change, is computed as:\n| (projected value) - (observed value) | / | (projected value) |\nThe sudden change algorithm returns this value for use by a condition in a policy. If the value exceeds the threshold in the policy condition, then the condition is true. If all the other conditions in the policy (if any) are also true, then an event is emitted.\nConfidence Validation Before reporting back the above value as a potential change, the algorithm performs several checks.\nOne of these checks is designed to determine if the regression model is a good enough fit for us to have any confidence in it’s projected value. Another check is used to add confidence that the observed value is sufficiently different from the projected value to be truly “anomalous”. Additional checks deal with detecting the trend in values leading up to the observed value. For example, if the trend was already negative and the actual observed value is just continuation of that trend, then no drop will be reported. The algorithm also requires data points to be consistently available and not be sparse.\nIn the above example, it is possible that some of these checks may have failed. In that case, the algorithm reports back that there was no drop.\nBest Practices When configuring a condition for sudden change deviation, we recommend setting a duration of no longer than 5 minutes. This is due to the nature of the event you are trying to capture: a single, sudden change in activity. Expecting a secondary sudden change in a longer duration of time may cause your policy to never activate, meaning you could miss otherwise genuine alerts.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/tcp-collector/",
	"title": "TCP",
	"tags": ["#snmp", "#integrations", "#collectors"],
	"description": "",
	"content": " The TCP Collector collects metrics on TCP stats.\nPrerequisites  Linux Agent  Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the TCPCollector.conf file. Change the enabled setting to True. Save the configuration file and restart the Linux Agent.  Collector Options    Setting Default Description Type     allowed_names ListenOverflows, ListenDrops, TCPLoss, TCPTimeouts, TCPFastRetrans, TCPLostRetransmit, TCPForwardRetrans, TCPSlowStartRetrans, CurrEstab, TCPAbortOnMemory, TCPBacklogDrop, AttemptFails, EstabResets, InErrs, ActiveOpens, PassiveOpens list of entries to collect, empty to collect all str   byte_unit byte Default numeric output(s) str   enabled False Enable collecting these metrics bool   gauges CurrEstab, MaxConn list of metrics to be published as gauges str   measure_collector_time False Collect the collector run time in ms bool   metrics_blacklist None Regex to match metrics to block. Mutually exclusive with metrics_whitelist NoneType   metrics_whitelist None Regex to match metrics to transmit. Mutually exclusive with metrics_blacklist NoneType    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/table-widget/",
	"title": "Table Widget",
	"tags": ["#getting started", "#metrics", "#widgets", "#dashboards"],
	"description": "",
	"content": "More writeup coming soon. Here\u0026rsquo;s what it looks like: "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/tomcat/",
	"title": "Tomcat",
	"tags": ["#tomcat", "#integrations"],
	"description": "",
	"content": " Tomcat (also known as Apache Tomcat or Tomcat Server) is an open source Java Servlet Container. You can use Metricly’s Java agent to collect information on your Tomcat Server.\nPrerequisites  Java Agent  Configure  Navigate to the zorka.properties file. Comment out the Default collection scripts section.  # Default collection of jvm metrics # scripts = jvm.bsh  3. Uncomment the Apache Tomcat scripts section.\n# Example: Apache Tomcat configuration with CAS server scripts = jvm.bsh, zabbix.bsh, apache/tomcat.bsh, apps/cas.bsh  5.Configure Tomcat to load the Java agent. This is often configured via the setenv.sh or tomcat.conf files.\n6. Restart your app server.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/top-violators/",
	"title": "Top Violators",
	"tags": ["#alerts", "#notifications", "#events", "#policies"],
	"description": "",
	"content": "Top Violators reports display the elements in your environment that have triggered the most events within the specified Time Frame setting, allowing you to quickly locate the elements with high event counts. This report provides the same type of data as the Event Explorer, but the data is grouped by element.\n Summary Table: This table provides both the number of events triggered by each element (Event Count), and the amount of time that each element triggered events within the specified Time Frame. Click the Element’s name to view the element’s Element Detail panel, or click the event count to view events in the Event Explorer.  For example, if the Event Count for an element is 50 and the Time Violating During 7 Days is one hour, then the element triggered 50 events in one hour during the past 7 days.\n\r Filters: Contains several filters where you can search for element names, element types, tags, attributes, collectors, and more. Expand the More filter to see additional filters; select a filter to add it to the list of active filters. Time Frame Controls: The Time Frame controls the range of data displayed. To refresh data, click the refresh button.Selecting “1w” in the Time Frame displays the most recent week of data and/or elements. By selecting “Ending Now,” you can specify a range of data beginning with a date other than today. For more information, see Time Frame. Pie Chart: The pie chart shows the total number of events by category for all elements that triggered an event within the specified Time Frame setting.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/metrics/metrics-troubleshooting/",
	"title": "Troubleshooting",
	"tags": ["#getting started", "#metrics"],
	"description": "",
	"content": " Collected Metrics If you are seeing metrics that will not collect continually, there are two common scenarios: - Your agent-based (Linux, Windows) collector has metrics that are not available anymore being collected - Your agentless-based collector (AWS, Azure) is collecting metrics from a service that’s not being used, e.g., a lambda function not firing or an SQS queue is empty.\nRemoving these metrics from being collected is the optimal solution.\nRemove via Agent Based Collector Use a metric whitelist or blacklist for agent-based collectors\nExample Blacklist you could use a negative lookahead (?! ) to specify a group that cannot match after the main expression\u0026ndash;if something matches, the result is discarded: metrics_blacklist = elasticsearch.indices.(?!_all$|datastore$|docs$)\nRemove via Agentless Collector Tweak your filtering in Metricly; if that does not work, you may be experiencing ingestion issues.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-troubleshooting/",
	"title": "Troubleshooting",
	"tags": ["#windows", "#integrations"],
	"description": "",
	"content": "  Logs are written to C:\\ProgramData\\CollectdWin\\CollectdWin.log by default. Errors are written to the Event Log.  To adjust the log file level, edit the line below near the end of the CollectdWinService.exe.config:\n Navigate to C:\\Program Files\\CollectdWin\\config or C:\\Program Files (x86)\\CollectdWin\\config. Edit\u0026lt;logger name=\u0026quot;*\u0026quot; writeTo=\u0026quot;default\u0026quot; minlevel=\u0026quot;[Trace/Debug/Info/Warn/Error/Fatal]\u0026quot; /\u0026gt;. Save file.  Windows Server 2003 If you are monitoring a Windows Server 2003 instance and are having trouble seeing data in Metricly, you may need to install a hotfix from Microsoft. In August 2016, AWS disabled an SSL cipher in their standard ELB policy that was the last supported SSL cipher that comes with Windows Server 2003 by default. Microsoft has created a hotfix (Windows Server 2003 R2 32Bit and 64Bit) to add more modern ciphers to your OS, which will fix the issue. The hotfix can be found here.\nVersions of the Windows Agent later than v0.7.4.55 do not support Windows Server 2003.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-uninstall/",
	"title": "Uninstall",
	"tags": ["#windows", "#integrations", "#uninstall"],
	"description": "",
	"content": " Open the Programs and Features list. Right click the CollectdWinService (64 bit) program.  Click Uninstall. If any prompt appears, click Yes to confirm that you want to delete the program.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-uninstall/",
	"title": "Uninstall Agent",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " How to Uninstall  Remove any JVM startup references to the Netuitive Java Agent.  java -javaagent:/opt/netuitive-zorka/netuitive.jar=/opt/netuitive-zorka -jar zorka-core-test.jar -- service   Delete all Netuitive Java Agent (netuitive-zorka-{version}) files.  If you instrumented metrics using the jvm.bsh script, you will need to remove the references to the script as well.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/windows-agent-upgrade/",
	"title": "Upgrade Agent",
	"tags": ["#windows", "#integrations", "#install"],
	"description": "",
	"content": "To upgrade the Windows agent, follow the installation steps listed on the main Windows Integration page using the version of the agent you wish to upgrade to. The latest versions of the agent can be downloaded from the agent repo and details of the releases can be found on the Github project page.\nInstalling a new version of the agent will overwrite changes you have made to existing agent configuration files located in C:\\Program Files\\CollectdWin\\config or C:\\Program Files (x86)\\CollectdWin\\config depending on your environment. To preserve those changes, it is recommended you create backups of the files prior to upgrading.\n\r"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-upgrade/",
	"title": "Upgrade Java",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " How to Upgrade  Download the latest Java agent here. Copy the new netuitive.jar file to your existing Java agent files to replace the old netuitive.jar file. Optionally, manually merge the new zorka.properties file with the old file to receive any new fields or settings.  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/collectd/collectd-uptime-metrics/",
	"title": "Uptime Metrics",
	"tags": ["#collectd", "#integrations", "#metrics", "#uptime", "#collectors"],
	"description": "",
	"content": " Collected    Fully Qualified Name(FQN) Description Statistic Units Min Max Sparse Data Strategy(SDS) BASE CORR UTIL     uptime.uptime.value Number of seconds since the system was last booted. max seconds 0 none none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/java-agent/java-calculator-app/",
	"title": "Use Calculator App",
	"tags": ["#java", "#integrations", "#agents"],
	"description": "",
	"content": " To to run the calculator app with the zorka agent, use the following command:\njava -javaagent:/opt/netuitive-zorka-agent/netuitive.jar=/opt/netuitive-zorka-agent/ -jar /opt/zorka-core-test.jar  Calculator.java Source package com.netuitive.agent.test; public class Calculator { public Integer calculate(String operator, Integer first, Integer second) { if (operator.equals(“+”)) { return add(first, second); } else if (operator.equals(“-“)) { return minus(first, second); } else if (operator.equals(“*”)) { return multiply(first, second); } else if (operator.equals(“/”)) { return divide(first, second); } else { throw new IllegalArgumentException(“‘” + operator + “‘ is not supported, use one of [+|-|*|/] operators”); } } private Integer add(Integer first, Integer second) { return first + second; } private Integer minus(Integer first, Integer second) { return first – second; } private Integer multiply(Integer first, Integer second) { return first * second; } private Integer divide(Integer first, Integer second) { return first / second; } }  Example Below is an example file called calculator.bsh that instruments metrics based on basic calculator operation method calls. When a user inputs an operator, the application will fetch the argument, calculate the result, and log the action into the Zorka Log file. Once the actions are submitted to the agent on the Java server, Metricly will create a metric for each input into the ${operator} parameter (e.g., a metric for +, -, *, and /).\n// Call zorka.require(...) to load additional scripts that this one depends on. zorka.require(\u0026quot;jvm.bsh\u0026quot;); // Simulate namespace. __calculator() { // Define JMX bean to host method call stats. _mbean = “zorka:type=ZorkaStats,name=CalculatorStats”; // Add the spy definition to instrument method “calculator” // of “com.netuitive.agent.test.Calculator” class. // The “calculate” method call statistics (calls, errors, time) // are grouped/keyed by the method’s first argument (“operator”). spy.add(spy.instrument(“CALCULATOR”) .onEnter( spy.fetchArg(“operator”, 1), spy.zorkaLog(“INFO”, “CALCULATOR”, “${operator}”)) .onSubmit( spy.zorkaStats(“java”, _mbean, “stats”, “${operator}”)) .include(spy.byMethod(“com.netuitive.agent.test.Calculator”, “calculate”)) ); return this; } calculator = __calculator();  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/user-scripts-collector/",
	"title": "User Scripts Collector",
	"tags": ["#user scripts", "#integrations"],
	"description": "",
	"content": " The User Scripts Collector runs external scripts and collects their output for you to view in Metricly.\nPrerequisites  Linux Agent  Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the UserScriptsCollector.conf file. Change the enabled setting to True. Update scripts_path with the directory where your scripts are located (default: /opt/netuitive-agent/). Save the configuration file and restart the Linux Agent.  About Scripts For the collector to work properly, your monitored scripts must be executable and should output metrics in the form of:\nmetric.path.a value metric.path.b value metric.path.c value  Value can be a static integer or the value stored in a variable;only numerical values are valid.\nExamples Checks Status of Metricly-Agent Service This example checks the status of the metricly-agent service and outputs the value of 1 if it is running or 0 if it is not running. The value is stored in the processes-running.netuitive-agent.count.value metric.\n#!/bin/sh procscnt=`ps aux | grep -c \u0026quot;[n]etuitive-agent - Handlers\u0026quot;` echo processes-running.netuitive-agent.count.value $procscnt   Sets the procscnt variable to the value output by the command ps aux | grep -c “[n]etuitive-agent – Handlers” Returns the metric, processes-running.netuitive-agent.count.value, with the value stored in the variable proscnt.  Checks Total Running Processes \u0026amp; Threads This example checks for total running processes and total running threads every 60 seconds.\n#!/bin/sh PROCTOTAL=`ps -A --no-headers | wc -l` PROCTHREADS=`ps -AL --no-headers | wc -l` echo processes.total_processes.count.value $PROCTOTAL echo processes.total_threads.count.value $PROCTHREADS  Counts Log Occurrences This example acknowledges a log every 60 seconds and count how many times a string shows in a log. This script is used to count log occurrences and converts that number into a metric.\n#!/bin/sh CHECKCOUNT=(awk -v d1=\u0026quot;$(date --date=\u0026quot;-1 min\u0026quot; \u0026quot;+%b %_d %H:%M\u0026quot;)\u0026quot; -v d2=\u0026quot;$(date \u0026quot;+%b %_d %H:%M\u0026quot;)\u0026quot; '$0 \u0026gt; d1 \u0026amp;\u0026amp; $0 \u0026lt; d2 || $0 ~ d2' /var/log/secure | grep -ci \u0026quot;POSSIBLE BREAK-IN ATTEMPT\u0026quot;) echo possible_sudo_hacks.count.value $CHECKCOUNT  Collector Options    Option Default Description     enabled False Enable collecting User Scripts metrics.   scripts_path /opt/netuitive-agent/ Path used to find scripts to run   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_blacklist  Regex list to match metrics to block. Mutually exclusive with metrics_whitelist option.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklistoption.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-victorops/",
	"title": "VictorOps Notifications",
	"tags": ["#alerts", "#notifications", "#victorops"],
	"description": "",
	"content": " Configuration 1. Copy REST API URL From VictorOps  Login to your VictorOps account. Navigate to Alert Behavior \u0026gt; Integrations.  Search for Metricly and select the card.  Click Enable Integration. Copy the Service API Endpoint. This is required for the next step.   2. Create a Webhook notification in Metricly  In Metricly, navigate to the Policy Editor. Click tab 3, Notifications. Click Add Notification and select Webhook as the Notification Type. Provide a name for the webhook notification. Choose your re-notification frequency. Click New Webhook. Name the Webhook. For URL, paste the Service API Endpoint from VictorOps.  Provided a username and password if required. Click Test and Save. The endpoint URL must return an HTTP code 200 to pass the validation.\n\r Click Save.  Optional Configuration Headers Add one or more headers (key-value pairs) to the webhook notification.\nCustom Payload Select Custom from the Payload drop-down menu. A text field will open after selecting Custom. You can use the following variables and/or VictorOps fields to make your notification more dynamic.\nExample The below example sends a notification that states the event’s category name, the name and ID of the element in violation, and the policy name of the violating element. Once the event has ended, it sends a RECOVERY notification stating the time that the event ended.\n{ \u0026quot;message_type\u0026quot;:\u0026quot;\u0026lt;#if payloadType == \u0026quot;event\u0026quot;\u0026gt;${eventCategory.name}\u0026lt;/#if\u0026gt;\u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;RECOVERY\u0026lt;/#if\u0026gt;\u0026quot;, \u0026quot;entity_id\u0026quot;:\u0026quot;${elementId}\u0026quot;, \u0026quot;entity_display_name\u0026quot;:\u0026quot;${elementName}\u0026quot;, \u0026quot;state_message\u0026quot;:\u0026quot;\u0026lt;#if payloadType == \u0026quot;event\u0026quot;\u0026gt; [${elementName}] [${policyName}] [${eventTimestamp}] : ${policyDescription}\u0026lt;/#if\u0026gt;\u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;The policy ${policyName} has CLEARED for ${elementName} and is no longer generating events as of ${eventTimestamp}\u0026lt;/#if\u0026gt;\u0026quot; }  VictorOps Fields You can visit the VictorOps knowledge base for more information.\n   Field Name Description     message_type String value. This field allows the following values: INFO, WARNING, ACKNOWLEDGMENT, CRITICAL, RECOVERY.   entity_id String value. The name of the alerting entity.   timestamp Number value. Timestamp of the alert in seconds since epoch.   state_start_time Number value. The time the entity entered its current state (in seconds since epoch).   state_message String value. Any additional status information from the alert.   monitoring_tool String value. The name of the monitoring system software/application.    Freemarker Variables    Variable Description     ${elementFqn} The Fully Qualified Name (FQN) of the element.   ${elementId} The type of element (e.g., SERVER, ELB, EC2, RDS, etc.).   ${elementLocation} The location of the element.   ${elementName} The friendly name for the element.   ${elementType} The type of element (e.g, SERVER, ELB, RUBY, etc.)   ${event.data.results} The description of the event as a policy violation.   ${event.id} The ID of the event   ${eventCategory.name} The event category ( (Info), (Warning), or (Critical)).   ${eventTimestamp} The time (in UTC) the event occurred.   ${policyDescription} The description of the policy that generated the event.   ${policyId} The policy identification number.   ${policyName} The name of the policy.    { \u0026quot;message_type\u0026quot;:\u0026quot;INFO\u0026quot;, \u0026quot;entity_is_host\u0026quot;:\u0026quot;Yes\u0026quot;, \u0026quot;entity_id\u0026quot;:\u0026quot;${elementId}\u0026quot;, \u0026quot;state_message\u0026quot;:\u0026quot;${elementName} is up, but an event occurred at ${eventTimestamp}.\u0026quot; }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/webhook-integration/",
	"title": "Webhook Integration",
	"tags": ["#webhook", "#integrations"],
	"description": "",
	"content": " Webhooks are an HTTP/HTTPS callback request sent to a desired URL in response to some event, which could be pushing code to a repository or a comment being posted in an online community. A Webhook integration can be used to generate external events in Metricly’s Event Explorer, meaning you could create policies based on the content of those messages.\nConfigure  From the top navigation menu, select Integrations. Select the Webhook card. The name should be already populated, and Data Collection should be enabled. Copy the API key.\n Select an element from your inventory to associate the Webhook events with. Post to Metricly’s API using the URL included in the instructions.  Metricly recommends using your Webhook external events as a basis for a policy using external event conditions.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/customize-notification-payloads/webhook-payloads/",
	"title": "Webhook Payloads",
	"tags": ["#alerts", "#notifications", "#webhook"],
	"description": "",
	"content": " Webhook Payloads Webhooks have two main payload types: inbound and outbound. Outbound payloads can be customized and sent as notifications.\nTo create a customized webhook payload:\n Navigate to your Account Profile \u0026gt; Notifications \u0026gt; Webhook. Click + Add Webhook. Fill out all fields; select Custom from the Payload dropdown. Input your custom JSON + Freemarker writeup. Save.  Example 1\n{ \u0026quot;message_type\u0026quot;:\u0026quot;\u0026lt;#if payloadType == \u0026quot;event\u0026quot;\u0026gt;${eventCategory.name}\u0026lt;/#if\u0026gt;\u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;RECOVERY\u0026lt;/#if\u0026gt;\u0026quot;, \u0026quot;entity_id\u0026quot;:\u0026quot;${elementId}\u0026quot;, \u0026quot;entity_display_name\u0026quot;:\u0026quot;${elementName}\u0026quot;, \u0026quot;state_message\u0026quot;:\u0026quot;\u0026lt;#if payloadType == \u0026quot;event\u0026quot;\u0026gt; [${elementName}] [${policyName}] [${eventTimestamp}] : ${policyDescription}\u0026lt;/#if\u0026gt;\u0026lt;#if payloadType == \u0026quot;event_cleared\u0026quot;\u0026gt;The policy ${policyName} has CLEARED for ${elementName} and is no longer generating events as of ${eventTimestamp}\u0026lt;/#if\u0026gt;\u0026quot; }  Example 2\n{\u0026quot;text\u0026quot;: \u0026quot;${eventTimestamp}: The CPU on ${elementId} has exceeded 5% for at least 5 minutes. \\n Event Category: ${eventCategory.name} \\n Fqn: ${elementFqn} \\n location: ${elementLocation}\u0026quot;}  Example 3\n[ { \u0026quot;source\u0026quot;:\u0026quot;Scality Tenant Alert\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;${policyName}\u0026quot;, \u0026quot;tags\u0026quot;: [ { \u0026quot;name\u0026quot;:\u0026quot;Event Tag\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;External\u0026quot; } ], \u0026quot;type\u0026quot;: \u0026quot;INFO\u0026quot;, \u0026quot;data\u0026quot;: { \u0026quot;elementId\u0026quot;: \u0026quot;${elementId}\u0026quot;, \u0026quot;level\u0026quot;: \u0026quot;WARNING\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;${policyDescription}\u0026quot; } } ]  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/notifications/notifications-webhooks/",
	"title": "Webhooks Notifications",
	"tags": ["#alerts", "#notifications", "#webhooks"],
	"description": "",
	"content": " There are two main uses for webhooks: pushing data into metricly (inbound) and pulling data like notifications out (outbound).\n Inbound: Achieved via POST URL that can be found on the Webhook integration card. Outbound: Used by several of our notification integrations and accessible through the Webhook GET API endpoint.  For a great example of an inbound webhook usecase, see how we pushed CloudWatch Logs into Metricly.\nWhen using the outbound method, you can customize the JSON payload using the freemarker markup language from Account \u0026gt; Notifications \u0026gt; Webhook.\nConfiguration Add a Webhook Notification  In Metricly, navigate to the Policy Editor. Click tab 3, Notifications. Click Add Notification and select Webhook as the Notification Type. Provide a name for the webhook notification. Choose your re-notification frequency. Click New Webhook. Name the Webhook. For URL, copy and paste the webhook’s payload URL that should receive notifications. Click Test to test the webhook. The endpoint URL must return an HTTP code 200 to pass the validation. Click Save.  Optional Configuration Headers Add one or more headers (key-value pairs) to the webhook notification.\nCustom Payloads Select Custom from the Payload drop-down menu. A text field will open after selecting Custom. Create a custom JSON payload in the textbox. You can use the following variables to make your notification more dynamic.\n   Variable Description     ${elementFqn} The Fully Qualified Name (FQN) of the element.   ${elementId} The type of element (e.g., SERVER, ELB, EC2, RDS, etc.).   ${elementLocation} The location of the element.   ${elementName} The friendly name for the element.   ${elementType} The type of element (e.g, SERVER, ELB, RUBY, etc.)   ${event.data.results} The description of the event as a policy violation.   ${event.id} The ID of the event   ${eventCategory.name} The event category ( (Info), (Warning), or (Critical)).   ${eventTimestamp} The time (in UTC) the event occurred.   ${policyDescription} The description of the policy that generated the event.   ${policyId} The policy identification number.   ${policyName} The name of the policy.    Examples PagerDuty { \u0026quot;service_key\u0026quot;: \u0026quot;\u0026lt;your service key here from pager duty\u0026gt;\u0026quot;, \u0026quot;incident_key\u0026quot;: \u0026quot;${policyName} \u0026quot;, \u0026quot;event_type\u0026quot;: \u0026quot;trigger\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;${category}: ${elementFqn} : ${policyName}\u0026quot;, \u0026quot;client\u0026quot;: \u0026quot;Metricly Cloud Service\u0026quot;, \u0026quot;client_url\u0026quot;: \u0026quot;https://app.Metricly.com\u0026quot;, \u0026quot;details\u0026quot;: { \u0026quot;category\u0026quot;: \u0026quot;${category}\u0026quot;, \u0026quot;elementFqn\u0026quot;:\u0026quot;${elementFqn}\u0026quot;, \u0026quot;elementType\u0026quot;: \u0026quot;${elementType}\u0026quot; }, \u0026quot;contexts\u0026quot;: [{ \u0026quot;type\u0026quot;: \u0026quot;link\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;https://app.Metricly.com/#/element/${elementId}/events\u0026quot; }] }  Microsoft Teams { \u0026quot;service_key\u0026quot;: \u0026quot;\u0026lt;your service key here from pager duty\u0026gt;\u0026quot;, \u0026quot;incident_key\u0026quot;: \u0026quot;${policyName} \u0026quot;, \u0026quot;event_type\u0026quot;: \u0026quot;trigger\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;${category}: ${elementFqn} : ${policyName}\u0026quot;, \u0026quot;client\u0026quot;: \u0026quot;Metricly Cloud Service\u0026quot;, \u0026quot;client_url\u0026quot;: \u0026quot;https://app.Metricly.com\u0026quot;, \u0026quot;details\u0026quot;: { \u0026quot;category\u0026quot;: \u0026quot;${category}\u0026quot;, \u0026quot;elementFqn\u0026quot;:\u0026quot;${elementFqn}\u0026quot;, \u0026quot;elementType\u0026quot;: \u0026quot;${elementType}\u0026quot; }, \u0026quot;contexts\u0026quot;: [{ \u0026quot;type\u0026quot;: \u0026quot;link\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;https://app.Metricly.com/#/element/${elementId}/events\u0026quot; }] }  Slack { \u0026lt;#if iconEmoji??\u0026gt; \u0026quot;icon_emoji\u0026quot;:\u0026quot;${iconEmoji}\u0026quot;, \u0026lt;#else\u0026gt; \u0026lt;#if iconUrl??\u0026gt; \u0026quot;icon_url\u0026quot;:\u0026quot;${iconUrl}\u0026quot;, \u0026lt;#else\u0026gt; \u0026quot;icon_url\u0026quot;:\u0026quot;url.png\u0026quot;, \u0026lt;/#if\u0026gt; \u0026lt;/#if\u0026gt; \u0026lt;#if username??\u0026gt; \u0026quot;username\u0026quot;: \u0026quot;${username}\u0026quot;, \u0026lt;#else\u0026gt; \u0026quot;username\u0026quot;: \u0026quot;Event\u0026quot;, \u0026lt;/#if\u0026gt; \u0026lt;#if channel??\u0026gt; \u0026quot;channel\u0026quot;:\u0026quot;${channel}\u0026quot;, \u0026lt;/#if\u0026gt; \u0026quot;attachments\u0026quot;:[ { \u0026quot;fallback\u0026quot;:\u0026quot;Netuitive Policy Violation:\u0026quot;, \u0026quot;pretext\u0026quot;:\u0026quot;*Netuitive Policy Violation:*\u0026quot;, \u0026quot;title_link\u0026quot;:\u0026quot;https://www.netuitive.com\u0026quot;, \u0026quot;color\u0026quot;:\u0026quot;${color}\u0026quot;, \u0026quot;mrkdwn_in\u0026quot;:[ \u0026quot;fields\u0026quot;, \u0026quot;pretext\u0026quot; ], \u0026quot;fields\u0026quot;:[ { \u0026quot;title\u0026quot;:\u0026quot;${policyName}\u0026quot;, \u0026quot;value\u0026quot;:\u0026quot;*Element*: ${elementName} \\n *Type:* ${elementType}\\n *Category:* ${eventCategory.name}\u0026quot;, \u0026quot;short\u0026quot;:true }, { \u0026quot;title\u0026quot;:\u0026quot;Click here to modify the Policy:\u0026quot;, \u0026quot;value\u0026quot;:\u0026quot;\u0026lt;${baseUrl}/policies/${policyId}|${policyName}\u0026gt; \\n *Click here to browse the Metrics:* \\n \u0026lt;${baseUrl}/metrics?event_id=\u0026lt;#if event.id??\u0026gt;${event.id}\u0026lt;/#if\u0026gt;\u0026amp;timeRangeDuration=14400\u0026amp;endTime=${timestamp?datetime?string.iso}|Metric Details\u0026gt;\u0026quot;, \u0026quot;short\u0026quot;:true }, { \u0026quot;title\u0026quot;:\u0026quot; \u0026quot;, \u0026quot;value\u0026quot;:\u0026quot;\\n *Violation:* \u0026lt;#if event.data??\u0026gt;\u0026lt;#if event.data.results??\u0026gt;\u0026lt;#assign results = event.data.results?eval\u0026gt;\u0026lt;#if results.conditions??\u0026gt;\u0026lt;#list results.conditions as condition\u0026gt;\u0026lt;#if condition?counter \u0026lt;= 5\u0026gt;${condition.expression}\u0026lt;/#if\u0026gt;\u0026lt;/#list\u0026gt;\u0026lt;/#if\u0026gt;\u0026lt;/#if\u0026gt;\u0026lt;/#if\u0026gt;\u0026quot;, \u0026quot;short\u0026quot;:false }, { \u0026quot;title\u0026quot;: \u0026quot; \u0026quot;, \u0026quot;value\u0026quot;:\u0026quot;\\n *Description:* ${policyDescription!\u0026quot;No description provided\u0026quot;}\u0026quot;, \u0026quot;short\u0026quot;:false } ], \u0026quot;footer\u0026quot;: \u0026quot;Netuitive Event Message\u0026quot;, \u0026quot;footer_icon\u0026quot;: \u0026quot;url.png\u0026quot;, \u0026quot;ts\u0026quot;: ${timestampSeconds?c} } ] }  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/data-visualization/dashboards/widgets/",
	"title": "Widgets",
	"tags": ["#getting started", "#directory page", "#user guide", "#widgets"],
	"description": "",
	"content": " This guide includes a list of all widget types available, their options, and the actions you can take. To take full advantage of widgets, you should strategize how to tag, group, and visualize the data in your environment. General knowledge on elements and the behavior of your metrics is strongly encouraged before making a custom dashboard.\nMove Widgets  Hover over the widget’s title to select. The header turns gray and your cursor is replaced with \rwhen a widget is selected. Drag widget to desired position.  Resize Widgets  Hover over a widget to select. Arrows appear in the bottom left and right corners when a widget is selected.  Drag corners to resize.  Widget Controls Create  Navigate to a custom or copied dashboard. Click + Add a Widget. Click Add on the widget type you want to use. Determine its scope, attributes, displayed metrics, and widget name. These settings vary for each widget type. Click Save.  Edit  Click the green Ellipsis on a widget. Click Settings. Edit the values to your liking. Click Save.  Copy  Click the green Ellipsis on a widget. Click Copy. Update the values if necessary. Rename the widget. Click Save.  Delete  Click the green Ellipsis on a widget. Click Delete Widget. Confirm by clicking Yes, Delete.  Notify Receive daily or weekly emails that snapshot widget data (limited to the table widget).\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/agents/windows-agent/",
	"title": "Windows Agent",
	"tags": ["#windows", "#integrations", "#agents"],
	"description": "",
	"content": " The Metricly Windows Agent is a Microsoft Windows service that collects, aggregates, and publishes windows performance counters and attributes. Microsoft SQL Server, IIS, and .NET metrics are native to our Windows Agent. Only one Windows integration in your account is necessary to receive all Windows-related metrics.\nConfigure Installation is as easy as executing an MSI installer and configuring the service. The agent is pre-configured to send the most important performance metrics, windows events, and system attributes to Metricly. It can also be configured to send additional or different data if required\n1. Copy the API key  In Metricly, click Integrations on the top-nav bar. Search for and click the Windows Server card. The name should be already populated, and Data Collection should be enabled. A unique API key for your account has already been generated. Copy the API key.  2. Install the Windows Agent If you install our Windows agent on an AWS EC2 or Azure VM, the EC2’s / VM’s power state (it will come in as the attribute hostRunning with a value of true or false) and tags are copied over to the corresponding Windows WINSRV element. You can then use this information to create policies.\n Download the latest Windows agent. Ensure you download the correct version for your environment. Open a command line interface and change to the directory you downloaded the Windows agent to. Run the following command:  msiexec /quiet /package CollectdWin-x64.msi NETUITIVE_API_KEY=my_api_key   my_api_key is the unique API key generated for your account that you copied in step 1.  3. Set up a proxy (Optional) Optionally, if you have a web proxy in your environment, you may need to configure the agent to use it.\n4. Start the agent  Open the Windows Service Control Manager. Select the CollectdWinService. Start the service.  If the service is already running, you’ll need to restart it for any configuration changes to take effect.\n"
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/checks/windows-checks/",
	"title": "Windows Checks",
	"tags": ["#alerts", "#notifications", "#checks", "#windows"],
	"description": "",
	"content": " Enable Windows Checks  Make sure the Windows agent is installed. Metricly checks can be enabled via the configuration files included with the agent. All checks configuration files for the Windows agent can be found in C:/Program Files (x86)/CollectdWin/conf/ or C:/Program Files/CollectdWin/conf/ (depending on the version of windows). Simply change the enable setting for the ReadSystemChecks from false to true in the CollectdWin.config file to enable the system checks. To configure the checks, edit the ReadSystemChecks.conf file.  Currently, Metricly comes with three pre-built checks: Heartbeat, Processes, and Ports. These are turnkey checks that do not require any scripting or coding, just simple configuration setting in the respective configuration files.\nHeartbeat Checks This check is enabled by default. The Heartbeat check is to monitor the state of the agent. This check is enabled by default so no additional configuration is required once the Windows Checks have been enabled.\nTo disable this check, open the ../CollectdWin/conf/ReadSystemChecks.config and change the EnableAgentHeartbeat setting to false.\nNote that each check has a TTL (time to live) timer which is expressed as a multiple of the agent collection interval time. The default agent collection interval is 60 seconds so a TTLMultiplier of 2.0 would mean that the check timer would expire if no new post has been made to the API within 120 seconds. The minimum value allowed is 1.0 and decimal values are allowed. The intent is to have the TTL timer slightly be longer in duration than the posting frequency for the checks. This will allow some buffer and avoid potential “flapping” due to network latency or processing delays.\n\u0026lt;readsystemchecks enableagentheartbeat=\u0026quot;true\u0026quot; heartbeatttlmultiplier=\u0026quot;2.0\u0026quot;\u0026gt; \u0026lt;/readsystemchecks\u0026gt;  HTTP Checks Configure HTTP checks to send an HTTP GET request to a URL. If a successful response is returned a check is sent to Metricly. By default, no HTTP checks are configured.\nAdd something like:\n\u0026lt;HttpCheck Name=\u0026quot;MyTestHTTPCheck\u0026quot; Url=\u0026quot;http://www.google.com\u0026quot; StatusMatches=\u0026quot;^(?!4|5)\u0026quot; /\u0026gt;  To your ReadySystemChecks.config file:\n\u0026lt;ReadSystemChecks EnableAgentHeartbeat=\u0026quot;true\u0026quot; HeartbeatTTLMultiplier=\u0026quot;2.5\u0026quot;\u0026gt; \u0026lt;Checks\u0026gt; \u0026lt;HttpCheck Name=\u0026quot;MyTestHTTPCheck\u0026quot; Url=\u0026quot;http://www.google.com\u0026quot; StatusMatches=\u0026quot;^(?!4|5)\u0026quot; /\u0026gt; \u0026lt;/Checks\u0026gt; \u0026lt;/ReadSystemChecks\u0026gt;   Name: This is used as the name of the check in Metricly if Alias is not set. URL: This is the URL to test. A check is sent if an HTTP GET request sent to the given URL returns a successful response. Redirects are automatically followed. StatusMatches: (optional) A regular expression to evaluate a successful response code. The default expression is ^2 which matches any 2xx code. Other examples:  ^(?!4|5) : any code except 4xx or 5xx ^(2|3) : any 2xx or 3xx code  AuthHeader: (optional) An authorization header to send with the request. e.g., Basic dXNlcm5hbWU6cGFzc3dvcmQ Alias: (optional) An alias to use for the check name in Metricly. TTLMultiplier: (optional) Sets the time-to-live of the check as a multiple of the agent execution interval. For example, if the agent is configured to collect data every 60 seconds (the default) and the check is configured with a TTLMultiplier of 2.5 (the default) then the next check must be received by Metricly within 150 seconds in order to pass.  Process and Service Checks  Service checks: verify whether a Windows Service is in the running state Process checks: verify whether a process of the given name is in the list of processes running on the computer.  By default, no process or service checks are enabled.\nTo add a new check:\n Edit the ../CollectdWin/conf/ReadSystemChecks.config file Insert a new entry between the … tags:  The check can be either Service or Process. Service Check: the Name setting is the service name. This can be found by opening the service in the Service Control Manager (note that it is the Service Name, not the Display Name). Process Check: the Name setting is is the process name as it appears in the performance monitor process list (this is typically the same as it appears in Task Manager but without the file extension).  (Optional) set the TTLMultiplier to configure the check time-to-live as a multiple of the agent collection interval.  For example, if the agent is configured to collect data every 60 seconds (the default) and the check is configured with a TTLMultiplier of 2.5 (the default) then the next check must be received by Metricly within 150 seconds in order to pass. The minimum allowed value is 1.0, but we recommended that it is set slightly higher to allow for processing time and network latency etc.  (Optional) You can add Alias=”my check alias” setting to provide an alias for the check received by Metricly. If it is not supplied then the process name is used. (Advanced) To capture multiple processes with a single check you can add UseRegex=”true” to the check configuration. With this set to true the Name field is used as a regular expression instead of an exact match and may match several processes.  \u0026lt;ServiceCheck Name=\u0026quot;MSSQLSERVER\u0026quot; Alias=\u0026quot;sqlservercheck\u0026quot; TTLMultiplier=\u0026quot;2.5\u0026quot;/\u0026gt; \u0026lt;ProcessCheck Name=\u0026quot;Process123\u0026quot; Alias=\u0026quot;process123\u0026quot; TTLMultiplier=\u0026quot;2.5\u0026quot;/\u0026gt;  Port Checks No port checks are configured by default.To configure the port checks requires the same steps documented above for the Service and Process checks except that the Name is simply the check name and the Port must be specified.\n \u0026lt;PortCheck Name=\u0026quot;ApplicationABC\u0026quot; Port=\u0026quot;8081\u0026quot;/\u0026gt;  "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/alerts-notifications/policies/default-policies/windows-policies/",
	"title": "Windows Policies",
	"tags": ["#alerts", "#notifications", "#policies", "#default policies", "#windows"],
	"description": "",
	"content": "Policy names are prefixed with Windows –\n\r   Policy name Duration Condition 1 (and) Condition 2 (and) Condition 3 Cat. Description     Elevated Disk Latency 15 min physical_disk._Total.avg_sec_per_read has an upper baseline deviation physical_disk._Total.avg_sec_per_write has an upper baseline deviation  WARNING This policy will generate a WARNING event when both disk read and write times are higher than their expected baselines   Elevated MemoryUtilization 10 min metricly.winsrv.memory.utilizationpercent has an upper baseline deviation + an upper contextual deviation   WARNING This policy will generate a WARNING event when memory utilization on the Windows server is higher than expected.   Heavy CPU Load 15 min metricly.winsrv.system.processor_queue_length_normalized has a static threshold \u0026gt; 2 processor._Total.percent_processor_time has an upper baseline deviation + an upper contextual deviation system.context_switches_per_sec has an upper baseline deviation + an upper contextual deviation CRITICAL High CPU values by themselves are not always a good indicator of server being under heavy load. This policy looks for upper deviations not only in CPU, but in run queue size (system.processor_queue_length) and context switches as well. Taken together, upper deviations in all three of these key metrics are a good indication of an overloaded server.   Heavy Disk Load 15 min physical_disk._Total.avg_queue_length has an upper baseline deviation + an upper contextual deviation   WARNING This policy will generate a WARNING event if the average disk queue length for the server is higher than expected, indicating a potential problem with heavy disk load.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/postresql/postresql-metrics/",
	"title": "metrics",
	"tags": ["#postresql", "#integrations", "#metrics"],
	"description": "",
	"content": " Collected    Friendly Name Fully Qualified Name (FQN) Description Statistic Units Min Max Sparse Data Strategy (SDS) BASE CORR UTIL     Blocks Hit postgres.database.*.blks_hit The number of times disk blocks were found already in the PostgreSQLbuffer cache so a read was not necessary. average  0 none none yes no no   Blocks Read postgres.database.*.blks_read The number of disk blocks read in the database. average  0 none none yes no no   Connections postgres.database.*.connections The number of connections to the database. average  0 none none yes no no   Backend Connections postgres.database.*.numbackends The number of backends currently connected to the database. average  0 none none yes no no   Database Size postgres.database.*.size The size of the database. average  0 none none yes no no   Deleted Rows postgres.database.*.tup_deleted Number of rows deleted by queries in the database. average  0 none none yes no no   Fetched Rows postgres.database.*.tup_fetched Number of rows fetched by queries in the database. average  0 none none yes no no   Inserted Rows postgres.database.*.tup_inserted Number of rows inserted by queries in the database. average  0 none none yes no no   Returned Rows postgres.database.*.tup_returned Number of rows returned by queries in the database. average  0 none none yes no no   Updated Rows postgres.database.*.tup_updated Number of rows updated by queries in the database. average  0 none none yes no no   Committed Transactions postgres.database.*.xact_commit Number of transactions in the database that have been committed. average  0 none none yes no no   Rolled Back Transactions postgres.database.*.xact_rollback Number of transactions in the database that have been rolled back. average  0 none none yes no no    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/rabbitmq/",
	"title": "rabbitMQ",
	"tags": ["#rabbitmq", "#integrations"],
	"description": "",
	"content": " Rabbit MQ is a message broker that manages queues between message producers and consumers. Metricly can be used to monitor your RabbitMQ server’s queuing performance.\nPrerequisites  Linux Agent  Before editing the configuration file, you should verify the RabbitMQ management module is enabled. If the module is not enabled, do the following:\n If the package is installed globally, type this into your command prompt:\nrabbitmq-plugins enable rabbitmq_management  If the package is installed in a directory, type this into your command prompt instead:\n/usr/lib/rabbitmq/bin/rabbitmq-plugins enable rabbitmq_management   Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the RabbitMQCollector.conf file. Change the enabled setting to True. Replace the default host address and/or port number if necessary. Replace the user and password settings with the appropriate values. Optionally, change the cluster value to false if you aren’t using a cluster or do not wish to collect several additional cluster metrics. Save the file and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting RabbitMQ metrics.   host 127.0.0.1:15672 Hostname and port to collect from.   user guest User name authentication for RabbitMQ.   password guest Password authentication for RabbitMQ.   replace_dot ‘_’ A value to replace the “.” in queue names and vhosts names. This option helps Metricly’s metadata usage if you use dots in your queue naming convention.   cluster TRUE If this node is part of a cluster, the collector will collect metrics on the cluster health.   metrics_blacklist “(.-test__[abc]-.) (rabbitmq.queues..*)”   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   queues  List of queues to publish. Leave empty to publish all.   queues_ignored  A list of queues or regexes for queue names not to report on.   vhosts  A list of vhosts and queues to collect.    "
},
{
	"uri": "https://metriclyhelpsite.netlify.com/integrations/collectors/redis/",
	"title": "redis",
	"tags": ["#redis", "#integrations"],
	"description": "",
	"content": " Redis is an adaptable, open source, in-memory data structure store that can be used as a database, cache, and message broker. Metricly can be used to monitor the performance of your Redis server.\nPrerequisites  Linux Agent  Configure  Navigate to the collectors folder, /opt/netuitive-agent/conf/collectors. Open the RedisCollector.conf file. Change the enabled setting to True. Update the instances setting to contain any number of Redis instances you want to monitor as long as it follows the format hostname:port. Save the configuration file and restart the Linux Agent.  Collector Options    Option Default Description     enabled FALSE Enable collecting RabbitMQ metrics.   host 127.0.0.1:15672 Hostname and port to collect from.   user guest User name authentication for RabbitMQ.   password guest Password authentication for RabbitMQ.   replace_dot ‘_’ A value to replace the “.” in queue names and vhosts names. This option helps Metricly’s metadata usage if you use dots in your queue naming convention.   cluster TRUE If this node is part of a cluster, the collector will collect metrics on the cluster health.   metrics_blacklist “(.-test__[abc]-.) (rabbitmq.queues..*)”   byte_unit  Default numeric output(s).   measure_collector_time  Measure the collector’s run time in milliseconds.   metrics_whitelist  Regex list to match metrics to transmit. Mutually exclusive with metrics_blacklist option.   queues  List of queues to publish. Leave empty to publish all.   queues_ignored  A list of queues or regexes for queue names not to report on.   vhosts  A list of vhosts and queues to collect.    "
}]